<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Getting started from Apache Spark</title><meta name=description content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes."><link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel=stylesheet><link rel=preload href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css as=style><link href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-2.2.4.min.js></script><style>.body__contained img{max-width:100%}</style><script src=/js/bootstrap.min.js></script><script src=/js/language-switch.js></script><script src=/js/fix-menu.js></script><script src=/js/section-nav.js></script><script src=/js/page-nav.js></script><link rel=alternate type=application/rss+xml title="Apache Beam" href=/feed.xml><link rel=canonical href=/get-started/from-spark/ data-proofer-ignore><link rel="shortcut icon" type=image/x-icon href=/images/favicon.ico><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.4.1/css/all.css integrity=sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz crossorigin=anonymous><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-73650088-1','auto');ga('send','pageview');</script></head><body class=body data-spy=scroll data-target=.page-nav data-offset=0><nav class="header navbar navbar-fixed-top"><div class=navbar-header><button type=button class=navbar-toggle aria-expanded=false aria-controls=navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a href=/ class=navbar-brand><img alt=Brand style=height:25px src=/images/beam_logo_navbar.png></a></div><div class="navbar-mask closed"></div><div id=navbar class="navbar-container closed"><ul class="nav navbar-nav"><li><a href=/get-started/beam-overview/>Get Started</a></li><li><a href=/documentation/>Documentation</a></li><li><a href=/documentation/sdks/java/>Languages</a></li><li><a href=/documentation/runners/capability-matrix/>RUNNERS</a></li><li><a href=/roadmap/>Roadmap</a></li><li><a href=/contribute/>Contribute</a></li><li><a href=/community/contact-us/>Community</a></li><li><a href=/blog/>Blog</a></li></ul><ul class="nav navbar-nav navbar-right"><li><div style=width:300px><script>(function(){var cx='012923275103528129024:4emlchv9wzi';var gcse=document.createElement('script');gcse.type='text/javascript';gcse.async=true;gcse.src='https://cse.google.com/cse.js?cx='+cx;var s=document.getElementsByTagName('script')[0];s.parentNode.insertBefore(gcse,s);})();</script><gcse:search></gcse:search></div></li><li class=dropdown><a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px><span class=caret></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href=http://www.apache.org/>ASF Homepage</a></li><li><a href=http://www.apache.org/licenses/>License</a></li><li><a href=http://www.apache.org/security/>Security</a></li><li><a href=http://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a href=http://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li><li><a href=https://github.com/apache/beam/edit/master/website/www/site/content/en/get-started/from-spark.md data-proofer-ignore><i class="far fa-edit fa-lg" alt="Edit on GitHub" title="Edit on GitHub"></i></a></li></ul></div></nav><div class="clearfix container-main-content"><div class="section-nav closed" data-offset-top=90 data-offset-bottom=500><span class="section-nav-back glyphicon glyphicon-menu-left"></span><nav><ul class=section-nav-list data-section-nav><li><span class=section-nav-list-main-title>Get started</span></li><li><a href=/get-started/beam-overview/>Beam Overview</a></li><li><span class=section-nav-list-title>Quickstarts</span><ul class=section-nav-list><li><a href=/get-started/try-apache-beam/>Try Apache Beam</a></li><li><a href=/get-started/quickstart-java/>Quickstart - Java</a></li><li><a href=/get-started/quickstart-py/>Quickstart - Python</a></li><li><a href=/get-started/quickstart-go/>Quickstart - Go</a></li></ul></li><li><a href=/get-started/from-spark/>From Apache Spark</a></li><li><span class=section-nav-list-title>Example Walkthroughs</span><ul class=section-nav-list><li><a href=/get-started/wordcount-example/>WordCount</a></li><li><a href=/get-started/mobile-gaming-example/>Mobile Gaming</a></li></ul></li><li><a href=/get-started/downloads>Downloads</a></li><li><a href=/security>Security</a></li></ul></nav></div><nav class="page-nav clearfix" data-offset-top=90 data-offset-bottom=500><nav id=TableOfContents><ul><li><a href=#overview>Overview</a></li><li><a href=#setup>Setup</a></li><li><a href=#transforms>Transforms</a></li><li><a href=#using-calculated-values>Using calculated values</a></li><li><a href=#next-steps>Next Steps</a></li></ul></nav></nav><div class="body__contained body__section-nav"><h1 id=getting-started-from-apache-spark>Getting started from Apache Spark</h1><script type=text/javascript>localStorage.setItem("language","language-py")</script><p>If you already know <a href=http://spark.apache.org/><em>Apache Spark</em></a>,
learning <em>Apache Beam</em> is familiar.
The Beam and Spark APIs are similar, so you already know the basic concepts.</p><p>Spark stores data <em>Spark DataFrames</em> for structured data,
and in <em>Resilient Distributed Datasets</em> (RDD) for unstructured data.
We are using RDDs for this guide.</p><p>A Spark RDD represents a collection of elements,
while in Beam it&rsquo;s called a <em>Parallel Collection</em> (PCollection).
A PCollection in Beam does <em>not</em> have any ordering guarantees.</p><p>Likewise, a transform in Beam is called a <em>Parallel Transform</em> (PTransform).</p><p>Here are some examples of common operations and their equivalent between PySpark and Beam.</p><h2 id=overview>Overview</h2><p>Here&rsquo;s a simple example of a PySpark pipeline that takes the numbers from one to four,
multiplies them by two, adds all the values together, and prints the result.</p><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=kn>import</span> <span class=nn>pyspark</span>

<span class=n>sc</span> <span class=o>=</span> <span class=n>pyspark</span><span class=o>.</span><span class=n>SparkContext</span><span class=p>()</span>
<span class=n>result</span> <span class=o>=</span> <span class=p>(</span>
    <span class=n>sc</span><span class=o>.</span><span class=n>parallelize</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span>
    <span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span> <span class=o>*</span> <span class=mi>2</span><span class=p>)</span>
    <span class=o>.</span><span class=n>reduce</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>x</span> <span class=o>+</span> <span class=n>y</span><span class=p>)</span>
<span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span></code></pre></div></div><p>In Beam you pipe your data through the pipeline using the
<em>pipe operator</em> <code>|</code> like <code>data | beam.Map(...)</code> instead of chaining
methods like <code>data.map(...)</code>, but they&rsquo;re doing the same thing.</p><p>Here&rsquo;s what an equivalent pipeline looks like in Beam.</p><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=kn>import</span> <span class=nn>apache_beam</span> <span class=kn>as</span> <span class=nn>beam</span>

<span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>pipeline</span><span class=p>:</span>
    <span class=n>result</span> <span class=o>=</span> <span class=p>(</span>
        <span class=n>pipeline</span>
        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span>
        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span> <span class=o>*</span> <span class=mi>2</span><span class=p>)</span>
        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>CombineGlobally</span><span class=p>(</span><span class=nb>sum</span><span class=p>)</span>
        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>print</span><span class=p>)</span>
    <span class=p>)</span></code></pre></div></div><blockquote><p>ℹ️ Note that we called <code>print</code> inside a <code>Map</code> transform.
That&rsquo;s because we can only access the elements of a PCollection
from within a PTransform.</p></blockquote><p>Another thing to note is that Beam pipelines are constructed lazily.
This means that when you pipe <code>|</code> data you&rsquo;re only declaring the
transformations and the order you want them to happen,
but the actual computation doesn&rsquo;t happen.
The pipeline is run after the <code>with beam.Pipeline() as pipeline</code> context has
closed.</p><blockquote><p>ℹ️ When the <code>with beam.Pipeline() as pipeline</code> context closes,
it implicitly calls <code>pipeline.run()</code> which triggers the computation to happen.</p></blockquote><p>The pipeline is then sent to your
<a href=https://beam.apache.org/documentation/runners/capability-matrix/>runner of choice</a>
and it processes the data.</p><blockquote><p>ℹ️ The pipeline can run locally with the <em>DirectRunner</em>,
or in a distributed runner such as Flink, Spark, or Dataflow.
The Spark runner is not related to PySpark.</p></blockquote><p>A label can optionally be added to a transform using the
<em>right shift operator</em> <code>>></code> like <code>data | 'My description' >> beam.Map(...)</code>.
This serves both as comments and makes your pipeline easier to debug.</p><p>This is how the pipeline looks after adding labels.</p><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=kn>import</span> <span class=nn>apache_beam</span> <span class=kn>as</span> <span class=nn>beam</span>

<span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>pipeline</span><span class=p>:</span>
    <span class=n>result</span> <span class=o>=</span> <span class=p>(</span>
        <span class=n>pipeline</span>
        <span class=o>|</span> <span class=s1>&#39;Create numbers&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span>
        <span class=o>|</span> <span class=s1>&#39;Multiply by two&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span> <span class=o>*</span> <span class=mi>2</span><span class=p>)</span>
        <span class=o>|</span> <span class=s1>&#39;Sum everything&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>CombineGlobally</span><span class=p>(</span><span class=nb>sum</span><span class=p>)</span>
        <span class=o>|</span> <span class=s1>&#39;Print results&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>print</span><span class=p>)</span>
    <span class=p>)</span></code></pre></div></div><h2 id=setup>Setup</h2><p>Here&rsquo;s a comparison on how to get started both in PySpark and Beam.</p><div class=table-wrapper><table><tr><th></th><th>PySpark</th><th>Beam</th></tr><tr><td><b>Install</b></td><td><code>$ pip install pyspark</code></td><td><code>$ pip install apache-beam</code></td></tr><tr><td><b>Imports</b></td><td><code>import pyspark</code></td><td><code>import apache_beam as beam</code></td></tr><tr><td><b>Creating a<br>local pipeline</b></td><td><code>sc = pyspark.SparkContext() as sc:</code><br><code># Your pipeline code here.</code></td><td><code>with beam.Pipeline() as pipeline:</code><br><code>&nbsp;&nbsp;&nbsp;&nbsp;# Your pipeline code here.</code></td></tr><tr><td><b>Creating values</b></td><td><code>values = sc.parallelize([1, 2, 3, 4])</code></td><td><code>values = pipeline | beam.Create([1, 2, 3, 4])</code></td></tr><tr><td><b>Creating<br>key-value pairs</b></td><td><code>pairs = sc.parallelize([</code><br><code>&nbsp;&nbsp;&nbsp;&nbsp;('key1', 'value1'),</code><br><code>&nbsp;&nbsp;&nbsp;&nbsp;('key2', 'value2'),</code><br><code>&nbsp;&nbsp;&nbsp;&nbsp;('key3', 'value3'),</code><br><code>])</code></td><td><code>pairs = pipeline | beam.Create([</code><br><code>&nbsp;&nbsp;&nbsp;&nbsp;('key1', 'value1'),</code><br><code>&nbsp;&nbsp;&nbsp;&nbsp;('key2', 'value2'),</code><br><code>&nbsp;&nbsp;&nbsp;&nbsp;('key3', 'value3'),</code><br><code>])</code></td></tr><tr><td><b>Running a<br>local pipeline</b></td><td><code>$ spark-submit spark_pipeline.py</code></td><td><code>$ python beam_pipeline.py</code></td></tr></table></div><h2 id=transforms>Transforms</h2><p>Here are the equivalents of some common transforms in both PySpark and Beam.</p><div class=table-wrapper><table><thead><tr><th></th><th>PySpark</th><th>Beam</th></tr></thead><tbody><tr><td><a href=/documentation/transforms/python/elementwise/map/><strong>Map</strong></a></td><td><code>values.map(lambda x: x * 2)</code></td><td><code>values | beam.Map(lambda x: x * 2)</code></td></tr><tr><td><a href=/documentation/transforms/python/elementwise/filter/><strong>Filter</strong></a></td><td><code>values.filter(lambda x: x % 2 == 0)</code></td><td><code>values | beam.Filter(lambda x: x % 2 == 0)</code></td></tr><tr><td><a href=/documentation/transforms/python/elementwise/flatmap/><strong>FlatMap</strong></a></td><td><code>values.flatMap(lambda x: range(x))</code></td><td><code>values | beam.FlatMap(lambda x: range(x))</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/groupbykey/><strong>Group by key</strong></a></td><td><code>pairs.groupByKey()</code></td><td><code>pairs | beam.GroupByKey()</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/combineglobally/><strong>Reduce</strong></a></td><td><code>values.reduce(lambda x, y: x+y)</code></td><td><code>values | beam.CombineGlobally(sum)</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/combineperkey/><strong>Reduce by key</strong></a></td><td><code>pairs.reduceByKey(lambda x, y: x+y)</code></td><td><code>pairs | beam.CombinePerKey(sum)</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/distinct/><strong>Distinct</strong></a></td><td><code>values.distinct()</code></td><td><code>values | beam.Distinct()</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/count/><strong>Count</strong></a></td><td><code>values.count()</code></td><td><code>values | beam.combiners.Count.Globally()</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/count/><strong>Count by key</strong></a></td><td><code>pairs.countByKey()</code></td><td><code>pairs | beam.combiners.Count.PerKey()</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/top/><strong>Take smallest</strong></a></td><td><code>values.takeOrdered(3)</code></td><td><code>values | beam.combiners.Top.Smallest(3)</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/top/><strong>Take largest</strong></a></td><td><code>values.takeOrdered(3, lambda x: -x)</code></td><td><code>values | beam.combiners.Top.Largest(3)</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/sample/><strong>Random sample</strong></a></td><td><code>values.takeSample(False, 3)</code></td><td><code>values | beam.combiners.Sample.FixedSizeGlobally(3)</code></td></tr><tr><td><a href=/documentation/transforms/python/other/flatten/><strong>Union</strong></a></td><td><code>values.union(otherValues)</code></td><td><code>(values, otherValues) | beam.Flatten()</code></td></tr><tr><td><a href=/documentation/transforms/python/aggregation/cogroupbykey/><strong>Co-group</strong></a></td><td><code>pairs.cogroup(otherPairs)</code></td><td><code>{'Xs': pairs, 'Ys': otherPairs} | beam.CoGroupByKey()</code></td></tr></tbody></table></div><blockquote><p>ℹ️ To learn more about the transforms available in Beam, check the
<a href=/documentation/transforms/python/overview>Python transform gallery</a>.</p></blockquote><h2 id=using-calculated-values>Using calculated values</h2><p>Since we are working in potentially distributed environments,
we can&rsquo;t guarantee that the results we&rsquo;ve calculated are available at any given machine.</p><p>In PySpark, we can get a result from a collection of elements (RDD) by using
<code>data.collect()</code>, or other aggregations such as <code>reduce()</code>, <code>count()</code>, and more.</p><p>Here&rsquo;s an example to scale numbers into a range between zero and one.</p><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=kn>import</span> <span class=nn>pyspark</span>

<span class=n>sc</span> <span class=o>=</span> <span class=n>pyspark</span><span class=o>.</span><span class=n>SparkContext</span><span class=p>()</span>
<span class=n>values</span> <span class=o>=</span> <span class=n>sc</span><span class=o>.</span><span class=n>parallelize</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span>
<span class=n>total</span> <span class=o>=</span> <span class=n>values</span><span class=o>.</span><span class=n>reduce</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>x</span> <span class=o>+</span> <span class=n>y</span><span class=p>)</span>

<span class=c1># We can simply use `total` since it&#39;s already a Python `int` value from `reduce`.</span>
<span class=n>scaled_values</span> <span class=o>=</span> <span class=n>values</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span> <span class=o>/</span> <span class=n>total</span><span class=p>)</span>

<span class=c1># But to access `scaled_values`, we need to call `collect`.</span>
<span class=k>print</span><span class=p>(</span><span class=n>scaled_values</span><span class=o>.</span><span class=n>collect</span><span class=p>())</span></code></pre></div></div><p>In Beam the results from all transforms result in a PCollection.
We use <a href=/documentation/programming-guide/#side-inputs><em>side inputs</em></a>
to feed a PCollection into a transform and access its values.</p><p>Any transform that accepts a function, like
<a href=/documentation/transforms/python/elementwise/map><code>Map</code></a>,
can take side inputs.
If we only need a single value, we can use
<a href=https://beam.apache.org/releases/pydoc/current/apache_beam.pvalue.html#apache_beam.pvalue.AsSingleton><code>beam.pvalue.AsSingleton</code></a> and access them as a Python value.
If we need multiple values, we can use
<a href=https://beam.apache.org/releases/pydoc/current/apache_beam.pvalue.html#apache_beam.pvalue.AsIter><code>beam.pvalue.AsIter</code></a>
and access them as an <a href=https://docs.python.org/3/glossary.html#term-iterable><code>iterable</code></a>.</p><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=kn>import</span> <span class=nn>apache_beam</span> <span class=kn>as</span> <span class=nn>beam</span>

<span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>pipeline</span><span class=p>:</span>
    <span class=n>values</span> <span class=o>=</span> <span class=n>pipeline</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span>
    <span class=n>total</span> <span class=o>=</span> <span class=n>values</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>CombineGlobally</span><span class=p>(</span><span class=nb>sum</span><span class=p>)</span>

    <span class=c1># To access `total`, we need to pass it as a side input.</span>
    <span class=n>scaled_values</span> <span class=o>=</span> <span class=n>values</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span>
        <span class=k>lambda</span> <span class=n>x</span><span class=p>,</span> <span class=n>total</span><span class=p>:</span> <span class=n>x</span> <span class=o>/</span> <span class=n>total</span><span class=p>,</span>
        <span class=n>total</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>pvalue</span><span class=o>.</span><span class=n>AsSingleton</span><span class=p>(</span><span class=n>total</span><span class=p>))</span>

    <span class=n>scaled_values</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>print</span><span class=p>)</span></code></pre></div></div><blockquote><p>ℹ️ In Beam we need to pass a side input explicitly, but we get the
benefit that a reduction or aggregation does <em>not</em> have to fit into memory.</p></blockquote><h2 id=next-steps>Next Steps</h2><ul><li>Take a look at all the available transforms in the <a href=/documentation/transforms/python/overview>Python transform gallery</a>.</li><li>Learn how to read from and write to files in the <a href=/documentation/programming-guide/#pipeline-io><em>Pipeline I/O</em> section of the <em>Programming guide</em></a></li><li>Walk through additional WordCount examples in the <a href=/get-started/wordcount-example>WordCount Example Walkthrough</a>.</li><li>Take a self-paced tour through our <a href=/documentation/resources/learning-resources>Learning Resources</a>.</li><li>Dive in to some of our favorite <a href=/documentation/resources/videos-and-podcasts>Videos and Podcasts</a>.</li><li>Join the Beam <a href=/community/contact-us>users@</a> mailing list.</li><li>If you&rsquo;re interested in contributing to the Apache Beam codebase, see the <a href=/contribute>Contribution Guide</a>.</li></ul><p>Please don&rsquo;t hesitate to <a href=/community/contact-us>reach out</a> if you encounter any issues!</p></div></div><footer class=footer><div class=footer__contained><div class=footer__cols><div class=footer__cols__col><div class=footer__cols__col__logo><img src=/images/beam_logo_circle.svg class=footer__logo alt="Beam logo"></div><div class=footer__cols__col__logo><img src=/images/apache_logo_circle.svg class=footer__logo alt="Apache logo"></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Start</div><div class=footer__cols__col__link><a href=/get-started/beam-overview/>Overview</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-java/>Quickstart (Java)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-py/>Quickstart (Python)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-go/>Quickstart (Go)</a></div><div class=footer__cols__col__link><a href=/get-started/downloads/>Downloads</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Docs</div><div class=footer__cols__col__link><a href=/documentation/programming-guide/>Concepts</a></div><div class=footer__cols__col__link><a href=/documentation/pipelines/design-your-pipeline/>Pipelines</a></div><div class=footer__cols__col__link><a href=/documentation/runners/capability-matrix/>Runners</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Community</div><div class=footer__cols__col__link><a href=/contribute/>Contribute</a></div><div class=footer__cols__col__link><a href=https://projects.apache.org/committee.html?beam target=_blank>Team<img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></div><div class=footer__cols__col__link><a href=/community/presentation-materials/>Media</a></div><div class=footer__cols__col__link><a href=/community/in-person/>Events/Meetups</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Resources</div><div class=footer__cols__col__link><a href=/blog/>Blog</a></div><div class=footer__cols__col__link><a href=/community/contact-us/>Contact Us</a></div><div class=footer__cols__col__link><a href=https://github.com/apache/beam>GitHub</a></div></div></div></div><div class=footer__bottom>&copy;
<a href=http://www.apache.org>The Apache Software Foundation</a>
| <a href=/privacy_policy>Privacy Policy</a>
| <a href=/feed.xml>RSS Feed</a><br><br>Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation. All other products or name brands are trademarks of their respective holders, including The Apache Software Foundation.</div></footer></body></html>