<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Beam SQL extension: CREATE EXTERNAL TABLE Statement</title><meta name=description content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes."><link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel=stylesheet><link rel=preload href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css as=style><link href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-2.2.4.min.js></script><style>.body__contained img{max-width:100%}</style><script src=/js/bootstrap.min.js></script><script src=/js/language-switch.js></script><script src=/js/fix-menu.js></script><script src=/js/section-nav.js></script><script src=/js/page-nav.js></script><link rel=alternate type=application/rss+xml title="Apache Beam" href=/feed.xml><link rel=canonical href=/documentation/dsls/sql/extensions/create-external-table/ data-proofer-ignore><link rel="shortcut icon" type=image/x-icon href=/images/favicon.ico><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.4.1/css/all.css integrity=sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz crossorigin=anonymous><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-73650088-1','auto');ga('send','pageview');</script></head><body class=body data-spy=scroll data-target=.page-nav data-offset=0><nav class="header navbar navbar-fixed-top"><div class=navbar-header><button type=button class=navbar-toggle aria-expanded=false aria-controls=navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a href=/ class=navbar-brand><img alt=Brand style=height:25px src=/images/beam_logo_navbar.png></a></div><div class="navbar-mask closed"></div><div id=navbar class="navbar-container closed"><ul class="nav navbar-nav"><li><a href=/get-started/beam-overview/>Get Started</a></li><li><a href=/documentation/>Documentation</a></li><li><a href=/documentation/sdks/java/>Languages</a></li><li><a href=/documentation/runners/capability-matrix/>RUNNERS</a></li><li><a href=/roadmap/>Roadmap</a></li><li><a href=/contribute/>Contribute</a></li><li><a href=/community/contact-us/>Community</a></li><li><a href=/blog/>Blog</a></li></ul><ul class="nav navbar-nav navbar-right"><li><div style=width:300px><script>(function(){var cx='012923275103528129024:4emlchv9wzi';var gcse=document.createElement('script');gcse.type='text/javascript';gcse.async=true;gcse.src='https://cse.google.com/cse.js?cx='+cx;var s=document.getElementsByTagName('script')[0];s.parentNode.insertBefore(gcse,s);})();</script><gcse:search></gcse:search></div></li><li class=dropdown><a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px><span class=caret></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href=http://www.apache.org/>ASF Homepage</a></li><li><a href=http://www.apache.org/licenses/>License</a></li><li><a href=http://www.apache.org/security/>Security</a></li><li><a href=http://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a href=http://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li><li><a href=https://github.com/apache/beam/edit/master/website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md data-proofer-ignore><i class="far fa-edit fa-lg" alt="Edit on GitHub" title="Edit on GitHub"></i></a></li></ul></div></nav><div class="clearfix container-main-content"><div class="section-nav closed" data-offset-top=90 data-offset-bottom=500><span class="section-nav-back glyphicon glyphicon-menu-left"></span><nav><ul class=section-nav-list data-section-nav><li><span class=section-nav-list-main-title>Languages</span></li><li><span class=section-nav-list-title>Java</span><ul class=section-nav-list><li><a href=/documentation/sdks/java/>Java SDK overview</a></li><li><a href=https://beam.apache.org/releases/javadoc/2.25.0/ target=_blank>Java SDK API reference <img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></li><li><a href=/documentation/sdks/java-dependencies/>Java SDK dependencies</a></li><li><a href=/documentation/sdks/java-extensions/>Java SDK extensions</a></li><li><a href=/documentation/sdks/java-thirdparty/>Java 3rd party extensions</a></li><li><a href=/documentation/sdks/java/testing/nexmark/>Nexmark benchmark suite</a></li></ul></li><li><span class=section-nav-list-title>Python</span><ul class=section-nav-list><li><a href=/documentation/sdks/python/>Python SDK overview</a></li><li><a href=https://beam.apache.org/releases/pydoc/2.25.0/ target=_blank>Python SDK API reference <img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></li><li><a href=/documentation/sdks/python-dependencies/>Python SDK dependencies</a></li><li><a href=/documentation/sdks/python-streaming/>Python streaming pipelines</a></li><li><a href=/documentation/sdks/python-type-safety/>Ensuring Python type safety</a></li><li><a href=/documentation/sdks/python-pipeline-dependencies/>Managing pipeline dependencies</a></li></ul></li><li><span class=section-nav-list-title>Go</span><ul class=section-nav-list><li><a href=/documentation/sdks/go/>Go SDK overview</a></li><li><a href=https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam target=_blank>Go SDK API reference <img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></li></ul></li><li><span class=section-nav-list-title>SQL</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/overview/>Overview</a></li><li><a href=/documentation/dsls/sql/walkthrough/>Walkthrough</a></li><li><a href=/documentation/dsls/sql/shell/>Shell</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Apache Calcite dialect</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/calcite/overview/>Calcite support overview</a></li><li><a href=/documentation/dsls/sql/calcite/query-syntax/>Query syntax</a></li><li><a href=/documentation/dsls/sql/calcite/lexical/>Lexical structure</a></li><li><a href=/documentation/dsls/sql/calcite/data-types/>Data types</a></li><li><a href=/documentation/dsls/sql/calcite/scalar-functions/>Scalar functions</a></li><li><a href=/documentation/dsls/sql/calcite/aggregate-functions/>Aggregate functions</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>ZetaSQL dialect</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/zetasql/overview/>ZetaSQL support overview</a></li><li><a href=/documentation/dsls/sql/zetasql/syntax/>Function call rules</a></li><li><a href=/documentation/dsls/sql/zetasql/conversion-rules/>Conversion rules</a></li><li><a href=/documentation/dsls/sql/zetasql/query-syntax/>Query syntax</a></li><li><a href=/documentation/dsls/sql/zetasql/lexical/>Lexical structure</a></li><li><a href=/documentation/dsls/sql/zetasql/data-types/>Data types</a></li><li><a href=/documentation/dsls/sql/zetasql/operators/>Operators</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Scalar functions</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/zetasql/string-functions/>String functions</a></li><li><a href=/documentation/dsls/sql/zetasql/math-functions/>Mathematical functions</a></li><li><a href=/documentation/dsls/sql/zetasql/conditional-expressions/>Conditional expressions</a></li></ul></li><li><a href=/documentation/dsls/sql/zetasql/aggregate-functions/>Aggregate functions</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Beam SQL extensions</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/extensions/create-external-table/>CREATE EXTERNAL TABLE</a></li><li><a href=/documentation/dsls/sql/extensions/windowing-and-triggering/>Windowing & triggering</a></li><li><a href=/documentation/dsls/sql/extensions/joins/>Joins</a></li><li><a href=/documentation/dsls/sql/extensions/user-defined-functions/>User-defined functions</a></li><li><a href=/documentation/dsls/sql/extensions/set/>SET pipeline options</a></li></ul></li></ul></li></ul></nav></div><nav class="page-nav clearfix" data-offset-top=90 data-offset-bottom=500><nav id=TableOfContents><ul><li><a href=#syntax>Syntax</a></li><li><a href=#bigquery>BigQuery</a><ul><li><a href=#syntax-1>Syntax</a></li><li><a href=#read-mode>Read Mode</a></li><li><a href=#write-mode>Write Mode</a></li><li><a href=#schema>Schema</a></li><li><a href=#example>Example</a></li></ul></li><li><a href=#cloud-bigtable>Cloud Bigtable</a><ul><li><a href=#syntax-2>Syntax</a></li><li><a href=#read-mode-1>Read Mode</a></li><li><a href=#write-mode-1>Write Mode</a></li><li><a href=#example-1>Example</a></li></ul></li><li><a href=#pubsub>Pub/Sub</a><ul><li><a href=#syntax-3>Syntax</a></li><li><a href=#read-mode-2>Read Mode</a></li><li><a href=#write-mode-2>Write Mode</a></li><li><a href=#schema-1>Schema</a></li><li><a href=#supported-payload>Supported Payload</a></li><li><a href=#example-2>Example</a></li></ul></li><li><a href=#kafka>Kafka</a><ul><li><a href=#syntax-4>Syntax</a></li><li><a href=#read-mode-3>Read Mode</a></li><li><a href=#write-mode-3>Write Mode</a></li><li><a href=#supported-formats>Supported Formats</a></li><li><a href=#schema-2>Schema</a></li></ul></li><li><a href=#mongodb>MongoDB</a><ul><li><a href=#syntax-5>Syntax</a></li><li><a href=#read-mode-4>Read Mode</a></li><li><a href=#write-mode-4>Write Mode</a></li><li><a href=#schema-3>Schema</a></li><li><a href=#example-3>Example</a></li></ul></li><li><a href=#text>Text</a><ul><li><a href=#syntax-6>Syntax</a></li><li><a href=#read-mode-5>Read Mode</a></li><li><a href=#write-mode-5>Write Mode</a></li><li><a href=#supported-payload-1>Supported Payload</a></li><li><a href=#schema-4>Schema</a></li><li><a href=#example-4>Example</a></li></ul></li></ul></nav></nav><div class="body__contained body__section-nav"><h1 id=beam-sql-extensions-create-external-table>Beam SQL extensions: CREATE EXTERNAL TABLE</h1><p>Beam SQL&rsquo;s <code>CREATE EXTERNAL TABLE</code> statement registers a virtual table that maps to an
<a href=/documentation/io/built-in/>external storage system</a>.
For some storage systems, <code>CREATE EXTERNAL TABLE</code> does not create a physical table until
a write occurs. After the physical table exists, you can access the table with
the <code>SELECT</code>, <code>JOIN</code>, and <code>INSERT INTO</code> statements.</p><p>The <code>CREATE EXTERNAL TABLE</code> statement includes a schema and extended clauses.</p><h2 id=syntax>Syntax</h2><pre><code>CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName (tableElement [, tableElement ]*)
TYPE type
[LOCATION location]
[TBLPROPERTIES tblProperties]

simpleType: TINYINT | SMALLINT | INTEGER | BIGINT | FLOAT | DOUBLE | DECIMAL | BOOLEAN | DATE | TIME | TIMESTAMP | CHAR | VARCHAR

fieldType: simpleType | MAP&lt;simpleType, fieldType&gt; | ARRAY&lt;fieldType&gt; | ROW&lt;tableElement [, tableElement ]*&gt;

tableElement: columnName fieldType [ NOT NULL ]
</code></pre><ul><li><code>IF NOT EXISTS</code>: Optional. If the table is already registered, Beam SQL
ignores the statement instead of returning an error.</li><li><code>tableName</code>: The case sensitive name of the table to create and register,
specified as an
<a href=/documentation/dsls/sql/calcite/lexical#identifiers>Identifier</a>.
The table name does not need to match the name in the underlying data
storage system.</li><li><code>tableElement</code>: <code>columnName</code> <code>fieldType</code> <code>[ NOT NULL ]</code><ul><li><code>columnName</code>: The case sensitive name of the column, specified as a
backtick_quoted_expression.</li><li><code>fieldType</code>: The field&rsquo;s type, specified as one of the following types:<ul><li><code>simpleType</code>: <code>TINYINT</code>, <code>SMALLINT</code>, <code>INTEGER</code>, <code>BIGINT</code>, <code>FLOAT</code>,
<code>DOUBLE</code>, <code>DECIMAL</code>, <code>BOOLEAN</code>, <code>DATE</code>, <code>TIME</code>, <code>TIMESTAMP</code>, <code>CHAR</code>,
<code>VARCHAR</code></li><li><code>MAP&lt;simpleType, fieldType></code></li><li><code>ARRAY&lt;fieldType></code></li><li><code>ROW&lt;tableElement [, tableElement ]*></code></li></ul></li><li><code>NOT NULL</code>: Optional. Indicates that the column is not nullable.</li></ul></li><li><code>type</code>: The I/O transform that backs the virtual table, specified as an
<a href=/documentation/dsls/sql/calcite/lexical/#identifiers>Identifier</a>
with one of the following values:<ul><li><code>bigquery</code></li><li><code>bigtable</code></li><li><code>pubsub</code></li><li><code>kafka</code></li><li><code>text</code></li></ul></li><li><code>location</code>: The I/O specific location of the underlying table, specified as
a <a href=/documentation/dsls/sql/calcite/lexical/#string-literals>String
Literal</a>.
See the I/O specific sections for <code>location</code> format requirements.</li><li><code>tblProperties</code>: The I/O specific quoted key value JSON object with extra
configuration, specified as a <a href=/documentation/dsls/sql/calcite/lexical/#string-literals>String
Literal</a>.
See the I/O specific sections for <code>tblProperties</code> format requirements.</li></ul><h2 id=bigquery>BigQuery</h2><h3 id=syntax-1>Syntax</h3><pre><code>CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName (tableElement [, tableElement ]*)
TYPE bigquery
LOCATION '[PROJECT_ID]:[DATASET].[TABLE]'
TBLPROPERTIES '{&quot;method&quot;: &quot;DIRECT_READ&quot;}'
</code></pre><ul><li><code>LOCATION</code>: Location of the table in the BigQuery CLI format.<ul><li><code>PROJECT_ID</code>: ID of the Google Cloud Project.</li><li><code>DATASET</code>: BigQuery Dataset ID.</li><li><code>TABLE</code>: BigQuery Table ID within the Dataset.</li></ul></li><li><code>TBLPROPERTIES</code>:<ul><li><code>method</code>: Optional. Read method to use. Following options are available:<ul><li><code>DIRECT_READ</code>: Use the BigQuery Storage API.</li><li><code>EXPORT</code>: Export data to Google Cloud Storage in Avro format and read data files from that location.</li><li>Default is <code>DIRECT_READ</code> for Beam 2.21+ (older versions use <code>EXPORT</code>).</li></ul></li></ul></li></ul><h3 id=read-mode>Read Mode</h3><p>Beam SQL supports reading columns with simple types (<code>simpleType</code>) and arrays of simple
types (<code>ARRAY&lt;simpleType></code>).</p><p>When reading using <code>EXPORT</code> method the following pipeline options should be set:</p><ul><li><code>project</code>: ID of the Google Cloud Project.</li><li><code>tempLocation</code>: Bucket to store intermediate data in. Ex: <code>gs://temp-storage/temp</code>.</li></ul><p>When reading using <code>DIRECT_READ</code> method, an optimizer will attempt to perform
project and predicate push-down, potentially reducing the time requited to read the data from BigQuery.</p><p>More information about the BigQuery Storage API can be found <a href=https://beam.apache.org/documentation/io/built-in/google-bigquery/#storage-api>here</a>.</p><h3 id=write-mode>Write Mode</h3><p>if the table does not exist, Beam creates the table specified in location when
the first record is written. If the table does exist, the specified columns must
match the existing table.</p><h3 id=schema>Schema</h3><p>Schema-related errors will cause the pipeline to crash. The Map type is not
supported. Beam SQL types map to <a href=https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types>BigQuery Standard SQL
types</a>
as follows:</p><table><tr><td>Beam SQL Type</td><td>BigQuery Standard SQL Type</td></tr><tr><td>TINYINT, SMALLINT, INTEGER, BIGINT &nbsp;</td><td>INT64</td></tr><tr><td>FLOAT, DOUBLE, DECIMAL</td><td>FLOAT64</td></tr><tr><td>BOOLEAN</td><td>BOOL</td></tr><tr><td>DATE</td><td>DATE</td></tr><tr><td>TIME</td><td>TIME</td></tr><tr><td>TIMESTAMP</td><td>TIMESTAMP</td></tr><tr><td>CHAR, VARCHAR</td><td>STRING</td></tr><tr><td>MAP</td><td>(not supported)</td></tr><tr><td>ARRAY</td><td>ARRAY</td></tr><tr><td>ROW</td><td>STRUCT</td></tr></table><h3 id=example>Example</h3><pre><code>CREATE EXTERNAL TABLE users (id INTEGER, username VARCHAR)
TYPE bigquery
LOCATION 'testing-integration:apache.users'
</code></pre><h2 id=cloud-bigtable>Cloud Bigtable</h2><h3 id=syntax-2>Syntax</h3><pre><code>CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName (
    key VARCHAR NOT NULL,
    family ROW&lt;qualifier cells [, qualifier cells ]* &gt;
    [, family ROW&lt; qualifier cells [, qualifier cells ]* &gt; ]*
)
TYPE bigtable
LOCATION 'googleapis.com/bigtable/projects/[PROJECT_ID]/instances/[INSTANCE_ID]/tables/[TABLE]'
</code></pre><ul><li><code>key</code>: key of the Bigtable row</li><li><code>family</code>: name of the column family</li><li><code>qualifier</code>: the column qualifier</li><li><code>cells</code>: Either of each value:<ul><li><code>TYPE</code></li><li><code>ARRAY&lt;SIMPLE_TYPE></code></li></ul></li><li><code>LOCATION</code>:<ul><li><code>PROJECT_ID</code>: ID of the Google Cloud Project.</li><li><code>INSTANCE_ID</code>: Bigtable instance ID.</li><li><code>TABLE</code>: Bigtable Table ID.</li></ul></li><li><code>TYPE</code>: <code>SIMPLE_TYPE</code> or <code>CELL_ROW</code></li><li><code>CELL_ROW</code>: <code>ROW&lt;val SIMPLE_TYPE [, timestampMicros BIGINT [NOT NULL]] [, labels ARRAY&lt;VARCHAR> [NOT NULL]]</code></li><li><code>SIMPLE_TYPE</code>: on of the following:<ul><li><code>BINARY</code></li><li><code>VARCHAR</code></li><li><code>BIGINT</code></li><li><code>INTEGER</code></li><li><code>SMALLINT</code></li><li><code>TINYINT</code></li><li><code>DOUBLE</code></li><li><code>FLOAT</code></li><li><code>BOOLEAN</code></li><li><code>TIMESTAMP</code></li></ul></li></ul><p>An alternative syntax with a flat schema:</p><pre><code>CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName (
    key VARCHAR NOT NULL,
    qualifier SIMPLE_TYPE
    [, qualifier SIMPLE_TYPE ]*
)
TYPE bigtable
LOCATION 'googleapis.com/bigtable/projects/[PROJECT_ID]/instances/[INSTANCE_ID]/tables/[TABLE]'
TBLPROPERTIES '{
  &quot;columnsMapping&quot;: &quot;family:qualifier[,family:qualifier]*&quot;
}'
</code></pre><ul><li><code>key</code>: key of the Bigtable row</li><li><code>family</code>: name of the column family</li><li><code>qualifier</code>: the column qualifier</li><li><code>LOCATION</code>:<ul><li><code>PROJECT_ID</code>: ID of the Google Cloud Project.</li><li><code>INSTANCE_ID</code>: Bigtable instance ID.</li><li><code>TABLE</code>: Bigtable Table ID.</li></ul></li><li><code>TBLPROPERTIES</code>: JSON object containing columnsMapping key with comma-separated
key-value pairs separated by a colon</li><li><code>SIMPLE_TYPE</code>: the same as in the previous syntax</li></ul><h3 id=read-mode-1>Read Mode</h3><p>Beam SQL supports reading rows with mandatory <code>key</code> field, at least one <code>family</code>
with at least one <code>qualifier</code>. Cells are represented as simple types (<code>SIMPLE_TYPE</code>) or
ROW type with a mandatory <code>val</code> field, optional <code>timestampMicros</code> and optional <code>labels</code>. Both
read the latest cell in the column. Cells specified as Arrays of simple types
(<code>ARRAY&lt;simpleType></code>) allow to read all the column&rsquo;s values.</p><p>For flat schema only <code>SIMPLE_TYPE</code> values are allowed. Every field except for <code>key</code> must correspond
to the key-values pairs specified in <code>columnsMapping</code>.</p><p>Not all existing column families and qualifiers have to be provided to the schema.</p><p>Filters are only allowed by <code>key</code> field with single <code>LIKE</code> statement with
<a href=https://github.com/google/re2/wiki/Syntax>RE2 Syntax</a> regex, e.g.
<code>SELECT * FROM table WHERE key LIKE '^key[012]{1}'</code></p><h3 id=write-mode-1>Write Mode</h3><p>Supported for flat schema only.</p><h3 id=example-1>Example</h3><pre><code>CREATE EXTERNAL TABLE beamTable(
  key VARCHAR NOT NULL,
  beamFamily ROW&lt;
     boolLatest BOOLEAN NOT NULL,
     longLatestWithTs ROW&lt;
        val BIGINT NOT NULL,
        timestampMicros BIGINT NOT NULL
      &gt; NOT NULL,
      allStrings ARRAY&lt;VARCHAR&gt; NOT NULL,
      doubleLatestWithTsAndLabels ROW&lt;
        val DOUBLE NOT NULL,
        timestampMicros BIGINT NOT NULL,
        labels ARRAY&lt;VARCHAR&gt; NOT NULL
      &gt; NOT NULL,
      binaryLatestWithLabels ROW&lt;
         val BINARY NOT NULL,
         labels ARRAY&lt;VARCHAR&gt; NOT NULL
      &gt; NOT NULL
    &gt; NOT NULL
  )
TYPE bigtable
LOCATION 'googleapis.com/bigtable/projects/beam/instances/beamInstance/tables/beamTable'
</code></pre><p>Flat schema example:</p><pre><code>CREATE EXTERNAL TABLE flatTable(
  key VARCHAR NOT NULL,
  boolColumn BOOLEAN NOT NULL,
  longColumn BIGINT NOT NULL,
  stringColumn VARCHAR NOT NULL,
  doubleColumn DOUBLE NOT NULL,
  binaryColumn BINARY NOT NULL
)
TYPE bigtable
LOCATION 'googleapis.com/bigtable/projects/beam/instances/beamInstance/tables/flatTable'
TBLPROPERTIES '{
  &quot;columnsMapping&quot;: &quot;f:boolColumn,f:longColumn,f:stringColumn,f2:doubleColumn,f2:binaryColumn&quot;
}'
</code></pre><p>Write example:</p><pre><code>INSERT INTO writeTable(key, boolColumn, longColumn, stringColumn, doubleColumn)
  VALUES ('key', TRUE, 10, 'stringValue', 5.5)
</code></pre><h2 id=pubsub>Pub/Sub</h2><h3 id=syntax-3>Syntax</h3><pre><code>CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName(
    event_timestamp TIMESTAMP,
    attributes MAP&lt;VARCHAR, VARCHAR&gt;,
    payload ROW&lt;tableElement [, tableElement ]*&gt;
)
TYPE pubsub
LOCATION 'projects/[PROJECT]/topics/[TOPIC]'
TBLPROPERTIES '{
    &quot;timestampAttributeKey&quot;: &quot;key&quot;,
    &quot;deadLetterQueue&quot;: &quot;projects/[PROJECT]/topics/[TOPIC]&quot;,
    &quot;format&quot;: &quot;format&quot;
}'
</code></pre><ul><li><code>event_timestamp</code>: The event timestamp associated with the Pub/Sub message
by PubsubIO. It can be one of the following:<ul><li>Message publish time, which is provided by Pub/Sub. This is the default
value if no extra configuration is provided.</li><li>A timestamp specified in one of the user-provided message attributes.
The attribute key is configured by the <code>timestampAttributeKey</code> field of
the <code>tblProperties</code> blob. The value of the attribute should conform to
the <a href=https://beam.apache.org/releases/javadoc/2.4.0/org/apache/beam/sdk/io/gcp/pubsub/PubsubIO.Read.html#withTimestampAttribute-java.lang.String->requirements of
PubsubIO</a>,
which is either millis since Unix epoch or <a href=https://www.ietf.org/rfc/rfc3339.txt>RFC 339
</a>date string.</li></ul></li><li><code>attributes</code>: The user-provided attributes map from the Pub/Sub message;</li><li><code>payload</code>: The schema of the payload of the Pub/Sub message. If a record
can&rsquo;t be unmarshalled, the record is written to the topic specified in the
<code>deadLeaderQueue</code> field of the <code>tblProperties</code> blob. If no dead-letter queue
is specified in this case, an exception is thrown and the pipeline will
crash.</li><li><code>LOCATION</code>:<ul><li><code>PROJECT</code>: ID of the Google Cloud Project</li><li><code>TOPIC</code>: The Pub/Sub topic name. A subscription will be created
automatically, but the subscription is not cleaned up automatically.
Specifying an existing subscription is not supported.</li></ul></li><li><code>TBLPROPERTIES</code>:<ul><li><code>timestampAttributeKey</code>: Optional. The key which contains the event
timestamp associated with the Pub/Sub message. If not specified, the
message publish timestamp is used as an event timestamp for
windowing/watermarking.</li><li><code>deadLetterQueue</code>: The topic into which messages are written if the
payload was not parsed. If not specified, an exception is thrown for
parsing failures.</li><li><code>format</code>: Optional. Allows you to specify the Pubsub payload format.
Possible values are {<code>json</code>, <code>avro</code>}. Defaults to <code>json</code>.</li></ul></li></ul><h3 id=read-mode-2>Read Mode</h3><p>PubsubIO is currently limited to read access only.</p><h3 id=write-mode-2>Write Mode</h3><p>Not supported. PubSubIO is currently limited to read access only in Beam SQL.</p><h3 id=schema-1>Schema</h3><p>Pub/Sub messages have metadata associated with them, and you can reference this
metadata in your queries. For each message, Pub/Sub exposes its publish time and
a map of user-provided attributes in addition to the payload (unstructured in
the general case). This information must be preserved and accessible from the
SQL statements. Currently, this means that PubsubIO tables require you to
declare a special set of columns, as shown below.</p><h3 id=supported-payload>Supported Payload</h3><ul><li>JSON Objects (Default)<ul><li>Beam only supports querying messages with payload containing JSON
objects. Beam attempts to parse JSON to match the schema of the
<code>payload</code> field.</li></ul></li><li>Avro<ul><li>An Avro schema is automatically generated from the specified schema of
the <code>payload</code> field. It is used to parse incoming messages.</li></ul></li></ul><h3 id=example-2>Example</h3><pre><code>CREATE EXTERNAL TABLE locations (event_timestamp TIMESTAMP, attributes MAP&lt;VARCHAR, VARCHAR&gt;, payload ROW&lt;id INTEGER, location VARCHAR&gt;)
TYPE pubsub
LOCATION 'projects/testing-integration/topics/user-location'
</code></pre><h2 id=kafka>Kafka</h2><p>KafkaIO is experimental in Beam SQL.</p><h3 id=syntax-4>Syntax</h3><pre><code>CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName (tableElement [, tableElement ]*)
TYPE kafka
LOCATION 'kafka://localhost:2181/brokers'
TBLPROPERTIES '{
    &quot;bootstrap.servers&quot;:&quot;localhost:9092&quot;,
    &quot;topics&quot;: [&quot;topic1&quot;, &quot;topic2&quot;],
    &quot;format&quot;: &quot;avro&quot;
    [, &quot;protoClass&quot;: &quot;com.example.ExampleMessage&quot; ]
}'
</code></pre><ul><li><code>LOCATION</code>: The Kafka topic URL.</li><li><code>TBLPROPERTIES</code>:<ul><li><code>bootstrap.servers</code>: Optional. Allows you to specify the bootstrap
server.</li><li><code>topics</code>: Optional. Allows you to specify specific topics.</li><li><code>format</code>: Optional. Allows you to specify the Kafka values format. Possible values are
{<code>csv</code>, <code>avro</code>, <code>json</code>, <code>proto</code>}. Defaults to <code>csv</code>.</li><li><code>protoClass</code>: Optional. Use only when <code>format</code> is equal to <code>proto</code>. Allows you to
specify full protocol buffer java class name.</li></ul></li></ul><h3 id=read-mode-3>Read Mode</h3><p>Read Mode supports reading from a topic.</p><h3 id=write-mode-3>Write Mode</h3><p>Write Mode supports writing to a topic.</p><h3 id=supported-formats>Supported Formats</h3><ul><li>CSV (default)<ul><li>Beam parses the messages, attempting to parse fields according to the
types specified in the schema.</li></ul></li><li>Avro<ul><li>An Avro schema is automatically generated from the specified field
types. It is used to parse incoming messages and to format outgoing
messages.</li></ul></li><li>JSON Objects<ul><li>Beam attempts to parse JSON to match the schema.</li></ul></li><li>Protocol buffers<ul><li>Fields in the schema have to match the fields of the given <code>protoClass</code>.</li></ul></li></ul><h3 id=schema-2>Schema</h3><p>For CSV only simple types are supported.</p><h2 id=mongodb>MongoDB</h2><h3 id=syntax-5>Syntax</h3><pre><code>CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName (tableElement [, tableElement ]*)
TYPE mongodb
LOCATION 'mongodb://[HOST]:[PORT]/[DATABASE]/[COLLECTION]'
</code></pre><ul><li><code>LOCATION</code>: Location of the collection.<ul><li><code>HOST</code>: Location of the MongoDB server. Can be localhost or an ip address.
When authentication is required username and password can be specified
as follows: <code>username:password@localhost</code>.</li><li><code>PORT</code>: Port on which MongoDB server is listening.</li><li><code>DATABASE</code>: Database to connect to.</li><li><code>COLLECTION</code>: Collection within the database.</li></ul></li></ul><h3 id=read-mode-4>Read Mode</h3><p>Read Mode supports reading from a collection.</p><h3 id=write-mode-4>Write Mode</h3><p>Write Mode supports writing to a collection.</p><h3 id=schema-3>Schema</h3><p>Only simple types are supported. MongoDB documents are mapped to Beam SQL types via <a href=https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/transforms/JsonToRow.html><code>JsonToRow</code></a> transform.</p><h3 id=example-3>Example</h3><pre><code>CREATE EXTERNAL TABLE users (id INTEGER, username VARCHAR)
TYPE mongodb
LOCATION 'mongodb://localhost:27017/apache/users'
</code></pre><h2 id=text>Text</h2><p>TextIO is experimental in Beam SQL. Read Mode and Write Mode do not currently
access the same underlying data.</p><h3 id=syntax-6>Syntax</h3><pre><code>CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName (tableElement [, tableElement ]*)
TYPE text
LOCATION '/home/admin/orders'
TBLPROPERTIES '{&quot;format: &quot;Excel&quot;}'
</code></pre><ul><li><code>LOCATION</code>: The path to the file for Read Mode. The prefix for Write Mode.</li><li><code>TBLPROPERTIES</code>:<ul><li><code>format</code>: Optional. Allows you to specify the CSV Format, which controls
the field delimeter, quote character, record separator, and other properties.
See the following table:</li></ul></li></ul><div class=table-bordered-wrapper><table><thead><tr><th>Value for <code>format</code></th><th>Field delimiter</th><th>Quote</th><th>Record separator</th><th>Ignore empty lines?</th><th>Allow missing column names?</th></tr></thead><tbody><tr><td><code>default</code></td><td><code>,</code></td><td><code>"</code></td><td><code>\r\n</code></td><td>Yes</td><td>No</td></tr><tr><td><code>rfc4180</code></td><td><code>,</code></td><td><code>"</code></td><td><code>\r\n</code></td><td>No</td><td>No</td></tr><tr><td><code>excel</code></td><td><code>,</code></td><td><code>"</code></td><td><code>\r\n</code></td><td>No</td><td>Yes</td></tr><tr><td><code>tdf</code></td><td><code>\t</code></td><td><code>"</code></td><td><code>\r\n</code></td><td>Yes</td><td>No</td></tr><tr><td><code>mysql</code></td><td><code>\t</code></td><td>none</td><td><code>\n</code></td><td>No</td><td>No</td></tr></tbody></table></div><h3 id=read-mode-5>Read Mode</h3><p>Read Mode supports reading from a file.</p><h3 id=write-mode-5>Write Mode</h3><p>Write Mode supports writing to a set of files. TextIO creates file on writes.</p><h3 id=supported-payload-1>Supported Payload</h3><ul><li>CSV<ul><li>Beam parses the messages, attempting to parse fields according to the
types specified in the schema using org.apache.commons.csv.</li></ul></li></ul><h3 id=schema-4>Schema</h3><p>Only simple types are supported.</p><h3 id=example-4>Example</h3><pre><code>CREATE EXTERNAL TABLE orders (id INTEGER, price INTEGER)
TYPE text
LOCATION '/home/admin/orders'
</code></pre></div></div><footer class=footer><div class=footer__contained><div class=footer__cols><div class=footer__cols__col><div class=footer__cols__col__logo><img src=/images/beam_logo_circle.svg class=footer__logo alt="Beam logo"></div><div class=footer__cols__col__logo><img src=/images/apache_logo_circle.svg class=footer__logo alt="Apache logo"></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Start</div><div class=footer__cols__col__link><a href=/get-started/beam-overview/>Overview</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-java/>Quickstart (Java)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-py/>Quickstart (Python)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-go/>Quickstart (Go)</a></div><div class=footer__cols__col__link><a href=/get-started/downloads/>Downloads</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Docs</div><div class=footer__cols__col__link><a href=/documentation/programming-guide/>Concepts</a></div><div class=footer__cols__col__link><a href=/documentation/pipelines/design-your-pipeline/>Pipelines</a></div><div class=footer__cols__col__link><a href=/documentation/runners/capability-matrix/>Runners</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Community</div><div class=footer__cols__col__link><a href=/contribute/>Contribute</a></div><div class=footer__cols__col__link><a href=https://projects.apache.org/committee.html?beam target=_blank>Team<img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></div><div class=footer__cols__col__link><a href=/community/presentation-materials/>Media</a></div><div class=footer__cols__col__link><a href=/community/in-person/>Events/Meetups</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Resources</div><div class=footer__cols__col__link><a href=/blog/>Blog</a></div><div class=footer__cols__col__link><a href=/community/contact-us/>Contact Us</a></div><div class=footer__cols__col__link><a href=https://github.com/apache/beam>GitHub</a></div></div></div></div><div class=footer__bottom>&copy;
<a href=http://www.apache.org>The Apache Software Foundation</a>
| <a href=/privacy_policy>Privacy Policy</a>
| <a href=/feed.xml>RSS Feed</a><br><br>Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation. All other products or name brands are trademarks of their respective holders, including The Apache Software Foundation.</div></footer></body></html>