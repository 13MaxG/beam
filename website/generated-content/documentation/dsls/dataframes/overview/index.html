<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Beam DataFrames: Overview</title><meta name=description content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes."><link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel=stylesheet><link rel=preload href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css as=style><link href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-2.2.4.min.js></script><style>.body__contained img{max-width:100%}</style><script src=/js/bootstrap.min.js></script><script src=/js/language-switch.js></script><script src=/js/fix-menu.js></script><script src=/js/section-nav.js></script><script src=/js/page-nav.js></script><link rel=alternate type=application/rss+xml title="Apache Beam" href=/feed.xml><link rel=canonical href=/documentation/dsls/dataframes/overview/ data-proofer-ignore><link rel="shortcut icon" type=image/x-icon href=/images/favicon.ico><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.4.1/css/all.css integrity=sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz crossorigin=anonymous><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-73650088-1','auto');ga('send','pageview');</script></head><body class=body data-spy=scroll data-target=.page-nav data-offset=0><nav class="header navbar navbar-fixed-top"><div class=navbar-header><button type=button class=navbar-toggle aria-expanded=false aria-controls=navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a href=/ class=navbar-brand><img alt=Brand style=height:25px src=/images/beam_logo_navbar.png></a></div><div class="navbar-mask closed"></div><div id=navbar class="navbar-container closed"><ul class="nav navbar-nav"><li><a href=/get-started/beam-overview/>Get Started</a></li><li><a href=/documentation/>Documentation</a></li><li><a href=/documentation/sdks/java/>Languages</a></li><li><a href=/documentation/runners/capability-matrix/>RUNNERS</a></li><li><a href=/roadmap/>Roadmap</a></li><li><a href=/contribute/>Contribute</a></li><li><a href=/community/contact-us/>Community</a></li><li><a href=/blog/>Blog</a></li></ul><ul class="nav navbar-nav navbar-right"><li><div style=width:300px><script>(function(){var cx='012923275103528129024:4emlchv9wzi';var gcse=document.createElement('script');gcse.type='text/javascript';gcse.async=true;gcse.src='https://cse.google.com/cse.js?cx='+cx;var s=document.getElementsByTagName('script')[0];s.parentNode.insertBefore(gcse,s);})();</script><gcse:search></gcse:search></div></li><li class=dropdown><a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px><span class=caret></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href=http://www.apache.org/>ASF Homepage</a></li><li><a href=http://www.apache.org/licenses/>License</a></li><li><a href=http://www.apache.org/security/>Security</a></li><li><a href=http://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a href=http://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li><li><a href=https://github.com/apache/beam/edit/master/website/www/site/content/en/documentation/dsls/dataframes/overview.md data-proofer-ignore><i class="far fa-edit fa-lg" alt="Edit on GitHub" title="Edit on GitHub"></i></a></li></ul></div></nav><div class="clearfix container-main-content"><div class="section-nav closed" data-offset-top=90 data-offset-bottom=500><span class="section-nav-back glyphicon glyphicon-menu-left"></span><nav><ul class=section-nav-list data-section-nav><li><span class=section-nav-list-main-title>Languages</span></li><li><span class=section-nav-list-title>Java</span><ul class=section-nav-list><li><a href=/documentation/sdks/java/>Java SDK overview</a></li><li><a href=https://beam.apache.org/releases/javadoc/2.27.0/ target=_blank>Java SDK API reference <img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></li><li><a href=/documentation/sdks/java-dependencies/>Java SDK dependencies</a></li><li><a href=/documentation/sdks/java-extensions/>Java SDK extensions</a></li><li><a href=/documentation/sdks/java-thirdparty/>Java 3rd party extensions</a></li><li><a href=/documentation/sdks/java/testing/nexmark/>Nexmark benchmark suite</a></li></ul></li><li><span class=section-nav-list-title>Python</span><ul class=section-nav-list><li><a href=/documentation/sdks/python/>Python SDK overview</a></li><li><a href=https://beam.apache.org/releases/pydoc/2.27.0/ target=_blank>Python SDK API reference <img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></li><li><a href=/documentation/sdks/python-dependencies/>Python SDK dependencies</a></li><li><a href=/documentation/sdks/python-streaming/>Python streaming pipelines</a></li><li><a href=/documentation/sdks/python-type-safety/>Ensuring Python type safety</a></li><li><a href=/documentation/sdks/python-pipeline-dependencies/>Managing pipeline dependencies</a></li></ul></li><li><span class=section-nav-list-title>Go</span><ul class=section-nav-list><li><a href=/documentation/sdks/go/>Go SDK overview</a></li><li><a href=https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam target=_blank>Go SDK API reference <img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></li></ul></li><li><span class=section-nav-list-title>SQL</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/overview/>Overview</a></li><li><a href=/documentation/dsls/sql/walkthrough/>Walkthrough</a></li><li><a href=/documentation/dsls/sql/shell/>Shell</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Apache Calcite dialect</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/calcite/overview/>Calcite support overview</a></li><li><a href=/documentation/dsls/sql/calcite/query-syntax/>Query syntax</a></li><li><a href=/documentation/dsls/sql/calcite/lexical/>Lexical structure</a></li><li><a href=/documentation/dsls/sql/calcite/data-types/>Data types</a></li><li><a href=/documentation/dsls/sql/calcite/scalar-functions/>Scalar functions</a></li><li><a href=/documentation/dsls/sql/calcite/aggregate-functions/>Aggregate functions</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>ZetaSQL dialect</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/zetasql/overview/>ZetaSQL support overview</a></li><li><a href=/documentation/dsls/sql/zetasql/syntax/>Function call rules</a></li><li><a href=/documentation/dsls/sql/zetasql/conversion-rules/>Conversion rules</a></li><li><a href=/documentation/dsls/sql/zetasql/query-syntax/>Query syntax</a></li><li><a href=/documentation/dsls/sql/zetasql/lexical/>Lexical structure</a></li><li><a href=/documentation/dsls/sql/zetasql/data-types/>Data types</a></li><li><a href=/documentation/dsls/sql/zetasql/operators/>Operators</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Scalar functions</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/zetasql/string-functions/>String functions</a></li><li><a href=/documentation/dsls/sql/zetasql/math-functions/>Mathematical functions</a></li><li><a href=/documentation/dsls/sql/zetasql/conditional-expressions/>Conditional expressions</a></li></ul></li><li><a href=/documentation/dsls/sql/zetasql/aggregate-functions/>Aggregate functions</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Beam SQL extensions</span><ul class=section-nav-list><li><a href=/documentation/dsls/sql/extensions/create-external-table/>CREATE EXTERNAL TABLE</a></li><li><a href=/documentation/dsls/sql/extensions/windowing-and-triggering/>Windowing & triggering</a></li><li><a href=/documentation/dsls/sql/extensions/joins/>Joins</a></li><li><a href=/documentation/dsls/sql/extensions/user-defined-functions/>User-defined functions</a></li><li><a href=/documentation/dsls/sql/extensions/set/>SET pipeline options</a></li></ul></li></ul></li><li><span class=section-nav-list-title>DataFrames</span><ul class=section-nav-list><li><a href=/documentation/dsls/dataframes/overview/>Overview</a></li></ul></li></ul></nav></div><nav class="page-nav clearfix" data-offset-top=90 data-offset-bottom=500><nav id=TableOfContents><ul><li><a href=#what-is-a-dataframe>What is a DataFrame?</a></li><li><a href=#using-dataframes>Using DataFrames</a></li><li><a href=#embedding-dataframes-in-a-pipeline>Embedding DataFrames in a pipeline</a></li><li><a href=#differences_from_standard_pandas>Differences from standard Pandas</a></li></ul></nav></nav><div class="body__contained body__section-nav"><h1 id=beam-dataframes-overview>Beam DataFrames overview</h1><p>The Apache Beam Python SDK provides a DataFrame API for working with Pandas-like <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html>DataFrame</a> objects. The feature lets you convert a PCollection to a DataFrame and then interact with the DataFrame using the standard methods available on the Pandas DataFrame API. The DataFrame API is built on top of the Pandas implementation, and Pandas DataFrame methods are invoked on subsets of the datasets in parallel. The big difference between Beam DataFrames and Pandas DataFrames is that operations are deferred by the Beam API, to support the Beam parallel processing model.</p><p>You can think of Beam DataFrames as a domain-specific language (DSL) for Beam pipelines. Similar to <a href=https://beam.apache.org/documentation/dsls/sql/overview/>Beam SQL</a>, DataFrames is a DSL built into the Beam Python SDK. Using this DSL, you can create pipelines without referencing standard Beam constructs like <a href=https://beam.apache.org/documentation/transforms/python/elementwise/pardo/>ParDo</a> or <a href=https://beam.apache.org/documentation/transforms/python/aggregation/combineperkey/>CombinePerKey</a>.</p><p>The Beam DataFrame API is intended to provide access to a familiar programming interface within a Beam pipeline. In some cases, the DataFrame API can also improve pipeline efficiency by deferring to the highly efficient, vectorized Pandas implementation.</p><h2 id=what-is-a-dataframe>What is a DataFrame?</h2><p>If you’re new to Pandas DataFrames, you can get started by reading <a href=https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html>10 minutes to pandas</a>, which shows you how to import and work with the <code>pandas</code> package. Pandas is an open-source Python library for data manipulation and analysis. It provides data structures that simplify working with relational or labeled data. One of these data structures is the <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html>DataFrame</a>, which contains two-dimensional tabular data and provides labeled rows and columns for the data.</p><h2 id=using-dataframes>Using DataFrames</h2><p>To use Beam DataFrames, you need to install Apache Beam version 2.26.0 or higher (for complete setup instructions, see the <a href=https://beam.apache.org/get-started/quickstart-py/>Apache Beam Python SDK Quickstart</a>) and Pandas version 1.0 or higher. You can use DataFrames as shown in the following example, which reads New York City taxi data from a CSV file, performs a grouped aggregation, and writes the output back to CSV:</p><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=kn>from</span> <span class=nn>apache_beam.dataframe.io</span> <span class=kn>import</span> <span class=n>read_csv</span>

<span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>p</span><span class=p>:</span>
  <span class=n>df</span> <span class=o>=</span> <span class=n>p</span> <span class=o>|</span> <span class=n>read_csv</span><span class=p>(</span><span class=s2>&#34;gs://apache-beam-samples/nyc_taxi/misc/sample.csv&#34;</span><span class=p>)</span>
  <span class=n>agg</span> <span class=o>=</span> <span class=n>df</span><span class=p>[[</span><span class=s1>&#39;passenger_count&#39;</span><span class=p>,</span> <span class=s1>&#39;DOLocationID&#39;</span><span class=p>]]</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s1>&#39;DOLocationID&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
  <span class=n>agg</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=s1>&#39;output&#39;</span><span class=p>)</span></code></pre></div></div><p>Pandas is able to infer column names from the first row of the CSV data, which is where <code>passenger_count</code> and <code>DOLocationID</code> come from.</p><p>In this example, the only traditional Beam type is the <code>Pipeline</code> instance. Otherwise the example is written completely with the DataFrame API. This is possible because the Beam DataFrame API includes its own IO operations (for example, <code>read_csv</code> and <code>to_csv</code>) based on the Pandas native implementations. <code>read_*</code> and <code>to_*</code> operations support file patterns and any Beam-compatible file system. The grouping is accomplished with a group-by-key, and arbitrary Pandas operations (in this case, <code>sum</code>) can be applied before the final write that occurs with <code>to_csv</code>.</p><p>The Beam DataFrame API aims to be compatible with the native Pandas implementation, with a few caveats detailed below in <a href=#differences_from_standard_pandas>Differences from standard Pandas</a>.</p><h2 id=embedding-dataframes-in-a-pipeline>Embedding DataFrames in a pipeline</h2><p>To use the DataFrames API in a larger pipeline, you can convert a PCollection to a DataFrame, process the DataFrame, and then convert the DataFrame back to a PCollection. In order to convert a PCollection to a DataFrame and back, you have to use PCollections that have <a href=https://beam.apache.org/documentation/programming-guide/#what-is-a-schema>schemas</a> attached. A PCollection with a schema attached is also referred to as a <em>schema-aware PCollection</em>. To learn more about attaching a schema to a PCollection, see <a href=https://beam.apache.org/documentation/programming-guide/#creating-schemas>Creating schemas</a>.</p><p>Here’s an example that creates a schema-aware PCollection, converts it to a DataFrame using <code>to_dataframe</code>, processes the DataFrame, and then converts the DataFrame back to a PCollection using <code>to_pcollection</code>:</p><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=kn>from</span> <span class=nn>apache_beam.dataframe.convert</span> <span class=kn>import</span> <span class=n>to_dataframe</span>
<span class=kn>from</span> <span class=nn>apache_beam.dataframe.convert</span> <span class=kn>import</span> <span class=n>to_pcollection</span>
<span class=o>...</span>
    <span class=c1># Read the text file[pattern] into a PCollection.</span>
    <span class=n>lines</span> <span class=o>=</span> <span class=n>p</span> <span class=o>|</span> <span class=s1>&#39;Read&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>ReadFromText</span><span class=p>(</span><span class=n>known_args</span><span class=o>.</span><span class=n>input</span><span class=p>)</span>

    <span class=n>words</span> <span class=o>=</span> <span class=p>(</span>
        <span class=n>lines</span>
        <span class=o>|</span> <span class=s1>&#39;Split&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>FlatMap</span><span class=p>(</span>
            <span class=k>lambda</span> <span class=n>line</span><span class=p>:</span> <span class=n>re</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;[\w]+&#39;</span><span class=p>,</span> <span class=n>line</span><span class=p>))</span><span class=o>.</span><span class=n>with_output_types</span><span class=p>(</span><span class=nb>str</span><span class=p>)</span>
        <span class=c1># Map to Row objects to generate a schema suitable for conversion</span>
        <span class=c1># to a dataframe.</span>
        <span class=o>|</span> <span class=s1>&#39;ToRows&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word</span><span class=p>:</span> <span class=n>beam</span><span class=o>.</span><span class=n>Row</span><span class=p>(</span><span class=n>word</span><span class=o>=</span><span class=n>word</span><span class=p>)))</span>

    <span class=n>df</span> <span class=o>=</span> <span class=n>to_dataframe</span><span class=p>(</span><span class=n>words</span><span class=p>)</span>
    <span class=n>df</span><span class=p>[</span><span class=s1>&#39;count&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>
    <span class=n>counted</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s1>&#39;word&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>counted</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=n>known_args</span><span class=o>.</span><span class=n>output</span><span class=p>)</span>

    <span class=c1># Deferred DataFrames can also be converted back to schema&#39;d PCollections</span>
    <span class=n>counted_pc</span> <span class=o>=</span> <span class=n>to_pcollection</span><span class=p>(</span><span class=n>counted</span><span class=p>,</span> <span class=n>include_indexes</span><span class=o>=</span><span class=bp>True</span><span class=p>)</span>

    <span class=c1># Do something with counted_pc</span>
    <span class=o>...</span></code></pre></div></div><p>You can <a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/wordcount_dataframe.py>see the full example on GitHub</a>.</p><p>It’s also possible to use the DataFrame API by passing a function to <a href=https://beam.apache.org/releases/pydoc/current/apache_beam.dataframe.transforms.html#apache_beam.dataframe.transforms.DataframeTransform><code>DataframeTransform</code></a>:</p><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=kn>from</span> <span class=nn>apache_beam.dataframe.transforms</span> <span class=kn>import</span> <span class=n>DataframeTransform</span>

<span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>p</span><span class=p>:</span>
  <span class=o>...</span>
  <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Select</span><span class=p>(</span><span class=n>DOLocationID</span><span class=o>=</span><span class=k>lambda</span> <span class=n>line</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=o>..</span><span class=p>),</span>
                <span class=n>passenger_count</span><span class=o>=</span><span class=k>lambda</span> <span class=n>line</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=o>..</span><span class=p>))</span>
  <span class=o>|</span> <span class=n>DataframeTransform</span><span class=p>(</span><span class=k>lambda</span> <span class=n>df</span><span class=p>:</span> <span class=n>df</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s1>&#39;DOLocationID&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>())</span>
  <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>row</span><span class=p>:</span> <span class=n>f</span><span class=s2>&#34;{row.DOLocationID},{row.passenger_count}&#34;</span><span class=p>)</span>
  <span class=o>...</span></code></pre></div></div><p><a href=https://beam.apache.org/releases/pydoc/current/apache_beam.dataframe.transforms.html#apache_beam.dataframe.transforms.DataframeTransform><code>DataframeTransform</code></a> is similar to <a href=https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.sql.html#apache_beam.transforms.sql.SqlTransform><code>SqlTransform</code></a> from the <a href=https://beam.apache.org/documentation/dsls/sql/overview/>Beam SQL</a> DSL. Where <code>SqlTransform</code> translates a SQL query to a PTransform, <code>DataframeTransform</code> is a PTransform that applies a function that takes and returns DataFrames. A <code>DataframeTransform</code> can be particularly useful if you have a stand-alone function that can be called both on Beam and on ordinary Pandas DataFrames.</p><p><code>DataframeTransform</code> can accept and return multiple PCollections by name and by keyword, as shown in the following examples:</p><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=n>output</span> <span class=o>=</span> <span class=p>(</span><span class=n>pc1</span><span class=p>,</span> <span class=n>pc2</span><span class=p>)</span> <span class=o>|</span> <span class=n>DataframeTransform</span><span class=p>(</span><span class=k>lambda</span> <span class=n>df1</span><span class=p>,</span> <span class=n>df2</span><span class=p>:</span> <span class=o>...</span><span class=p>)</span>

<span class=n>output</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;a&#39;</span><span class=p>:</span> <span class=n>pc</span><span class=p>,</span> <span class=o>...</span><span class=p>}</span> <span class=o>|</span> <span class=n>DataframeTransform</span><span class=p>(</span><span class=k>lambda</span> <span class=n>a</span><span class=p>,</span> <span class=o>...</span><span class=p>:</span> <span class=o>...</span><span class=p>)</span>

<span class=n>pc1</span><span class=p>,</span> <span class=n>pc2</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;a&#39;</span><span class=p>:</span> <span class=n>pc</span><span class=p>}</span> <span class=o>|</span> <span class=n>DataframeTransform</span><span class=p>(</span><span class=k>lambda</span> <span class=n>a</span><span class=p>:</span> <span class=n>expr1</span><span class=p>,</span> <span class=n>expr2</span><span class=p>)</span>

<span class=p>{</span><span class=o>...</span><span class=p>}</span> <span class=o>=</span> <span class=p>{</span><span class=n>a</span><span class=p>:</span> <span class=n>pc</span><span class=p>}</span> <span class=o>|</span> <span class=n>DataframeTransform</span><span class=p>(</span><span class=k>lambda</span> <span class=n>a</span><span class=p>:</span> <span class=p>{</span><span class=o>...</span><span class=p>})</span></code></pre></div></div><h2 id=differences_from_standard_pandas>Differences from standard Pandas</h2><p>Beam DataFrames are deferred, like the rest of the Beam API. As a result, there are some limitations on what you can do with Beam DataFrames, compared to the standard Pandas implementation:</p><ul><li>Because all operations are deferred, the result of a given operation may not be available for control flow. For example, you can compute a sum, but you can&rsquo;t branch on the result.</li><li>Result columns must be computable without access to the data. For example, you can’t use <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transpose.html>transpose</a>.</li><li>PCollections in Beam are inherently unordered, so Pandas operations that are sensitive to the ordering of rows are unsupported. For example, order-sensitive operations such as <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html>shift</a>, <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.cummax.html>cummax</a>, <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.cummin.html>cummin</a>, <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html>head</a>, and <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail>tail</a> are not supported.</li></ul><p>With Beam DataFrames, computation doesn’t take place until the pipeline runs. Before that, only the shape or schema of the result is known, meaning that you can work with the names and types of the columns, but not the result data itself.</p><p>There are a few common exceptions you may see when attempting to use certain Pandas operations:</p><ul><li><strong>WontImplementError</strong>: Indicates that this operation or argument isn’t supported because it’s incompatible with the Beam model. The largest class of operations that raise this error are order-sensitive operations.</li><li><strong>NotImplementedError</strong>: Indicates this is an operation or argument that hasn’t been implemented yet. Many Pandas operations are already available through Beam DataFrames, but there’s still a long tail of unimplemented operations.</li><li><strong>NonParallelOperation</strong>: Indicates that you’re attempting a non-parallel operation outside of an <code>allow_non_parallel_operations</code> block. Some operations don&rsquo;t lend themselves to parallel computation. They can still be used, but must be guarded in a <code>with beam.dataframe.allow_non_parallel_operations(True)</code> block.</li></ul></div></div><footer class=footer><div class=footer__contained><div class=footer__cols><div class=footer__cols__col><div class=footer__cols__col__logo><img src=/images/beam_logo_circle.svg class=footer__logo alt="Beam logo"></div><div class=footer__cols__col__logo><img src=/images/apache_logo_circle.svg class=footer__logo alt="Apache logo"></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Start</div><div class=footer__cols__col__link><a href=/get-started/beam-overview/>Overview</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-java/>Quickstart (Java)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-py/>Quickstart (Python)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-go/>Quickstart (Go)</a></div><div class=footer__cols__col__link><a href=/get-started/downloads/>Downloads</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Docs</div><div class=footer__cols__col__link><a href=/documentation/programming-guide/>Concepts</a></div><div class=footer__cols__col__link><a href=/documentation/pipelines/design-your-pipeline/>Pipelines</a></div><div class=footer__cols__col__link><a href=/documentation/runners/capability-matrix/>Runners</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Community</div><div class=footer__cols__col__link><a href=/contribute/>Contribute</a></div><div class=footer__cols__col__link><a href=https://projects.apache.org/committee.html?beam target=_blank>Team<img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></div><div class=footer__cols__col__link><a href=/community/presentation-materials/>Media</a></div><div class=footer__cols__col__link><a href=/community/in-person/>Events/Meetups</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Resources</div><div class=footer__cols__col__link><a href=/blog/>Blog</a></div><div class=footer__cols__col__link><a href=/community/contact-us/>Contact Us</a></div><div class=footer__cols__col__link><a href=https://github.com/apache/beam>GitHub</a></div></div></div></div><div class=footer__bottom>&copy;
<a href=http://www.apache.org>The Apache Software Foundation</a>
| <a href=/privacy_policy>Privacy Policy</a>
| <a href=/feed.xml>RSS Feed</a><br><br>Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation. All other products or name brands are trademarks of their respective holders, including The Apache Software Foundation.</div></footer></body></html>