<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Apache Beam – Learn about Beam</title><link>/documentation/</link><description>Recent content in Learn about Beam on Apache Beam</description><generator>Hugo -- gohugo.io</generator><atom:link href="/documentation/index.xml" rel="self" type="application/rss+xml"/><item><title>Documentation: AI Platform integration patterns</title><link>/documentation/patterns/ai-platform/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/patterns/ai-platform/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="ai-platform-integration-patterns">AI Platform integration patterns&lt;/h1>
&lt;p>This page describes common patterns in pipelines with Google Cloud AI Platform transforms.&lt;/p>
&lt;nav class="language-switcher">
&lt;strong>Adapt for:&lt;/strong>
&lt;ul>
&lt;li data-type="language-java" class="active">Java SDK&lt;/li>
&lt;li data-type="language-py">Python SDK&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;h2 id="analysing-the-structure-and-meaning-of-text">Analysing the structure and meaning of text&lt;/h2>
&lt;p>This section shows how to use &lt;a href="https://cloud.google.com/natural-language">Google Cloud Natural Language API&lt;/a> to perform text analysis.&lt;/p>
&lt;p>Beam provides a PTransform called &lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.ml.gcp.naturallanguageml.html#apache_beam.ml.gcp.naturallanguageml.AnnotateText">AnnotateText&lt;/a>. The transform takes a PCollection of type &lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.ml.gcp.naturallanguageml.html#apache_beam.ml.gcp.naturallanguageml.Document">Document&lt;/a>. Each Document object contains various information about text. This includes the content, whether it is a plain text or HTML, an optional language hint and other settings.
&lt;code>AnnotateText&lt;/code> produces response object of type &lt;code>AnnotateTextResponse&lt;/code> returned from the API. &lt;code>AnnotateTextResponse&lt;/code> is a protobuf message which contains a lot of attributes, some of which are complex structures.&lt;/p>
&lt;p>Here is an example of a pipeline that creates in-memory PCollection of strings, changes each string to Document object and invokes Natural Language API. Then, for each response object, a function is called to extract certain results of analysis.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">features&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nlp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">types&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AnnotateTextRequest&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Features&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">extract_entities&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">extract_document_sentiment&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">extract_entity_sentiment&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">extract_syntax&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">responses&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="s1">&amp;#39;My experience so far has been fantastic! &amp;#39;&lt;/span>
&lt;span class="s1">&amp;#39;I&lt;/span>&lt;span class="se">\&amp;#39;&lt;/span>&lt;span class="s1">d really recommend this product.&amp;#39;&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">nlp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">type&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;PLAIN_TEXT&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">nlp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AnnotateText&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">features&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">responses&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">extract_sentiments&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Parse sentiments to JSON&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">json&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dumps&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Write sentiments&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WriteToText&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;sentiments.txt&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">responses&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">extract_entities&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Parse entities to JSON&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">json&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dumps&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Write entities&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WriteToText&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;entities.txt&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">responses&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">analyze_dependency_tree&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Parse adjacency list to JSON&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">json&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dumps&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Write adjacency list&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WriteToText&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;adjancency_list.txt&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">AnnotateTextRequest&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Features&lt;/span> &lt;span class="n">features&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">AnnotateTextRequest&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Features&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">newBuilder&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setExtractEntities&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setExtractDocumentSentiment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setExtractEntitySentiment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setExtractSyntax&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">AnnotateText&lt;/span> &lt;span class="n">annotateText&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">AnnotateText&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">newBuilder&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setFeatures&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">features&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">AnnotateTextResponse&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">responses&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;My experience so far has been fantastic, &amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;I\&amp;#39;d really recommend this product.&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">SerializableFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Document&lt;/span>&lt;span class="o">&amp;gt;)&lt;/span>
&lt;span class="n">input&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span>
&lt;span class="n">Document&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">newBuilder&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setContent&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">input&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Document&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Type&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">PLAIN_TEXT&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">()))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">annotateText&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">responses&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TextSentiments&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">extractSentiments&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">strings&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">((&lt;/span>&lt;span class="n">SerializableFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">TextSentiments&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;)&lt;/span> &lt;span class="n">TextSentiments&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">toJson&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;sentiments.txt&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">responses&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">maps&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">strings&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">strings&lt;/span>&lt;span class="o">()))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">extractEntities&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">strings&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mapEntitiesToJson&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;entities.txt&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">responses&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">lists&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">maps&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">strings&lt;/span>&lt;span class="o">(),&lt;/span>
&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">lists&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">strings&lt;/span>&lt;span class="o">()))))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">analyzeDependencyTree&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">strings&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mapDependencyTreesToJson&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;adjacency_list.txt&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="extracting-sentiments">Extracting sentiments&lt;/h3>
&lt;p>This is a part of response object returned from the API. Sentence-level sentiments can be found in &lt;code>sentences&lt;/code> attribute. &lt;code>sentences&lt;/code> behaves like a standard Python sequence, therefore all core language features (like iteration or slicing) will work. Overall sentiment can be found in &lt;code>document_sentiment&lt;/code> attribute.&lt;/p>
&lt;pre>&lt;code>sentences {
text {
content: &amp;quot;My experience so far has been fantastic!&amp;quot;
}
sentiment {
magnitude: 0.8999999761581421
score: 0.8999999761581421
}
}
sentences {
text {
content: &amp;quot;I\'d really recommend this product.&amp;quot;
begin_offset: 41
}
sentiment {
magnitude: 0.8999999761581421
score: 0.8999999761581421
}
}
...many lines omitted
document_sentiment {
magnitude: 1.899999976158142
score: 0.8999999761581421
}
&lt;/code>&lt;/pre>&lt;p>The function for extracting information about sentence-level and document-level sentiments is shown in the next code snippet.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">return&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;sentences&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[{&lt;/span>
&lt;span class="n">sentence&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">sentence&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sentiment&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">score&lt;/span>
&lt;span class="p">}&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">sentence&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sentences&lt;/span>&lt;span class="p">],&lt;/span>
&lt;span class="s1">&amp;#39;document_sentiment&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">document_sentiment&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">score&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">extractSentiments&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">SerializableFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">AnnotateTextResponse&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">TextSentiments&lt;/span>&lt;span class="o">&amp;gt;)&lt;/span>
&lt;span class="n">annotateTextResponse&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">TextSentiments&lt;/span> &lt;span class="n">sentiments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TextSentiments&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">sentiments&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setDocumentSentiment&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">annotateTextResponse&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getDocumentSentiment&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getMagnitude&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Float&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">sentenceSentimentsMap&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">annotateTextResponse&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getSentencesList&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">stream&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">collect&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Collectors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toMap&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">Sentence&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getText&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getContent&lt;/span>&lt;span class="o">(),&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">Sentence&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getSentiment&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getMagnitude&lt;/span>&lt;span class="o">()));&lt;/span>
&lt;span class="n">sentiments&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setSentenceSentiments&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">sentenceSentimentsMap&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">sentiments&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">};&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The snippet loops over &lt;code>sentences&lt;/code> and, for each sentence, extracts the sentiment score.&lt;/p>
&lt;p>The output is:&lt;/p>
&lt;pre>&lt;code>{&amp;quot;sentences&amp;quot;: [{&amp;quot;My experience so far has been fantastic!&amp;quot;: 0.8999999761581421}, {&amp;quot;I'd really recommend this product.&amp;quot;: 0.8999999761581421}], &amp;quot;document_sentiment&amp;quot;: 0.8999999761581421}
&lt;/code>&lt;/pre>&lt;h3 id="extracting-entities">Extracting entities&lt;/h3>
&lt;p>The next function inspects the response for entities and returns the names and the types of those entities.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">return&lt;/span> &lt;span class="p">[{&lt;/span>
&lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">entity&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;type&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">nlp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">enums&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Entity&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">entity&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">type&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">}&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">entity&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">entities&lt;/span>&lt;span class="p">]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">extractEntities&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">SerializableFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">AnnotateTextResponse&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;)&lt;/span>
&lt;span class="n">annotateTextResponse&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span>
&lt;span class="n">annotateTextResponse&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getEntitiesList&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">stream&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">collect&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Collectors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toMap&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Entity&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">getName&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Entity&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getType&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">()));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Entities can be found in &lt;code>entities&lt;/code> attribute. Just like before, &lt;code>entities&lt;/code> is a sequence, that&amp;rsquo;s why list comprehension is a viable choice. The most tricky part is interpreting the types of entities. Natural Language API defines entity types as enum. In a response object, entity types are returned as integers. That&amp;rsquo;s why a user has to instantiate &lt;code>naturallanguageml.enums.Entity.Type&lt;/code> to access a human-readable name.&lt;/p>
&lt;p>The output is:&lt;/p>
&lt;pre>&lt;code>[{&amp;quot;name&amp;quot;: &amp;quot;experience&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;OTHER&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;product&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;CONSUMER_GOOD&amp;quot;}]
&lt;/code>&lt;/pre>&lt;h3 id="accessing-sentence-dependency-tree">Accessing sentence dependency tree&lt;/h3>
&lt;p>The following code loops over the sentences and, for each sentence, builds an adjacency list that represents a dependency tree. For more information on what dependency tree is, see &lt;a href="https://cloud.google.com/natural-language/docs/morphology#dependency_trees">Morphology &amp;amp; Dependency Trees&lt;/a>.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">from&lt;/span> &lt;span class="nn">collections&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">defaultdict&lt;/span>
&lt;span class="n">adjacency_lists&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="n">index&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">sentence&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sentences&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">adjacency_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">defaultdict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">list&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">sentence_begin&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sentence&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">begin_offset&lt;/span>
&lt;span class="n">sentence_end&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sentence_begin&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sentence&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;span class="k">while&lt;/span> &lt;span class="n">index&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tokens&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="ow">and&lt;/span> \
&lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tokens&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">begin_offset&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">sentence_end&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">token&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tokens&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">head_token_index&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">token&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dependency_edge&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">head_token_index&lt;/span>
&lt;span class="n">head_token_text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tokens&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">head_token_index&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">content&lt;/span>
&lt;span class="n">adjacency_list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">head_token_text&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">token&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">index&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;span class="n">adjacency_lists&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">adjacency_list&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">analyzeDependencyTree&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">SerializableFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">AnnotateTextResponse&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&amp;gt;)&lt;/span>
&lt;span class="n">response&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">adjacencyLists&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">ArrayList&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;();&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">index&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Sentence&lt;/span> &lt;span class="n">s&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getSentencesList&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">adjacencyMap&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HashMap&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;();&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">sentenceBegin&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getText&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getBeginOffset&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">sentenceEnd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sentenceBegin&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getText&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getContent&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">length&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">1&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">while&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">index&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getTokensCount&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getTokens&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">getText&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getBeginOffset&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">sentenceEnd&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Token&lt;/span> &lt;span class="n">token&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getTokensList&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">headTokenIndex&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">token&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getDependencyEdge&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getHeadTokenIndex&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">headTokenContent&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">response&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getTokens&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">headTokenIndex&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">getText&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getContent&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">adjacencyList&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">adjacencyMap&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getOrDefault&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">headTokenContent&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">ArrayList&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;());&lt;/span>
&lt;span class="n">adjacencyList&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">token&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getText&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getContent&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">adjacencyMap&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">put&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">headTokenContent&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">adjacencyList&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">index&lt;/span>&lt;span class="o">++;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">adjacencyLists&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">adjacencyMap&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">adjacencyLists&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">};&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The output is below. For better readability, indexes are replaced by text which they refer to:&lt;/p>
&lt;pre>&lt;code>[
{
&amp;quot;experience&amp;quot;: [
&amp;quot;My&amp;quot;
],
&amp;quot;been&amp;quot;: [
&amp;quot;experience&amp;quot;,
&amp;quot;far&amp;quot;,
&amp;quot;has&amp;quot;,
&amp;quot;been&amp;quot;,
&amp;quot;fantastic&amp;quot;,
&amp;quot;!&amp;quot;
],
&amp;quot;far&amp;quot;: [
&amp;quot;so&amp;quot;
]
},
{
&amp;quot;recommend&amp;quot;: [
&amp;quot;I&amp;quot;,
&amp;quot;'d&amp;quot;,
&amp;quot;really&amp;quot;,
&amp;quot;recommend&amp;quot;,
&amp;quot;product&amp;quot;,
&amp;quot;.&amp;quot;
],
&amp;quot;product&amp;quot;: [
&amp;quot;this&amp;quot;
]
}
]
&lt;/code>&lt;/pre>&lt;h2 id="getting-predictions">Getting predictions&lt;/h2>
&lt;p>This section shows how to use &lt;a href="https://cloud.google.com/ai-platform/prediction/docs/overview">Google Cloud AI Platform Prediction&lt;/a> to make predictions about new data from a cloud-hosted machine learning model.&lt;/p>
&lt;p>&lt;a href="https://github.com/tensorflow/tfx-bsl">tfx_bsl&lt;/a> is a library with a Beam PTransform called &lt;code>RunInference&lt;/code>. &lt;code>RunInference&lt;/code> is able to perform an inference that can use an external service endpoint for receiving data. When using a service endpoint, the transform takes a PCollection of type &lt;code>tf.train.Example&lt;/code> and, for every batch of elements, sends a request to AI Platform Prediction. The size of a batch is automatically computed. For more details on how Beam finds the best batch size, refer to a docstring for &lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html?highlight=batchelements#apache_beam.transforms.util.BatchElements">BatchElements&lt;/a>. Currently, the transform does not support using &lt;code>tf.train.SequenceExample&lt;/code> as input, but the work is in progress.&lt;/p>
&lt;p>The transform produces a PCollection of type &lt;code>PredictionLog&lt;/code>, which contains predictions.&lt;/p>
&lt;p>Before getting started, deploy a TensorFlow model to AI Platform Prediction. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Do note that only TensorFlow models are supported by the transform. For more information, see &lt;a href="https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction">Exporting a SavedModel for prediction&lt;/a>.&lt;/p>
&lt;p>Once a machine learning model is deployed, prepare a list of instances to get predictions for. To send binary data, make sure that the name of an input ends in &lt;code>_bytes&lt;/code>. This will base64-encode data before sending a request.&lt;/p>
&lt;h3 id="example">Example&lt;/h3>
&lt;p>Here is an example of a pipeline that reads input instances from the file, converts JSON objects to &lt;code>tf.train.Example&lt;/code> objects and sends data to AI Platform Prediction. The content of a file can look like this:&lt;/p>
&lt;pre>&lt;code>{&amp;quot;input&amp;quot;: &amp;quot;the quick brown&amp;quot;}
{&amp;quot;input&amp;quot;: &amp;quot;la bruja le&amp;quot;}
&lt;/code>&lt;/pre>&lt;p>The example creates &lt;code>tf.train.BytesList&lt;/code> instances, thus it expects byte-like strings as input. However, other data types, like &lt;code>tf.train.FloatList&lt;/code> and &lt;code>tf.train.Int64List&lt;/code>, are also supported by the transform.&lt;/p>
&lt;p>Here is the code:&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">json&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">tfx_bsl.beam.run_inference&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">RunInference&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">tfx_bsl.proto&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">model_spec_pb2&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">convert_json_to_tf_example&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">json_obj&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">samples&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">json&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loads&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">json_obj&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">text&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">samples&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="n">value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Feature&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bytes_list&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BytesList&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;utf-8&amp;#39;&lt;/span>&lt;span class="p">)]))&lt;/span>
&lt;span class="n">feature&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">value&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Example&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">features&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Features&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">feature&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">feature&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ReadFromText&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;gs://my-bucket/samples.json&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">convert_json_to_tf_example&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">RunInference&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">model_spec_pb2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">InferenceEndpoint&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">model_endpoint_spec&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">model_spec_pb2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AIPlatformPredictionModelSpec&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">project_id&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;my-project-id&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">model_name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;my-model-name&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">version_name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;my-model-version&amp;#39;&lt;/span>&lt;span class="p">))))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">//&lt;/span> &lt;span class="n">Getting&lt;/span> &lt;span class="n">predictions&lt;/span> &lt;span class="n">is&lt;/span> &lt;span class="n">not&lt;/span> &lt;span class="n">yet&lt;/span> &lt;span class="n">available&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">Java&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="o">[&lt;/span>&lt;span class="n">BEAM&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">9501&lt;/span>&lt;span class="o">]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div></description></item><item><title>Documentation: Apache Beam: Developing I/O connectors for Java</title><link>/documentation/io/developing-io-java/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/io/developing-io-java/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="developing-io-connectors-for-java">Developing I/O connectors for Java&lt;/h1>
&lt;p>To connect to a data store that isn’t supported by Beam’s existing I/O
connectors, you must create a custom I/O connector that usually consist of a
source and a sink. All Beam sources and sinks are composite transforms; however,
the implementation of your custom I/O depends on your use case. Before you
start, read the
&lt;a href="/documentation/io/developing-io-overview/">new I/O connector overview&lt;/a>
for an overview of developing a new I/O connector, the available implementation
options, and how to choose the right option for your use case.&lt;/p>
&lt;p>This guide covers using the &lt;code>Source&lt;/code> and &lt;code>FileBasedSink&lt;/code> interfaces using Java.
The Python SDK offers the same functionality, but uses a slightly different API.
See &lt;a href="/documentation/io/developing-io-python/">Developing I/O connectors for Python&lt;/a>
for information specific to the Python SDK.&lt;/p>
&lt;h2 id="basic-code-reqs">Basic code requirements&lt;/h2>
&lt;p>Beam runners use the classes you provide to read and/or write data using
multiple worker instances in parallel. As such, the code you provide for
&lt;code>Source&lt;/code> and &lt;code>FileBasedSink&lt;/code> subclasses must meet some basic requirements:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Serializability:&lt;/strong> Your &lt;code>Source&lt;/code> or &lt;code>FileBasedSink&lt;/code> subclass, whether
bounded or unbounded, must be Serializable. A runner might create multiple
instances of your &lt;code>Source&lt;/code> or &lt;code>FileBasedSink&lt;/code> subclass to be sent to
multiple remote workers to facilitate reading or writing in parallel.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Immutability:&lt;/strong>
Your &lt;code>Source&lt;/code> or &lt;code>FileBasedSink&lt;/code> subclass must be effectively immutable.
All private fields must be declared final, and all private variables of
collection type must be effectively immutable. If your class has setter
methods, those methods must return an independent copy of the object with
the relevant field modified.&lt;/p>
&lt;p>You should only use mutable state in your &lt;code>Source&lt;/code> or &lt;code>FileBasedSink&lt;/code>
subclass if you are using lazy evaluation of expensive computations that
you need to implement the source or sink; in that case, you must declare
all mutable instance variables transient.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Thread-Safety:&lt;/strong> Your code must be thread-safe. If you build your source
to work with dynamic work rebalancing, it is critical that you make your
code thread-safe. The Beam SDK provides a helper class to make this easier.
See &lt;a href="#bounded-dynamic">Using Your BoundedSource with dynamic work rebalancing&lt;/a>
for more details.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Testability:&lt;/strong> It is critical to exhaustively unit test all of your
&lt;code>Source&lt;/code> and &lt;code>FileBasedSink&lt;/code> subclasses, especially if you build your
classes to work with advanced features such as dynamic work rebalancing. A
minor implementation error can lead to data corruption or data loss (such
as skipping or duplicating records) that can be hard to detect.&lt;/p>
&lt;p>To assist in testing &lt;code>BoundedSource&lt;/code> implementations, you can use the
SourceTestUtils class. &lt;code>SourceTestUtils&lt;/code> contains utilities for automatically
verifying some of the properties of your &lt;code>BoundedSource&lt;/code> implementation. You
can use &lt;code>SourceTestUtils&lt;/code> to increase your implementation&amp;rsquo;s test coverage
using a wide range of inputs with relatively few lines of code. For
examples that use &lt;code>SourceTestUtils&lt;/code>, see the
&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/core/src/test/java/org/apache/beam/sdk/io/AvroSourceTest.java">AvroSourceTest&lt;/a> and
&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/core/src/test/java/org/apache/beam/sdk/io/TextIOReadTest.java">TextIOReadTest&lt;/a>
source code.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>In addition, see the &lt;a href="/contribute/ptransform-style-guide/">PTransform style guide&lt;/a>
for Beam&amp;rsquo;s transform style guidance.&lt;/p>
&lt;h2 id="implementing-the-source-interface">Implementing the Source interface&lt;/h2>
&lt;p>To create a data source for your pipeline, you must provide the format-specific
logic that tells a runner how to read data from your input source, and how to
split your data source into multiple parts so that multiple worker instances can
read your data in parallel. If you&amp;rsquo;re creating a data source that reads
unbounded data, you must provide additional logic for managing your source&amp;rsquo;s
watermark and optional checkpointing.&lt;/p>
&lt;p>Supply the logic for your source by creating the following classes:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>A subclass of &lt;code>BoundedSource&lt;/code> if you want to read a finite (batch) data set,
or a subclass of &lt;code>UnboundedSource&lt;/code> if you want to read an infinite (streaming)
data set. These subclasses describe the data you want to read, including the
data&amp;rsquo;s location and parameters (such as how much data to read).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A subclass of &lt;code>Source.Reader&lt;/code>. Each Source must have an associated Reader that
captures all the state involved in reading from that &lt;code>Source&lt;/code>. This can
include things like file handles, RPC connections, and other parameters that
depend on the specific requirements of the data format you want to read.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;code>Reader&lt;/code> class hierarchy mirrors the Source hierarchy. If you&amp;rsquo;re extending
&lt;code>BoundedSource&lt;/code>, you&amp;rsquo;ll need to provide an associated &lt;code>BoundedReader&lt;/code>. if you&amp;rsquo;re
extending &lt;code>UnboundedSource&lt;/code>, you&amp;rsquo;ll need to provide an associated
&lt;code>UnboundedReader&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>One or more user-facing wrapper composite transforms (&lt;code>PTransform&lt;/code>) that
wrap read operations. &lt;a href="#ptransform-wrappers">PTransform wrappers&lt;/a> discusses
why you should avoid exposing your sources.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="implementing-the-source-subclass">Implementing the Source subclass&lt;/h3>
&lt;p>You must create a subclass of either &lt;code>BoundedSource&lt;/code> or &lt;code>UnboundedSource&lt;/code>,
depending on whether your data is a finite batch or an infinite stream. In
either case, your &lt;code>Source&lt;/code> subclass must override the abstract methods in the
superclass. A runner might call these methods when using your data source. For
example, when reading from a bounded source, a runner uses these methods to
estimate the size of your data set and to split it up for parallel reading.&lt;/p>
&lt;p>Your &lt;code>Source&lt;/code> subclass should also manage basic information about your data
source, such as the location. For example, the example &lt;code>Source&lt;/code> implementation
in Beam’s &lt;a href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/io/gcp/datastore/DatastoreIO.html">DatastoreIO&lt;/a>
class takes host, datasetID, and query as arguments. The connector uses these
values to obtain data from Cloud Datastore.&lt;/p>
&lt;h4 id="boundedsource">BoundedSource&lt;/h4>
&lt;p>&lt;code>BoundedSource&lt;/code> represents a finite data set from which a Beam runner may read,
possibly in parallel. &lt;code>BoundedSource&lt;/code> contains a set of abstract methods that
the runner uses to split the data set for reading by multiple workers.&lt;/p>
&lt;p>To implement a &lt;code>BoundedSource&lt;/code>, your subclass must override the following
abstract methods:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>split&lt;/code>: The runner uses this method to split your finite data
into bundles of a given size.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>getEstimatedSizeBytes&lt;/code>: The runner uses this method to estimate the total
size of your data, in bytes.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>createReader&lt;/code>: Creates the associated &lt;code>BoundedReader&lt;/code> for this
&lt;code>BoundedSource&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>You can see a model of how to implement &lt;code>BoundedSource&lt;/code> and the required
abstract methods in Beam’s implementations for Cloud BigTable
(&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigtable/BigtableIO.java">BigtableIO.java&lt;/a>)
and BigQuery (&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQuerySourceBase.java">BigQuerySourceBase.java&lt;/a>).&lt;/p>
&lt;h4 id="unboundedsource">UnboundedSource&lt;/h4>
&lt;p>&lt;code>UnboundedSource&lt;/code> represents an infinite data stream from which the runner may
read, possibly in parallel. &lt;code>UnboundedSource&lt;/code> contains a set of abstract methods
that the runner uses to support streaming reads in parallel; these include
&lt;em>checkpointing&lt;/em> for failure recovery, &lt;em>record IDs&lt;/em> to prevent data duplication,
and &lt;em>watermarking&lt;/em> for estimating data completeness in downstream parts of your
pipeline.&lt;/p>
&lt;p>To implement an &lt;code>UnboundedSource&lt;/code>, your subclass must override the following
abstract methods:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>split&lt;/code>: The runner uses this method to generate a list of
&lt;code>UnboundedSource&lt;/code> objects which represent the number of sub-stream instances
from which the service should read in parallel.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>getCheckpointMarkCoder&lt;/code>: The runner uses this method to obtain the Coder for
the checkpoints for your source (if any).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>requiresDeduping&lt;/code>: The runner uses this method to determine whether the data
requires explicit removal of duplicate records. If this method returns true,
the runner will automatically insert a step to remove duplicates from your
source&amp;rsquo;s output. This should return true if and only if your source
provides record IDs for each record. See &lt;code>UnboundedReader.getCurrentRecordId&lt;/code>
for when this should be done.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>createReader&lt;/code>: Creates the associated &lt;code>UnboundedReader&lt;/code> for this
&lt;code>UnboundedSource&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="implementing-the-reader-subclass">Implementing the Reader subclass&lt;/h3>
&lt;p>You must create a subclass of either &lt;code>BoundedReader&lt;/code> or &lt;code>UnboundedReader&lt;/code> to be
returned by your source subclass&amp;rsquo;s &lt;code>createReader&lt;/code> method. The runner uses the
methods in your &lt;code>Reader&lt;/code> (whether bounded or unbounded) to do the actual reading
of your dataset.&lt;/p>
&lt;p>&lt;code>BoundedReader&lt;/code> and &lt;code>UnboundedReader&lt;/code> have similar basic interfaces, which
you&amp;rsquo;ll need to define. In addition, there are some additional methods unique to
&lt;code>UnboundedReader&lt;/code> that you&amp;rsquo;ll need to implement for working with unbounded data,
and an optional method you can implement if you want your &lt;code>BoundedReader&lt;/code> to
take advantage of dynamic work rebalancing. There are also minor differences in
the semantics for the &lt;code>start()&lt;/code> and &lt;code>advance()&lt;/code> methods when using
&lt;code>UnboundedReader&lt;/code>.&lt;/p>
&lt;h4 id="reader-methods-common-to-both-boundedreader-and-unboundedreader">Reader methods common to both BoundedReader and UnboundedReader&lt;/h4>
&lt;p>A runner uses the following methods to read data using &lt;code>BoundedReader&lt;/code> or
&lt;code>UnboundedReader&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>start&lt;/code>: Initializes the &lt;code>Reader&lt;/code> and advances to the first record to be read.
This method is called exactly once when the runner begins reading your data,
and is a good place to put expensive operations needed for initialization.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>advance&lt;/code>: Advances the reader to the next valid record. This method must
return false if there is no more input available. &lt;code>BoundedReader&lt;/code> should stop
reading once advance returns false, but &lt;code>UnboundedReader&lt;/code> can return true in
future calls once more data is available from your stream.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>getCurrent&lt;/code>: Returns the data record at the current position, last read by
start or advance.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>getCurrentTimestamp&lt;/code>: Returns the timestamp for the current data record. You
only need to override &lt;code>getCurrentTimestamp&lt;/code> if your source reads data that has
intrinsic timestamps. The runner uses this value to set the intrinsic
timestamp for each element in the resulting output &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="reader-methods-unique-to-unboundedreader">Reader methods unique to UnboundedReader&lt;/h4>
&lt;p>In addition to the basic &lt;code>Reader&lt;/code> interface, &lt;code>UnboundedReader&lt;/code> has some
additional methods for managing reads from an unbounded data source:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>getCurrentRecordId&lt;/code>: Returns a unique identifier for the current record.
The runner uses these record IDs to filter out duplicate records. If your
data has logical IDs present in each record, you can have this method return
them; otherwise, you can return a hash of the record contents, using at
least a 128-bit hash. It is incorrect to use Java&amp;rsquo;s &lt;code>Object.hashCode()&lt;/code>, as
a 32-bit hash is generally insufficient for preventing collisions, and
&lt;code>hasCode()&lt;/code> is not guaranteed to be stable across processes.&lt;/p>
&lt;p>Implementing &lt;code>getCurrentRecordId&lt;/code> is optional if your source uses a
checkpointing scheme that uniquely identifies each record. For example, if
your splits are files and the checkpoints are file positions up to which all
data has been read, you do not need record IDs. However, record IDs can
still be useful if upstream systems writing data to your source occasionally
produce duplicate records that your source might then read.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>getWatermark&lt;/code>: Returns a watermark that your &lt;code>Reader&lt;/code> provides. The watermark
is the approximate lower bound on timestamps of future elements to be read
by your &lt;code>Reader&lt;/code>. The runner uses the watermark as an estimate of data
completeness. Watermarks are used in windowing and triggers.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>getCheckpointMark&lt;/code>: The runner uses this method to create a checkpoint in
your data stream. The checkpoint represents the progress of the
&lt;code>UnboundedReader&lt;/code>, which can be used for failure recovery. Different data
streams may use different checkpointing methods; some sources might require
received records to be acknowledged, while others might use positional
checkpointing. You&amp;rsquo;ll need to tailor this method to the most appropriate
checkpointing scheme. For example, you might have this method return the
most recently acked record(s).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>getCheckpointMark&lt;/code> is optional; you don&amp;rsquo;t need to implement it if your data
does not have meaningful checkpoints. However, if you choose not to
implement checkpointing in your source, you may encounter duplicate data or
data loss in your pipeline, depending on whether your data source tries to
re-send records in case of errors.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>You can read a bounded &lt;code>PCollection&lt;/code> from an &lt;code>UnboundedSource&lt;/code> by specifying
either &lt;code>.withMaxNumRecords&lt;/code> or &lt;code>.withMaxReadTime&lt;/code> when you read from your
source. &lt;code>.withMaxNumRecords&lt;/code> reads a fixed maximum number of records from your
unbounded source, while &lt;code>.withMaxReadTime&lt;/code> reads from your unbounded source for
a fixed maximum time duration.&lt;/p>
&lt;h4 id="bounded-dynamic">Using your BoundedSource with dynamic work rebalancing&lt;/h4>
&lt;p>If your source provides bounded data, you can have your &lt;code>BoundedReader&lt;/code> work
with dynamic work rebalancing by implementing the method &lt;code>splitAtFraction&lt;/code>. The
runner may call &lt;code>splitAtFraction&lt;/code> concurrently with start or advance on a given
reader so that the remaining data in your &lt;code>Source&lt;/code> can be split and
redistributed to other workers.&lt;/p>
&lt;p>When you implement &lt;code>splitAtFraction&lt;/code>, your code must produce a
mutually-exclusive set of splits where the union of those splits matches the
total data set.&lt;/p>
&lt;p>If you implement &lt;code>splitAtFraction&lt;/code>, you must implement both &lt;code>splitAtFraction&lt;/code>
and &lt;code>getFractionConsumed&lt;/code> in a thread-safe manner, or data loss is possible. You
should also unit-test your implementation exhaustively to avoid data duplication
or data loss.&lt;/p>
&lt;p>To ensure that your code is thread-safe, use the &lt;code>RangeTracker&lt;/code> thread-safe
helper object to manage positions in your data source when implementing
&lt;code>splitAtFraction&lt;/code> and &lt;code>getFractionConsumed&lt;/code>.&lt;/p>
&lt;p>We highly recommended that you unit test your implementations of
&lt;code>splitAtFraction&lt;/code> using the &lt;code>SourceTestUtils&lt;/code> class. &lt;code>SourceTestUtils&lt;/code> contains
a number of methods for testing your implementation of &lt;code>splitAtFraction&lt;/code>,
including exhaustive automatic testing.&lt;/p>
&lt;h3 id="convenience-source-and-reader-base-classes">Convenience Source and Reader base classes&lt;/h3>
&lt;p>The Beam SDK contains some convenient abstract base classes to help you create
&lt;code>Source&lt;/code> and &lt;code>Reader&lt;/code> classes that work with common data storage formats, like
files.&lt;/p>
&lt;h4 id="filebasedsource">FileBasedSource&lt;/h4>
&lt;p>If your data source uses files, you can derive your &lt;code>Source&lt;/code> and &lt;code>Reader&lt;/code>
classes from the &lt;code>FileBasedSource&lt;/code> and &lt;code>FileBasedReader&lt;/code> abstract base classes.
&lt;code>FileBasedSource&lt;/code> is a bounded source subclass that implements code common to
Beam sources that interact with files, including:&lt;/p>
&lt;ul>
&lt;li>File pattern expansion&lt;/li>
&lt;li>Sequential record reading&lt;/li>
&lt;li>Split points&lt;/li>
&lt;/ul>
&lt;h2 id="using-filebasedsink">Using the FileBasedSink abstraction&lt;/h2>
&lt;p>If your data source uses files, you can implement the &lt;code>FileBasedSink&lt;/code>
abstraction to create a file-based sink. For other sinks, use &lt;code>ParDo&lt;/code>,
&lt;code>GroupByKey&lt;/code>, and other transforms offered by the Beam SDK for Java. See the
&lt;a href="/documentation/io/developing-io-overview/">developing I/O connectors overview&lt;/a>
for more details.&lt;/p>
&lt;p>When using the &lt;code>FileBasedSink&lt;/code> interface, you must provide the format-specific
logic that tells the runner how to write bounded data from your pipeline&amp;rsquo;s
&lt;code>PCollection&lt;/code>s to an output sink. The runner writes bundles of data in parallel
using multiple workers.&lt;/p>
&lt;p>Supply the logic for your file-based sink by implementing the following classes:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>A subclass of the abstract base class &lt;code>FileBasedSink&lt;/code>. &lt;code>FileBasedSink&lt;/code>
describes a location or resource that your pipeline can write to in
parallel. To avoid exposing your sink to end-users, your &lt;code>FileBasedSink&lt;/code>
subclass should be protected or private.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A user-facing wrapper &lt;code>PTransform&lt;/code> that, as part of the logic, calls
&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/io/WriteFiles.java">WriteFiles&lt;/a>
and passes your &lt;code>FileBasedSink&lt;/code> as a parameter. A user should not need to
call &lt;code>WriteFiles&lt;/code> directly.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>The &lt;code>FileBasedSink&lt;/code> abstract base class implements code that is common to Beam
sinks that interact with files, including:&lt;/p>
&lt;ul>
&lt;li>Setting file headers and footers&lt;/li>
&lt;li>Sequential record writing&lt;/li>
&lt;li>Setting the output MIME type&lt;/li>
&lt;/ul>
&lt;p>&lt;code>FileBasedSink&lt;/code> and its subclasses support writing files to any Beam-supported
&lt;code>FileSystem&lt;/code> implementations. See the following Beam-provided &lt;code>FileBasedSink&lt;/code>
implementations for examples:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/io/TextSink.java">TextSink&lt;/a> and&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/io/AvroSink.java">AvroSink&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h2 id="ptransform-wrappers">PTransform wrappers&lt;/h2>
&lt;p>When you create a source or sink that end-users will use, avoid exposing your
source or sink code. To avoid exposing your sources and sinks to end-users, your
new classes should be protected or private. Then, implement a user-facing
wrapper &lt;code>PTransform&lt;/code>. By exposing your source or sink as a transform, your
implementation is hidden and can be arbitrarily complex or simple. The greatest
benefit of not exposing implementation details is that later on, you can add
additional functionality without breaking the existing implementation for users.&lt;/p>
&lt;p>For example, if your users’ pipelines read from your source using
&lt;code>read&lt;/code> and you want to insert a reshard into the pipeline, all
users would need to add the reshard themselves (using the &lt;code>GroupByKey&lt;/code>
transform). To solve this, we recommended that you expose the source as a
composite &lt;code>PTransform&lt;/code> that performs both the read operation and the reshard.&lt;/p>
&lt;p>See Beam’s &lt;a href="/contribute/ptransform-style-guide/#exposing-a-ptransform-vs-something-else">PTransform style guide&lt;/a>
for additional information about wrapping with a &lt;code>PTransform&lt;/code>.&lt;/p></description></item><item><title>Documentation: Apache Beam: Developing I/O connectors for Python</title><link>/documentation/io/developing-io-python/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/io/developing-io-python/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="developing-io-connectors-for-python">Developing I/O connectors for Python&lt;/h1>
&lt;p>To connect to a data store that isn’t supported by Beam’s existing I/O
connectors, you must create a custom I/O connector that usually consist of a
source and a sink. All Beam sources and sinks are composite transforms; however,
the implementation of your custom I/O depends on your use case. Before you
start, read the &lt;a href="/documentation/io/developing-io-overview/">new I/O connector overview&lt;/a>
for an overview of developing a new I/O connector, the available implementation
options, and how to choose the right option for your use case.&lt;/p>
&lt;p>This guide covers using the &lt;a href="https://beam.apache.org/releases/pydoc/2.24.0/apache_beam.io.iobase.html">Source and FileBasedSink interfaces&lt;/a>
for Python. The Java SDK offers the same functionality, but uses a slightly
different API. See &lt;a href="/documentation/io/developing-io-java/">Developing I/O connectors for Java&lt;/a>
for information specific to the Java SDK.&lt;/p>
&lt;h2 id="basic-code-reqs">Basic code requirements&lt;/h2>
&lt;p>Beam runners use the classes you provide to read and/or write data using
multiple worker instances in parallel. As such, the code you provide for
&lt;code>Source&lt;/code> and &lt;code>FileBasedSink&lt;/code> subclasses must meet some basic requirements:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Serializability:&lt;/strong> Your &lt;code>Source&lt;/code> or &lt;code>FileBasedSink&lt;/code> subclass must be
serializable. The service may create multiple instances of your &lt;code>Source&lt;/code>
or &lt;code>FileBasedSink&lt;/code> subclass to be sent to multiple remote workers to
facilitate reading or writing in parallel. The &lt;em>way&lt;/em> the source and sink
objects are serialized is runner specific.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Immutability:&lt;/strong> Your &lt;code>Source&lt;/code> or &lt;code>FileBasedSink&lt;/code> subclass must be
effectively immutable. You should only use mutable state in your &lt;code>Source&lt;/code>
or &lt;code>FileBasedSink&lt;/code> subclass if you are using lazy evaluation of expensive
computations that you need to implement the source.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Thread-Safety:&lt;/strong> Your code must be thread-safe. The Beam SDK for Python
provides the &lt;code>RangeTracker&lt;/code> class to make this easier.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Testability:&lt;/strong> It is critical to exhaustively unit-test all of your
&lt;code>Source&lt;/code> and &lt;code>FileBasedSink&lt;/code> subclasses. A minor implementation error can
lead to data corruption or data loss (such as skipping or duplicating
records) that can be hard to detect. You can use test harnesses and utility
methods available in the &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/source_test_utils.py">source_test_utils module&lt;/a>
to develop tests for your source.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>In addition, see the &lt;a href="/contribute/ptransform-style-guide/">PTransform style guide&lt;/a>
for Beam&amp;rsquo;s transform style guidance.&lt;/p>
&lt;h2 id="implementing-the-source-interface">Implementing the Source interface&lt;/h2>
&lt;p>To create a new data source for your pipeline, you&amp;rsquo;ll need to provide the format-specific logic that tells the service how to read data from your input source, and how to split your data source into multiple parts so that multiple worker instances can read your data in parallel.&lt;/p>
&lt;p>Supply the logic for your new source by creating the following classes:&lt;/p>
&lt;ul>
&lt;li>A subclass of &lt;code>BoundedSource&lt;/code>. &lt;code>BoundedSource&lt;/code> is a source that reads a
finite amount of input records. The class describes the data you want to
read, including the data&amp;rsquo;s location and parameters (such as how much data to
read).&lt;/li>
&lt;li>A subclass of &lt;code>RangeTracker&lt;/code>. &lt;code>RangeTracker&lt;/code> is a thread-safe object used to
manage a range for a given position type.&lt;/li>
&lt;li>One or more user-facing wrapper composite transforms (&lt;code>PTransform&lt;/code>) that
wrap read operations. &lt;a href="#ptransform-wrappers">PTransform wrappers&lt;/a> discusses
why you should avoid exposing your sources, and walks through how to create
a wrapper.&lt;/li>
&lt;/ul>
&lt;p>You can find these classes in the
&lt;a href="https://beam.apache.org/releases/pydoc/2.24.0/apache_beam.io.iobase.html">apache_beam.io.iobase module&lt;/a>.&lt;/p>
&lt;h3 id="implementing-the-boundedsource-subclass">Implementing the BoundedSource subclass&lt;/h3>
&lt;p>&lt;code>BoundedSource&lt;/code> represents a finite data set from which the service reads, possibly in parallel. &lt;code>BoundedSource&lt;/code> contains a set of methods that the service uses to split the data set for reading by multiple remote workers.&lt;/p>
&lt;p>To implement a &lt;code>BoundedSource&lt;/code>, your subclass must override the following methods:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>estimate_size&lt;/code>: Services use this method to estimate the &lt;em>total size&lt;/em> of your data, in bytes. This estimate is in terms of external storage size, before performing decompression or other processing.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>split&lt;/code>: Service use this method to split your finite data into bundles of a given size.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>get_range_tracker&lt;/code>: Services use this method to get the &lt;code>RangeTracker&lt;/code> for a given position range, and use the information to report progress and perform dynamic splitting of sources.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>read&lt;/code>: This method returns an iterator that reads data from the source, with respect to the boundaries defined by the given &lt;code>RangeTracker&lt;/code> object.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="implementing-the-rangetracker-subclass">Implementing the RangeTracker subclass&lt;/h3>
&lt;p>A &lt;code>RangeTracker&lt;/code> is a thread-safe object used to manage the current range and current position of the reader of a &lt;code>BoundedSource&lt;/code> and protect concurrent access to them.&lt;/p>
&lt;p>To implement a &lt;code>RangeTracker&lt;/code>, you should first familiarize yourself with the following definitions:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Position-based sources&lt;/strong> - A position-based source can be described by a range of positions of an ordered type, and the records read by the source can be described by positions of that type. For example, for a record within a file, the position can be the starting byte offset of the record. The position type for the record in this case is &lt;code>long&lt;/code>.&lt;/p>
&lt;p>The main requirement for position-based sources is &lt;strong>associativity&lt;/strong>: Reading records in position range &amp;lsquo;[A, B)&amp;rsquo; and records in position range &amp;lsquo;[B, C)&amp;rsquo; should give the same records as reading records in position range &amp;lsquo;[A, C)', where &amp;lsquo;A&amp;rsquo; &amp;lt;= &amp;lsquo;B&amp;rsquo; &amp;lt;= &amp;lsquo;C&amp;rsquo;. This property ensures that no matter how many arbitrary sub-ranges a range of positions is split into, the total set of records they describe stays the same.&lt;/p>
&lt;p>The other important property is how the source&amp;rsquo;s range relates to positions of records in the source. In many sources each record can be identified by a unique starting position. In this case:&lt;/p>
&lt;ul>
&lt;li>All records returned by a source &amp;lsquo;[A, B)&amp;rsquo; must have starting positions in this range.&lt;/li>
&lt;li>All but the last record should end within this range. The last record may or may not extend past the end of the range.&lt;/li>
&lt;li>Records must not overlap.&lt;/li>
&lt;/ul>
&lt;p>Such sources should define &amp;ldquo;read &amp;lsquo;[A, B)'&amp;rdquo; as &amp;ldquo;read from the first record starting at or after &amp;lsquo;A&amp;rsquo;, up to but not including the first record starting at or after &amp;lsquo;B&amp;rsquo;&amp;quot;.&lt;/p>
&lt;p>Some examples of such sources include reading lines or CSV from a text file, reading keys and values from a database, etc.&lt;/p>
&lt;p>The concept of &lt;em>split points&lt;/em> allows to extend the definitions for dealing with sources where some records cannot be identified by a unique starting position.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Split points&lt;/strong> - A split point describes a record that is the first one returned when reading the range from and including position &lt;strong>A&lt;/strong> up to infinity (i.e. [A, infinity)).&lt;/p>
&lt;p>Some sources may have records that are not directly addressable. For example, imagine a file format consisting of a sequence of compressed blocks. Each block can be assigned an offset, but records within the block cannot be directly addressed without decompressing the block. Let us refer to this hypothetical format as &lt;em>CBF (Compressed Blocks Format)&lt;/em>.&lt;/p>
&lt;p>Many such formats can still satisfy the associativity property. For example, in CBF, reading [A, B) can mean &amp;ldquo;read all the records in all blocks whose starting offset is in [A, B)&amp;quot;.&lt;/p>
&lt;p>To support such complex formats, Beam introduces the notion of &lt;em>split points&lt;/em>. A record is a split point if there exists a position &lt;strong>A&lt;/strong> such that the record is the first one to be returned when reading the range [A, infinity). In CBF, the only split points would be the first records in each block.&lt;/p>
&lt;p>Split points allow us to define the meaning of a record&amp;rsquo;s position and a source&amp;rsquo;s range in the following cases:&lt;/p>
&lt;ul>
&lt;li>For a record that is at a split point, its position is defined to be the largest &lt;strong>A&lt;/strong> such that reading a source with the range [A, infinity) returns this record.&lt;/li>
&lt;li>Positions of other records are only required to be non-decreasing.&lt;/li>
&lt;li>Reading the source [A, B) must return records starting from the first split point at or after &lt;strong>A&lt;/strong>, up to but not including the first split point at or after &lt;strong>B&lt;/strong>. In particular, this means that the first record returned by a source MUST always be a split point.&lt;/li>
&lt;li>Positions of split points must be unique.&lt;/li>
&lt;/ul>
&lt;p>As a result, for any decomposition of the full range of the source into position ranges, the total set of records will be the full set of records in the source, and each record will be read exactly once.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Consumed positions&lt;/strong> - Consumed positions refer to records that have been read.&lt;/p>
&lt;p>As the source is being read, and records read from it are being passed to the downstream transforms in the pipeline, we say that positions in the source are being &lt;em>consumed&lt;/em>. When a reader has read a record (or promised to a caller that a record will be returned), positions up to and including the record&amp;rsquo;s start position are considered &lt;em>consumed&lt;/em>.&lt;/p>
&lt;p>Dynamic splitting can happen only at &lt;em>unconsumed&lt;/em> positions. If the reader just returned a record at offset 42 in a file, dynamic splitting can happen only at offset 43 or beyond. Otherwise, that record could be read twice (by the current reader and the reader of the new task).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="rangetracker-methods">RangeTracker methods&lt;/h4>
&lt;p>To implement a &lt;code>RangeTracker&lt;/code>, your subclass must override the following methods:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>start_position&lt;/code>: Returns the starting position of the current range, inclusive.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>stop_position&lt;/code>: Returns the ending position of the current range, exclusive.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>try_claim&lt;/code>: This method is used to determine if a record at a split point is within the range. This method should modify the internal state of the &lt;code>RangeTracker&lt;/code> by updating the last-consumed position to the given starting &lt;code>position&lt;/code> of the record being read by the source. The method returns true if the given position falls within the current range.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>set_current_position&lt;/code>: This method updates the last-consumed position to the given starting position of a record being read by a source. You can invoke this method for records that do not start at split points, and this should modify the internal state of the &lt;code>RangeTracker&lt;/code>. If the record starts at a split point, you must invoke &lt;code>try_claim&lt;/code> instead of this method.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>position_at_fraction&lt;/code>: Given a fraction within the range [0.0, 1.0), this method will return the position at the given fraction compared to the position range [&lt;code>self.start_position&lt;/code>, &lt;code>self.stop_position&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>try_split&lt;/code>: This method attempts to split the current range into two parts around a suggested position. It is allowed to split at a different position, but in most cases it will split at the suggested position.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>This method splits the current range [&lt;code>self.start_position&lt;/code>, &lt;code>self.stop_position&lt;/code>) into a &amp;ldquo;primary&amp;rdquo; part [&lt;code>self.start_position&lt;/code>, &lt;code>split_position&lt;/code>), and a &amp;ldquo;residual&amp;rdquo; part [&lt;code>split_position&lt;/code>, &lt;code>self.stop_position&lt;/code>), assuming that &lt;code>split_position&lt;/code> has not been consumed yet.&lt;/p>
&lt;p>If &lt;code>split_position&lt;/code> has already been consumed, the method returns &lt;code>None&lt;/code>. Otherwise, it updates the current range to be the primary and returns a tuple (&lt;code>split_position&lt;/code>, &lt;code>split_fraction&lt;/code>). &lt;code>split_fraction&lt;/code> should be the fraction of size of range [&lt;code>self.start_position&lt;/code>, &lt;code>split_position&lt;/code>) compared to the original (before split) range [&lt;code>self.start_position&lt;/code>, &lt;code>self.stop_position&lt;/code>).&lt;/p>
&lt;ul>
&lt;li>&lt;code>fraction_consumed&lt;/code>: Returns the approximate fraction of consumed positions in the source.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note:&lt;/strong> Methods of class &lt;code>iobase.RangeTracker&lt;/code> may be invoked by multiple threads, hence this class must be made thread-safe, for example, by using a single lock object.&lt;/p>
&lt;h3 id="convenience-source-base-classes">Convenience Source base classes&lt;/h3>
&lt;p>The Beam SDK for Python contains some convenient abstract base classes to help you easily create new sources.&lt;/p>
&lt;h4 id="filebasedsource">FileBasedSource&lt;/h4>
&lt;p>&lt;code>FileBasedSource&lt;/code> is a framework for developing sources for new file types. You can derive your &lt;code>BoundedSource&lt;/code> class from the &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/filebasedsource.py">FileBasedSource&lt;/a> class.&lt;/p>
&lt;p>To create a source for a new file type, you need to create a sub-class of &lt;code>FileBasedSource&lt;/code>. Sub-classes of &lt;code>FileBasedSource&lt;/code> must implement the method &lt;code>FileBasedSource.read_records()&lt;/code>.&lt;/p>
&lt;p>See &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/avroio.py">AvroSource&lt;/a> for an example implementation of &lt;code>FileBasedSource&lt;/code>.&lt;/p>
&lt;h3 id="reading-from-a-new-source">Reading from a new Source&lt;/h3>
&lt;p>The following example, &lt;code>CountingSource&lt;/code>, demonstrates an implementation of &lt;code>BoundedSource&lt;/code> and uses the SDK-provided &lt;code>RangeTracker&lt;/code> called &lt;code>OffsetRangeTracker&lt;/code>.&lt;/p>
&lt;pre>&lt;code>class CountingSource(iobase.BoundedSource):
def __init__(self, count):
self.records_read = Metrics.counter(self.__class__, &amp;#39;recordsRead&amp;#39;)
self._count = count
def estimate_size(self):
return self._count
def get_range_tracker(self, start_position, stop_position):
if start_position is None:
start_position = 0
if stop_position is None:
stop_position = self._count
return OffsetRangeTracker(start_position, stop_position)
def read(self, range_tracker):
for i in range(range_tracker.start_position(),
range_tracker.stop_position()):
if not range_tracker.try_claim(i):
return
self.records_read.inc()
yield i
def split(self, desired_bundle_size, start_position=None, stop_position=None):
if start_position is None:
start_position = 0
if stop_position is None:
stop_position = self._count
bundle_start = start_position
while bundle_start &amp;lt; stop_position:
bundle_stop = min(stop_position, bundle_start + desired_bundle_size)
yield iobase.SourceBundle(
weight=(bundle_stop - bundle_start),
source=self,
start_position=bundle_start,
stop_position=bundle_stop)
bundle_start = bundle_stop&lt;/code>&lt;/pre>
&lt;p>To read data from the source in your pipeline, use the &lt;code>Read&lt;/code> transform:&lt;/p>
&lt;pre>&lt;code>with beam.Pipeline(options=PipelineOptions()) as p:
numbers = p | &amp;#39;ProduceNumbers&amp;#39; &amp;gt;&amp;gt; beam.io.Read(CountingSource(count))&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Note:&lt;/strong> When you create a source that end-users are going to use, we
recommended that you do not expose the code for the source itself as
demonstrated in the example above. Use a wrapping &lt;code>PTransform&lt;/code> instead.
&lt;a href="#ptransform-wrappers">PTransform wrappers&lt;/a> discusses why you should avoid
exposing your sources, and walks through how to create a wrapper.&lt;/p>
&lt;h2 id="using-the-filebasedsink-abstraction">Using the FileBasedSink abstraction&lt;/h2>
&lt;p>If your data source uses files, you can implement the &lt;a href="https://beam.apache.org/releases/pydoc/2.24.0/apache_beam.io.filebasedsink.html">FileBasedSink&lt;/a>
abstraction to create a file-based sink. For other sinks, use &lt;code>ParDo&lt;/code>,
&lt;code>GroupByKey&lt;/code>, and other transforms offered by the Beam SDK for Python. See the
&lt;a href="/documentation/io/developing-io-overview/">developing I/O connectors overview&lt;/a>
for more details.&lt;/p>
&lt;p>When using the &lt;code>FileBasedSink&lt;/code> interface, you must provide the format-specific
logic that tells the runner how to write bounded data from your pipeline&amp;rsquo;s
&lt;code>PCollection&lt;/code>s to an output sink. The runner writes bundles of data in parallel
using multiple workers.&lt;/p>
&lt;p>Supply the logic for your file-based sink by implementing the following classes:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>A subclass of the abstract base class &lt;code>FileBasedSink&lt;/code>. &lt;code>FileBasedSink&lt;/code>
describes a location or resource that your pipeline can write to in
parallel. To avoid exposing your sink to end-users, use the &lt;code>_&lt;/code> prefix when
creating your &lt;code>FileBasedSink&lt;/code> subclass.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A user-facing wrapper &lt;code>PTransform&lt;/code> that, as part of the logic, calls
&lt;code>Write&lt;/code> and passes your &lt;code>FileBasedSink&lt;/code> as a parameter. A user should not
need to call &lt;code>Write&lt;/code> directly.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>The &lt;code>FileBasedSink&lt;/code> abstract base class implements code that is common to Beam
sinks that interact with files, including:&lt;/p>
&lt;ul>
&lt;li>Setting file headers and footers&lt;/li>
&lt;li>Sequential record writing&lt;/li>
&lt;li>Setting the output MIME type&lt;/li>
&lt;/ul>
&lt;p>&lt;code>FileBasedSink&lt;/code> and its subclasses support writing files to any Beam-supported
&lt;code>FileSystem&lt;/code> implementations. See the following Beam-provided &lt;code>FileBasedSink&lt;/code>
implementation for an example:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/textio.py">TextSink&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="ptransform-wrappers">PTransform wrappers&lt;/h2>
&lt;p>When you create a source or sink that end-users will use, avoid exposing your
source or sink code. To avoid exposing your sources and sinks to end-users, your
new classes should use the &lt;code>_&lt;/code> prefix. Then, implement a user-facing
wrapper &lt;code>PTransform&lt;/code>.`By exposing your source or sink as a transform, your
implementation is hidden and can be arbitrarily complex or simple. The greatest
benefit of not exposing implementation details is that later on, you can add
additional functionality without breaking the existing implementation for users.&lt;/p>
&lt;p>For example, if your users’ pipelines read from your source using
&lt;code>beam.io.Read&lt;/code> and you want to insert a reshard into the pipeline, all
users would need to add the reshard themselves (using the &lt;code>GroupByKey&lt;/code>
transform). To solve this, we recommended that you expose the source as a
composite &lt;code>PTransform&lt;/code> that performs both the read operation and the reshard.&lt;/p>
&lt;p>See Beam’s &lt;a href="/contribute/ptransform-style-guide/#exposing-a-ptransform-vs-something-else">PTransform style guide&lt;/a>
for additional information about wrapping with a &lt;code>PTransform&lt;/code>.&lt;/p>
&lt;p>The following examples change the source and sink from the above sections so
that they are not exposed to end-users. For the source, rename &lt;code>CountingSource&lt;/code>
to &lt;code>_CountingSource&lt;/code>. Then, create the wrapper &lt;code>PTransform&lt;/code>, called
&lt;code>ReadFromCountingSource&lt;/code>:&lt;/p>
&lt;pre>&lt;code>class ReadFromCountingSource(PTransform):
def __init__(self, count):
super(ReadFromCountingSource, self).__init__()
self._count = count
def expand(self, pcoll):
return pcoll | iobase.Read(_CountingSource(self._count))&lt;/code>&lt;/pre>
&lt;p>Finally, read from the source:&lt;/p>
&lt;pre>&lt;code>with beam.Pipeline(options=PipelineOptions()) as p:
numbers = p | &amp;#39;ProduceNumbers&amp;#39; &amp;gt;&amp;gt; ReadFromCountingSource(count)&lt;/code>&lt;/pre>
&lt;p>For the sink, rename &lt;code>SimpleKVSink&lt;/code> to &lt;code>_SimpleKVSink&lt;/code>. Then, create the wrapper &lt;code>PTransform&lt;/code>, called &lt;code>WriteToKVSink&lt;/code>:&lt;/p>
&lt;pre>&lt;code>class WriteToKVSink(PTransform):
def __init__(self, simplekv, url, final_table_name):
self._simplekv = simplekv
super(WriteToKVSink, self).__init__()
self._url = url
self._final_table_name = final_table_name
def expand(self, pcoll):
return pcoll | iobase.Write(
_SimpleKVSink(self._simplekv, self._url, self._final_table_name))&lt;/code>&lt;/pre>
&lt;p>Finally, write to the sink:&lt;/p>
&lt;pre>&lt;code>with beam.Pipeline(options=PipelineOptions()) as p:
kvs = p | &amp;#39;CreateKVs&amp;#39; &amp;gt;&amp;gt; beam.core.Create(KVs)
kvs | &amp;#39;WriteToSimpleKV&amp;#39; &amp;gt;&amp;gt; WriteToKVSink(
simplekv, &amp;#39;http://url_to_simple_kv/&amp;#39;, final_table_name)&lt;/code>&lt;/pre></description></item><item><title>Documentation: Apache Hadoop Input/Output Format IO</title><link>/documentation/io/built-in/hadoop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/io/built-in/hadoop/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="hadoop-inputoutput-format-io">Hadoop Input/Output Format IO&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>IMPORTANT!&lt;/strong> Previous implementation of Hadoop Input Format IO, called &lt;code>HadoopInputFormatIO&lt;/code>, is deprecated starting from &lt;em>Apache Beam 2.10&lt;/em>. Please, use current &lt;code>HadoopFormatIO&lt;/code> which supports both &lt;code>InputFormat&lt;/code> and &lt;code>OutputFormat&lt;/code>.&lt;/p>
&lt;/blockquote>
&lt;p>A &lt;code>HadoopFormatIO&lt;/code> is a transform for reading data from any source or writing data to any sink that implements Hadoop&amp;rsquo;s &lt;code>InputFormat&lt;/code> or &lt;code>OurputFormat&lt;/code> accordingly. For example, Cassandra, Elasticsearch, HBase, Redis, Postgres, etc.&lt;/p>
&lt;p>&lt;code>HadoopFormatIO&lt;/code> allows you to connect to many data sources/sinks that do not yet have a Beam IO transform. However, &lt;code>HadoopFormatIO&lt;/code> has to make several performance trade-offs in connecting to &lt;code>InputFormat&lt;/code> or &lt;code>OutputFormat&lt;/code>. So, if there is another Beam IO transform for connecting specifically to your data source/sink of choice, we recommend you use that one.&lt;/p>
&lt;h3 id="reading-using-hadoopformatio">Reading using HadoopFormatIO&lt;/h3>
&lt;p>You will need to pass a Hadoop &lt;code>Configuration&lt;/code> with parameters specifying how the read will occur. Many properties of the &lt;code>Configuration&lt;/code> are optional and some are required for certain &lt;code>InputFormat&lt;/code> classes, but the following properties must be set for all &lt;code>InputFormat&lt;/code> classes:&lt;/p>
&lt;ul>
&lt;li>&lt;code>mapreduce.job.inputformat.class&lt;/code> - The &lt;code>InputFormat&lt;/code> class used to connect to your data source of choice.&lt;/li>
&lt;li>&lt;code>key.class&lt;/code> - The &lt;code>Key&lt;/code> class returned by the &lt;code>InputFormat&lt;/code> in &lt;code>mapreduce.job.inputformat.class&lt;/code>.&lt;/li>
&lt;li>&lt;code>value.class&lt;/code> - The &lt;code>Value&lt;/code> class returned by the &lt;code>InputFormat&lt;/code> in &lt;code>mapreduce.job.inputformat.class&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>For example:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Configuration&lt;/span> &lt;span class="n">myHadoopConfiguration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Set Hadoop InputFormat, key and value class in configuration
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;mapreduce.job.inputformat.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InputFormatClass&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">InputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;key.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InputFormatKeyClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;value.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InputFormatValueClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>You will need to check if the &lt;code>Key&lt;/code> and &lt;code>Value&lt;/code> classes output by the &lt;code>InputFormat&lt;/code> have a Beam &lt;code>Coder&lt;/code> available. If not, you can use &lt;code>withKeyTranslation&lt;/code> or &lt;code>withValueTranslation&lt;/code> to specify a method transforming instances of those classes into another class that is supported by a Beam &lt;code>Coder&lt;/code>. These settings are optional and you don&amp;rsquo;t need to specify translation for both key and value.&lt;/p>
&lt;p>For example:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">SimpleFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">InputFormatKeyClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">MyKeyClass&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">myOutputKeyType&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">SimpleFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">InputFormatKeyClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">MyKeyClass&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">MyKeyClass&lt;/span> &lt;span class="nf">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">InputFormatKeyClass&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// ...logic to transform InputFormatKeyClass to MyKeyClass
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">};&lt;/span>
&lt;span class="n">SimpleFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">InputFormatValueClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">MyValueClass&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">myOutputValueType&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">SimpleFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">InputFormatValueClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">MyValueClass&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">MyValueClass&lt;/span> &lt;span class="nf">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">InputFormatValueClass&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// ...logic to transform InputFormatValueClass to MyValueClass
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">};&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="read-data-only-with-hadoop-configuration">Read data only with Hadoop configuration.&lt;/h4>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">InputFormatKeyClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InputFormatKeyClass&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="read-data-with-configuration-and-key-translation">Read data with configuration and key translation&lt;/h4>
&lt;p>For example, a Beam &lt;code>Coder&lt;/code> is not available for &lt;code>Key&lt;/code> class, so key translation is required.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">MyKeyClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InputFormatKeyClass&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withKeyTranslation&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">myOutputKeyType&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="read-data-with-configuration-and-value-translation">Read data with configuration and value translation&lt;/h4>
&lt;p>For example, a Beam &lt;code>Coder&lt;/code> is not available for &lt;code>Value&lt;/code> class, so value translation is required.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">InputFormatKeyClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">MyValueClass&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withValueTranslation&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">myOutputValueType&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="read-data-with-configuration-value-translation-and-key-translation">Read data with configuration, value translation and key translation&lt;/h4>
&lt;p>For example, Beam Coders are not available for both &lt;code>Key&lt;/code> class and &lt;code>Value&lt;/code> classes of &lt;code>InputFormat&lt;/code>, so key and value translation are required.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">MyKeyClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">MyValueClass&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withKeyTranslation&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">myOutputKeyType&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withValueTranslation&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">myOutputValueType&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h1 id="examples-for-specific-inputformats">Examples for specific InputFormats&lt;/h1>
&lt;h3 id="cassandra---cqlinputformat">Cassandra - CqlInputFormat&lt;/h3>
&lt;p>To read data from Cassandra, use &lt;code>org.apache.cassandra.hadoop.cql3.CqlInputFormat&lt;/code>, which needs the following properties to be set:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Configuration&lt;/span> &lt;span class="n">cassandraConf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">cassandraConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;cassandra.input.thrift.port&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;9160&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">cassandraConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;cassandra.input.thrift.address&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CassandraHostIp&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">cassandraConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;cassandra.input.partitioner.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;Murmur3Partitioner&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">cassandraConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;cassandra.input.keyspace&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;myKeySpace&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">cassandraConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;cassandra.input.columnfamily&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;myColumnFamily&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">cassandraConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;key.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">java&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">lang&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Long&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">cassandraConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;value.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">com&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">datastax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">driver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">core&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Row&lt;/span> &lt;span class="n">Row&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">cassandraConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;mapreduce.job.inputformat.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">cassandra&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hadoop&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">cql3&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CqlInputFormat&lt;/span> &lt;span class="n">CqlInputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Call Read transform as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">cassandraData&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cassandraConf&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withValueTranslation&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cassandraOutputValueType&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The &lt;code>CqlInputFormat&lt;/code> key class is &lt;code>java.lang.Long&lt;/code> &lt;code>Long&lt;/code>, which has a Beam &lt;code>Coder&lt;/code>. The &lt;code>CqlInputFormat&lt;/code> value class is &lt;code>com.datastax.driver.core.Row&lt;/code> &lt;code>Row&lt;/code>, which does not have a Beam &lt;code>Coder&lt;/code>. Rather than write a new coder, you can provide your own translation method, as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">SimpleFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">cassandraOutputValueType&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SimpleFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span>
&lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Row&lt;/span> &lt;span class="n">row&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">row&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="err">&amp;#39;&lt;/span>&lt;span class="n">myColName&lt;/span>&lt;span class="err">&amp;#39;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">};&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="elasticsearch---esinputformat">Elasticsearch - EsInputFormat&lt;/h3>
&lt;p>To read data from Elasticsearch, use &lt;code>EsInputFormat&lt;/code>, which needs following properties to be set:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Configuration&lt;/span> &lt;span class="n">elasticsearchConf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">elasticsearchConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;es.nodes&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ElasticsearchHostIp&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">elasticsearchConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;es.port&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;9200&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">elasticsearchConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;es.resource&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;ElasticIndexName/ElasticTypeName&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">elasticsearchConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;key.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hadoop&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Text&lt;/span> &lt;span class="n">Text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">elasticsearchConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;value.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">elasticsearch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hadoop&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">mr&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">LinkedMapWritable&lt;/span> &lt;span class="n">LinkedMapWritable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">elasticsearchConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;mapreduce.job.inputformat.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">elasticsearch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hadoop&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">mr&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">EsInputFormat&lt;/span> &lt;span class="n">EsInputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Call Read transform as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LinkedMapWritable&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">elasticData&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LinkedMapWritable&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">elasticsearchConf&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The &lt;code>org.elasticsearch.hadoop.mr.EsInputFormat&lt;/code>'s &lt;code>EsInputFormat&lt;/code> key class is &lt;code>org.apache.hadoop.io.Text&lt;/code> &lt;code>Text&lt;/code>, and its value class is &lt;code>org.elasticsearch.hadoop.mr.LinkedMapWritable&lt;/code> &lt;code>LinkedMapWritable&lt;/code>. Both key and value classes have Beam Coders.&lt;/p>
&lt;h3 id="hcatalog---hcatinputformat">HCatalog - HCatInputFormat&lt;/h3>
&lt;p>To read data using HCatalog, use &lt;code>org.apache.hive.hcatalog.mapreduce.HCatInputFormat&lt;/code>, which needs the following properties to be set:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Configuration&lt;/span> &lt;span class="n">hcatConf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">hcatConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;mapreduce.job.inputformat.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">HCatInputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">hcatConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;key.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LongWritable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">hcatConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;value.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">HCatRecord&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">hcatConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hive.metastore.uris&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;thrift://metastore-host:port&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hive&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hcatalog&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">mapreduce&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">HCatInputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setInput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hcatConf&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;my_database&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;my_table&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;my_filter&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Call Read transform as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">HCatRecord&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">hcatData&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">HCatRecord&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hcatConf&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="amazon-dynamodb---dynamodbinputformat">Amazon DynamoDB - DynamoDBInputFormat&lt;/h3>
&lt;p>To read data from Amazon DynamoDB, use &lt;code>org.apache.hadoop.dynamodb.read.DynamoDBInputFormat&lt;/code>.
DynamoDBInputFormat implements the older &lt;code>org.apache.hadoop.mapred.InputFormat&lt;/code> interface and to make it compatible with HadoopFormatIO which uses the newer abstract class &lt;code>org.apache.hadoop.mapreduce.InputFormat&lt;/code>,
a wrapper API is required which acts as an adapter between HadoopFormatIO and DynamoDBInputFormat (or in general any InputFormat implementing &lt;code>org.apache.hadoop.mapred.InputFormat&lt;/code>)
The below example uses one such available wrapper API - &lt;a href="https://github.com/twitter/elephant-bird/blob/master/core/src/main/java/com/twitter/elephantbird/mapreduce/input/MapReduceInputFormatWrapper.java">https://github.com/twitter/elephant-bird/blob/master/core/src/main/java/com/twitter/elephantbird/mapreduce/input/MapReduceInputFormatWrapper.java&lt;/a>&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Configuration&lt;/span> &lt;span class="n">dynamoDBConf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">Job&lt;/span> &lt;span class="n">job&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Job&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getInstance&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">com&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">twitter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">elephantbird&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">mapreduce&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">input&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">MapReduceInputFormatWrapper&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setInputFormat&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hadoop&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">dynamodb&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DynamoDBInputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">job&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">job&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getConfiguration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;key.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">WritableComparable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;value.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hadoop&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">dynamodb&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DynamoDBItemWritable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Writable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;dynamodb.servicename&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;dynamodb&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;dynamodb.input.tableName&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;table_name&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;dynamodb.endpoint&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;dynamodb.us-west-1.amazonaws.com&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;dynamodb.regionid&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;us-west-1&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;dynamodb.throughput.read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;1&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;dynamodb.throughput.read.percent&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;1&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;dynamodb.version&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;2011-12-05&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">DynamoDBConstants&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DYNAMODB_ACCESS_KEY_CONF&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;aws_access_key&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">DynamoDBConstants&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DYNAMODB_SECRET_KEY_CONF&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;aws_secret_key&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Call Read transform as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">DynamoDBItemWritable&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">dynamoDBData&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">DynamoDBItemWritable&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dynamoDBConf&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="apache-hbase---tablesnapshotinputformat">Apache HBase - TableSnapshotInputFormat&lt;/h3>
&lt;p>To read data from an HBase table snapshot, use &lt;code>org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat&lt;/code>.
Reading from a table snapshot bypasses the HBase region servers, instead reading HBase data files directly from the filesystem.
This is useful for cases such as reading historical data or offloading of work from the HBase cluster.
There are scenarios when this may prove faster than accessing content through the region servers using the &lt;code>HBaseIO&lt;/code>.&lt;/p>
&lt;p>A table snapshot can be taken using the HBase shell or programmatically:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="k">try&lt;/span> &lt;span class="o">(&lt;/span>
&lt;span class="n">Connection&lt;/span> &lt;span class="n">connection&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ConnectionFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">createConnection&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hbaseConf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">Admin&lt;/span> &lt;span class="n">admin&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">connection&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getAdmin&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">admin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">snapshot&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;my_snaphshot&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;my_table&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">HBaseProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">SnapshotDescription&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Type&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">FLUSH&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>A &lt;code>TableSnapshotInputFormat&lt;/code> is configured as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Construct a typical HBase scan
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">Scan&lt;/span> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Scan&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setCaching&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setBatch&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">addColumn&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;CF&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;col_1&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">addColumn&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;CF&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;col_2&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">Configuration&lt;/span> &lt;span class="n">hbaseConf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">HBaseConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">hbaseConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HConstants&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">ZOOKEEPER_QUORUM&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;zk1:2181&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">hbaseConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.rootdir&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;/hbase&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">hbaseConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;mapreduce.job.inputformat.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">TableSnapshotInputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">InputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">hbaseConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;key.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ImmutableBytesWritable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Writable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">hbaseConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;value.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Result&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Writable&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">ClientProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Scan&lt;/span> &lt;span class="n">proto&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ProtobufUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toScan&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">scan&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">hbaseConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableInputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">SCAN&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Base64&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">encodeBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">proto&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toByteArray&lt;/span>&lt;span class="o">()));&lt;/span>
&lt;span class="c1">// Make use of existing utility methods
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">Job&lt;/span> &lt;span class="n">job&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Job&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getInstance&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hbaseConf&lt;/span>&lt;span class="o">);&lt;/span> &lt;span class="c1">// creates internal clone of hbaseConf
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">TableSnapshotInputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setInput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">job&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;my_snapshot&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;/tmp/snapshot_restore&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">hbaseConf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">job&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getConfiguration&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="o">//&lt;/span> &lt;span class="n">extract&lt;/span> &lt;span class="n">the&lt;/span> &lt;span class="n">modified&lt;/span> &lt;span class="n">clone&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Call Read transform as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ImmutableBytesWritable&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Result&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">hbaseSnapshotData&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">ImmutableBytesWritable&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Result&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hbaseConf&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="writing-using-hadoopformatio">Writing using HadoopFormatIO&lt;/h3>
&lt;p>You will need to pass a Hadoop &lt;code>Configuration&lt;/code> with parameters specifying how the write will occur. Many properties of the &lt;code>Configuration&lt;/code> are optional, and some are required for certain &lt;code>OutputFormat&lt;/code> classes, but the following properties must be set for all &lt;code>OutputFormat&lt;/code>s:&lt;/p>
&lt;ul>
&lt;li>&lt;code>mapreduce.job.id&lt;/code> - The identifier of the write job. E.g.: end timestamp of window.&lt;/li>
&lt;li>&lt;code>mapreduce.job.outputformat.class&lt;/code> - The &lt;code>OutputFormat&lt;/code> class used to connect to your data sink of choice.&lt;/li>
&lt;li>&lt;code>mapreduce.job.output.key.class&lt;/code> - The key class passed to the &lt;code>OutputFormat&lt;/code> in &lt;code>mapreduce.job.outputformat.class&lt;/code>.&lt;/li>
&lt;li>&lt;code>mapreduce.job.output.value.class&lt;/code> - The value class passed to the &lt;code>OutputFormat&lt;/code> in &lt;code>mapreduce.job.outputformat.class&lt;/code>.&lt;/li>
&lt;li>&lt;code>mapreduce.job.reduces&lt;/code> - Number of reduce tasks. Value is equal to number of write tasks which will be genarated. This property is not required for &lt;code>Write.PartitionedWriterBuilder#withoutPartitioning()&lt;/code> write.&lt;/li>
&lt;li>&lt;code>mapreduce.job.partitioner.class&lt;/code> - Hadoop partitioner class which will be used for distributing of records among partitions. This property is not required for &lt;code>Write.PartitionedWriterBuilder#withoutPartitioning()&lt;/code> write.&lt;/li>
&lt;/ul>
&lt;p>&lt;em>Note&lt;/em>: All mentioned values have appropriate constants. E.g.: &lt;code>HadoopFormatIO.OUTPUT_FORMAT_CLASS_ATTR&lt;/code>.&lt;/p>
&lt;p>For example:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Configuration&lt;/span> &lt;span class="n">myHadoopConfiguration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Set Hadoop OutputFormat, key and value class in configuration
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;mapreduce.job.outputformat.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">MyDbOutputFormatClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">OutputFormat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;mapreduce.job.output.key.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">MyDbOutputFormatKeyClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;mapreduce.job.output.value.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">MyDbOutputFormatValueClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;mapreduce.job.partitioner.class&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">MyPartitionerClass&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setInt&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;mapreduce.job.reduces&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">2&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>You will need to set &lt;code>OutputFormat&lt;/code> key and value class (i.e. &amp;ldquo;mapreduce.job.output.key.class&amp;rdquo; and &amp;ldquo;mapreduce.job.output.value.class&amp;rdquo;) in Hadoop &lt;code>Configuration&lt;/code> which are equal to &lt;code>KeyT&lt;/code> and &lt;code>ValueT&lt;/code>. If you set different &lt;code>OutputFormat&lt;/code> key or value class than &lt;code>OutputFormat&lt;/code>'s actual key or value class then, it will throw &lt;code>IllegalArgumentException&lt;/code>.&lt;/p>
&lt;h4 id="batch-writing-">Batch writing&lt;/h4>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Data which will we want to write
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LongWritable&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">boundedWordsCount&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="c1">// Hadoop configuration for write
&lt;/span>&lt;span class="c1">// We have partitioned write, so Partitioner and reducers count have to be set - see withPartitioning() javadoc
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">Configuration&lt;/span> &lt;span class="n">myHadoopConfiguration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="c1">// Path to directory with locks
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">locksDirPath&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">boundedWordsCount&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;writeBatch&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LongWritable&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">myHadoopConfiguration&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withPartitioning&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withExternalSynchronization&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">HDFSSynchronization&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">locksDirPath&lt;/span>&lt;span class="o">)));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="stream-writing-">Stream writing&lt;/h4>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Data which will we want to write
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LongWritable&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">unboundedWordsCount&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="c1">// Transformation which transforms data of one window into one hadoop configuration
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;?&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LongWritable&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;,&lt;/span> &lt;span class="n">PCollectionView&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Configuration&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">configTransform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">unboundedWordsCount&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;writeStream&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HadoopFormatIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">Text&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LongWritable&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfigurationTransform&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">configTransform&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withExternalSynchronization&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">HDFSSynchronization&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">locksDirPath&lt;/span>&lt;span class="o">)));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support Hadoop Input/Output Format IO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div></description></item><item><title>Documentation: Apache HCatalog I/O connector</title><link>/documentation/io/built-in/hcatalog/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/io/built-in/hcatalog/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="hcatalog-io">HCatalog IO&lt;/h1>
&lt;p>An &lt;code>HCatalogIO&lt;/code> is a transform for reading and writing data to an HCatalog managed source.&lt;/p>
&lt;h3 id="reading-using-hcatalogio">Reading using HCatalogIO&lt;/h3>
&lt;p>To configure an HCatalog source, you must specify a metastore URI and a table name. Other optional parameters are database and filter.&lt;/p>
&lt;p>For example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">configProperties&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HashMap&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;();&lt;/span>
&lt;span class="n">configProperties&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">put&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hive.metastore.uris&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="s">&amp;#34;thrift://metastore-host:port&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HCatalogIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfigProperties&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">configProperties&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDatabase&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;default&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="c1">//optional, assumes default if none specified
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;employee&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withFilter&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">filterString&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">//&lt;/span>&lt;span class="n">optional&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">may&lt;/span> &lt;span class="n">be&lt;/span> &lt;span class="n">specified&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">the&lt;/span> &lt;span class="n">table&lt;/span> &lt;span class="n">is&lt;/span> &lt;span class="n">partitioned&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support HCatalogIO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="writing-using-hcatalogio">Writing using HCatalogIO&lt;/h3>
&lt;p>To configure an &lt;code>HCatalog&lt;/code> sink, you must specify a metastore URI and a table name. Other
optional parameters are database, partition and batchsize.
The destination table should exist beforehand as the transform will not create a new table if missing.&lt;/p>
&lt;p>For example:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">configProperties&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HashMap&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;();&lt;/span>
&lt;span class="n">configProperties&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">put&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hive.metastore.uris&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="s">&amp;#34;thrift://metastore-host:port&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(...)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HCatalogIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withConfigProperties&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">configProperties&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDatabase&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;default&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="c1">//optional, assumes default if none specified
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;employee&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withPartition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">partitionValues&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="c1">//optional, may be specified if the table is partitioned
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withBatchSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1024L&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">//&lt;/span>&lt;span class="n">optional&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">assumes&lt;/span> &lt;span class="n">a&lt;/span> &lt;span class="k">default&lt;/span> &lt;span class="n">batch&lt;/span> &lt;span class="n">size&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="n">1024&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">none&lt;/span> &lt;span class="n">specified&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># The Beam SDK for Python does not support HCatalogIO.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="using-older-versions-of-hcatalog-1x">Using older versions of HCatalog (1.x)&lt;/h3>
&lt;p>&lt;code>HCatalogIO&lt;/code> is built for Apache HCatalog versions 2 and up and will not work out of the box for older versions of HCatalog.
The following illustrates a workaround to work with Hive 1.1.&lt;/p>
&lt;p>Include the following Hive 1.2 jars in the über jar you build.
The 1.2 jars provide the necessary methods for Beam while remain compatible with Hive 1.1.&lt;/p>
&lt;pre>&lt;code>&amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;beam-sdks-java-io-hcatalog&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;${beam.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;org.apache.hive.hcatalog&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;hive-hcatalog-core&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;1.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;org.apache.hive&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;hive-metastore&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;1.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;org.apache.hive&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;hive-exec&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;1.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;org.apache.hive&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;hive-common&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;1.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Relocate &lt;em>only&lt;/em> the following hive packages:&lt;/p>
&lt;pre>&lt;code>&amp;lt;plugin&amp;gt;
&amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;maven-shade-plugin&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;${maven-shade-plugin.version}&amp;lt;/version&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;createDependencyReducedPom&amp;gt;false&amp;lt;/createDependencyReducedPom&amp;gt;
&amp;lt;filters&amp;gt;
&amp;lt;filter&amp;gt;
&amp;lt;artifact&amp;gt;*:*&amp;lt;/artifact&amp;gt;
&amp;lt;excludes&amp;gt;
&amp;lt;exclude&amp;gt;META-INF/*.SF&amp;lt;/exclude&amp;gt;
&amp;lt;exclude&amp;gt;META-INF/*.DSA&amp;lt;/exclude&amp;gt;
&amp;lt;exclude&amp;gt;META-INF/*.RSA&amp;lt;/exclude&amp;gt;
&amp;lt;/excludes&amp;gt;
&amp;lt;/filter&amp;gt;
&amp;lt;/filters&amp;gt;
&amp;lt;/configuration&amp;gt;
&amp;lt;executions&amp;gt;
&amp;lt;execution&amp;gt;
&amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt;
&amp;lt;goals&amp;gt;
&amp;lt;goal&amp;gt;shade&amp;lt;/goal&amp;gt;
&amp;lt;/goals&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;shadedArtifactAttached&amp;gt;true&amp;lt;/shadedArtifactAttached&amp;gt;
&amp;lt;shadedClassifierName&amp;gt;shaded&amp;lt;/shadedClassifierName&amp;gt;
&amp;lt;transformers&amp;gt;
&amp;lt;transformer implementation=&amp;quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&amp;quot;/&amp;gt;
&amp;lt;/transformers&amp;gt;
&amp;lt;relocations&amp;gt;
&amp;lt;!-- Important: Do not relocate org.apache.hadoop.hive --&amp;gt;
&amp;lt;relocation&amp;gt;
&amp;lt;pattern&amp;gt;org.apache.hadoop.hive.conf&amp;lt;/pattern&amp;gt;
&amp;lt;shadedPattern&amp;gt;h12.org.apache.hadoop.hive.conf&amp;lt;/shadedPattern&amp;gt;
&amp;lt;/relocation&amp;gt;
&amp;lt;relocation&amp;gt;
&amp;lt;pattern&amp;gt;org.apache.hadoop.hive.ql&amp;lt;/pattern&amp;gt;
&amp;lt;shadedPattern&amp;gt;h12.org.apache.hadoop.hive.ql&amp;lt;/shadedPattern&amp;gt;
&amp;lt;/relocation&amp;gt;
&amp;lt;relocation&amp;gt;
&amp;lt;pattern&amp;gt;org.apache.hadoop.hive.metastore&amp;lt;/pattern&amp;gt;
&amp;lt;shadedPattern&amp;gt;h12.org.apache.hadoop.hive.metastore&amp;lt;/shadedPattern&amp;gt;
&amp;lt;/relocation&amp;gt;
&amp;lt;/relocations&amp;gt;
&amp;lt;/configuration&amp;gt;
&amp;lt;/execution&amp;gt;
&amp;lt;/executions&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code>&lt;/pre>&lt;p>This has been testing to read SequenceFile and ORCFile file backed tables running with
Beam 2.4.0 on Spark 2.3 / YARN in a Cloudera CDH 5.12.2 managed environment.&lt;/p></description></item><item><title>Documentation: Apache Parquet I/O connector</title><link>/documentation/io/built-in/parquet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/io/built-in/parquet/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>&lt;a href="/documentation/io/built-in/">Built-in I/O Transforms&lt;/a>&lt;/p>
&lt;h1 id="apache-parquet-io-connector">Apache Parquet I/O connector&lt;/h1>
&lt;nav class="language-switcher">
&lt;strong>Adapt for:&lt;/strong>
&lt;ul>
&lt;li data-type="language-java" class="active">Java SDK&lt;/li>
&lt;li data-type="language-py">Python SDK&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;p>The Beam SDKs include built-in transforms that can read data from and write data
to &lt;a href="https://parquet.apache.org">Apache Parquet&lt;/a> files.&lt;/p>
&lt;h2 id="before-you-start">Before you start&lt;/h2>
&lt;!-- Java specific -->
&lt;p class="language-java">To use ParquetIO, add the Maven artifact dependency to your &lt;code>pom.xml&lt;/code> file.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">beam&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">sdks&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">java&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">parquet&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">24&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">0&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">Additional resources:&lt;/p>
&lt;span class="language-java">&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/io/parquet/src/main/java/org/apache/beam/sdk/io/parquet/ParquetIO.java">ParquetIO source code&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/org/apache/beam/sdk/io/parquet/ParquetIO.html">ParquetIO Javadoc&lt;/a>&lt;/li>
&lt;/ul>&lt;/span>
&lt;!-- Python specific -->
&lt;p class="language-py">ParquetIO comes preinstalled with the Apache Beam python sdk..2.24.0&lt;/p>
&lt;p class="language-py">Additional resources:&lt;/p>
&lt;span class="language-py">&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/parquetio.py">ParquetIO source code&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://beam.apache.org/releases/pydoc/2.24.0/apache_beam.io.parquetio.html">ParquetIO Pydoc&lt;/a>&lt;/li>
&lt;/ul>&lt;/span>
&lt;p class="language-java">&lt;h4 id="using-parquetio-with-spark-before-24">Using ParquetIO with Spark before 2.4&lt;/h4>&lt;/p>
&lt;p class="language-java">&lt;code>ParquetIO&lt;/code> depends on an API introduced in Apache Parquet 1.10.0. &lt;strong>Spark 2.4.x is compatible and no additional steps are necessary&lt;/strong>. Older versions of Spark will not work out of the box since a pre-installed version of Parquet libraries will take precedence during execution. The following workaround should be applied.&lt;/p>
&lt;p class="language-java">&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: The following technique allows you to execute your pipeline with &lt;code>ParquetIO&lt;/code> correctly.
The Parquet files that are consumed or generated by this Beam connector should remain interoperable with the other tools on your cluster.&lt;/p>
&lt;/blockquote>&lt;/p>
&lt;p class="language-java">Include the Parquet artifact normally and ensure that it brings in the correct version of Parquet as a transitive dependency.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">beam&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">sdks&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">java&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">parquet&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">$&lt;/span>&lt;span class="o">{&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">version&lt;/span>&lt;span class="o">}&amp;lt;/&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">Relocate the following packages:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">plugin&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">maven&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">plugins&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">maven&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">shade&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">plugin&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">configuration&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">createDependencyReducedPom&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">createDependencyReducedPom&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">filters&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">filter&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">artifact&lt;/span>&lt;span class="o">&amp;gt;*:*&amp;lt;/&lt;/span>&lt;span class="n">artifact&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">excludes&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">exclude&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">META&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">INF&lt;/span>&lt;span class="o">/*.&lt;/span>&lt;span class="na">SF&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">exclude&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">exclude&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">META&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">INF&lt;/span>&lt;span class="o">/*.&lt;/span>&lt;span class="na">DSA&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">exclude&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">exclude&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">META&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">INF&lt;/span>&lt;span class="o">/*.&lt;/span>&lt;span class="na">RSA&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">exclude&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">excludes&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">filter&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">filters&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">configuration&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">executions&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">execution&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">phase&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">package&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">phase&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">goals&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">goal&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">shade&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">goal&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">goals&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">configuration&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">shadedArtifactAttached&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">shadedArtifactAttached&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">shadedClassifierName&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">shaded&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">shadedClassifierName&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">relocations&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">relocation&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">pattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">parquet&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">pattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">shadedPattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">shaded&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">parquet&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">shadedPattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">relocation&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;!--&lt;/span> &lt;span class="n">Some&lt;/span> &lt;span class="n">packages&lt;/span> &lt;span class="n">are&lt;/span> &lt;span class="n">shaded&lt;/span> &lt;span class="n">already&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">and&lt;/span> &lt;span class="n">on&lt;/span> &lt;span class="n">the&lt;/span> &lt;span class="n">original&lt;/span> &lt;span class="n">spark&lt;/span> &lt;span class="n">classpath&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">Shade&lt;/span> &lt;span class="n">them&lt;/span> &lt;span class="n">more&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="o">--&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">relocation&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">pattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">shaded&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">parquet&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">pattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">shadedPattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">reshaded&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">parquet&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">shadedPattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">relocation&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">relocation&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">pattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">avro&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">pattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">shadedPattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">shaded&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">avro&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">shadedPattern&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">relocation&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">relocations&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">transformers&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">transformer&lt;/span>
&lt;span class="n">implementation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&amp;#34;&lt;/span>&lt;span class="o">/&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">transformers&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">configuration&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">execution&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">executions&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">plugin&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">This technique has been tested to work on Spark 2.2.3, Spark 2.3.3 and Spark 2.4.3 (although it is optional for Spark 2.4+).&lt;/p></description></item><item><title>Documentation: Apache Snowflake I/O connector</title><link>/documentation/io/built-in/snowflake/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/io/built-in/snowflake/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>&lt;a href="/documentation/io/built-in/">Built-in I/O Transforms&lt;/a>&lt;/p>
&lt;h1 id="snowflake-io">Snowflake I/O&lt;/h1>
&lt;p>Pipeline options and general information about using and running Snowflake IO.&lt;/p>
&lt;h2 id="authentication">Authentication&lt;/h2>
&lt;p>All authentication methods available for the Snowflake JDBC Driver are possible to use with the IO transforms:&lt;/p>
&lt;ul>
&lt;li>Username and password&lt;/li>
&lt;li>Key pair&lt;/li>
&lt;li>OAuth token&lt;/li>
&lt;/ul>
&lt;p>Passing credentials is done via Pipeline options.&lt;/p>
&lt;p>Passing credentials is done via Pipeline options used to instantiate &lt;code>SnowflakeIO.DataSourceConfiguration&lt;/code>:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">SnowflakePipelineOptions&lt;/span> &lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PipelineOptionsFactory&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">fromArgs&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withValidation&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">as&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">SnowflakePipelineOptions&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">SnowflakeCredentials&lt;/span> &lt;span class="n">credentials&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SnowflakeCredentialsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DataSourceConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">credentials&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.(&lt;/span>&lt;span class="n">other&lt;/span> &lt;span class="n">DataSourceConfiguration&lt;/span> &lt;span class="n">options&lt;/span>&lt;span class="o">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;h3 id="username-and-password">Username and password&lt;/h3>
&lt;p>To use username/password authentication in SnowflakeIO, invoke your pipeline with the following Pipeline options:
&lt;pre>&lt;code>--username=&amp;lt;USERNAME&amp;gt; --password=&amp;lt;PASSWORD&amp;gt;&lt;/code>&lt;/pre>
&lt;/p>
&lt;h3 id="key-pair">Key pair&lt;/h3>
&lt;p>To use this authentication method, you must first generate a key pair and associate the public key with the Snowflake user that will connect using the IO transform. For instructions, see the &lt;a href="https://docs.snowflake.com/en/user-guide/jdbc-configure.html">Snowflake documentation&lt;/a>.&lt;/p>
&lt;p>To use key pair authentication with SnowflakeIO, invoke your pipeline with one of the following set of Pipeline options:
&lt;pre>&lt;code>--username=&amp;lt;USERNAME&amp;gt; --privateKeyPath=&amp;lt;PATH_TO_P8_FILE&amp;gt; --privateKeyPassphrase=&amp;lt;PASSWORD_FOR_KEY&amp;gt;
--username=&amp;lt;USERNAME&amp;gt; --rawPrivateKey=&amp;lt;PRIVATE_KEY&amp;gt; --privateKeyPassphrase=&amp;lt;PASSWORD_FOR_KEY&amp;gt;&lt;/code>&lt;/pre>
&lt;/p>
&lt;h3 id="oauth-token">OAuth token&lt;/h3>
&lt;p>SnowflakeIO also supports OAuth token.&lt;/p>
&lt;p>&lt;strong>IMPORTANT&lt;/strong>: SnowflakeIO requires a valid OAuth access token. It will neither be able to refresh the token nor obtain it using a web-based flow. For information on configuring an OAuth integration and obtaining the token, see the &lt;a href="https://docs.snowflake.com/en/user-guide/oauth-intro.html">Snowflake documentation&lt;/a>.&lt;/p>
&lt;p>Once you have the token, invoke your pipeline with following Pipeline Options:
&lt;pre>&lt;code>--oauthToken=&amp;lt;TOKEN&amp;gt;&lt;/code>&lt;/pre>
&lt;/p>
&lt;h2 id="datasource-configuration">DataSource Configuration&lt;/h2>
&lt;p>DataSource configuration is required in both read and write object for configuring Snowflake connection properties for IO purposes.&lt;/p>
&lt;h3 id="general-usage">General usage&lt;/h3>
&lt;p>Create the DataSource configuration:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DataSourceConfiguration&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withUrl&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getUrl&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withServerName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getServerName&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDatabase&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getDatabase&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withWarehouse&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getWarehouse&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getSchema&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
Where parameters can be:&lt;/p>
&lt;ul>
&lt;li>&lt;code> .withUrl(...)&lt;/code>
&lt;ul>
&lt;li>JDBC-like URL for your Snowflake account, including account name and region, without any parameters.&lt;/li>
&lt;li>Example: &lt;code>.withUrl(&amp;quot;jdbc:snowflake://account.snowflakecomputing.com&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>.withServerName(...)&lt;/code>
&lt;ul>
&lt;li>Server Name - full server name with account, zone and domain.&lt;/li>
&lt;li>Example: &lt;code>.withServerName(&amp;quot;account.snowflakecomputing.com&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>.withDatabase(...)&lt;/code>
&lt;ul>
&lt;li>Name of the Snowflake database to use.&lt;/li>
&lt;li>Example: &lt;code>.withDatabase(&amp;quot;MY_DATABASE&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>.withWarehouse(...)&lt;/code>
&lt;ul>
&lt;li>Name of the Snowflake warehouse to use. This parameter is optional. If no warehouse name is specified, the default warehouse for the user is used.&lt;/li>
&lt;li>Example: &lt;code>.withWarehouse(&amp;quot;MY_WAREHOUSE&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>.withSchema(...)&lt;/code>
&lt;ul>
&lt;li>Name of the schema in the database to use. This parameter is optional.&lt;/li>
&lt;li>Example: &lt;code>.withSchema(&amp;quot;PUBLIC&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>.withUsernamePasswordAuth(username, password)&lt;/code>
&lt;ul>
&lt;li>Sets username/password authentication.&lt;/li>
&lt;li>Example: &lt;code>.withUsernamePasswordAuth(&amp;quot;USERNAME&amp;quot;, &amp;quot;PASSWORD&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>.withOAuth(token)&lt;/code>
&lt;ul>
&lt;li>Sets OAuth authentication.&lt;/li>
&lt;li>Example: &lt;code>.withOAuth(&amp;quot;TOKEN&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>.withKeyPairAuth(username, privateKey)&lt;/code>
&lt;ul>
&lt;li>Sets key pair authentication using username and &lt;a href="https://docs.oracle.com/javase/8/docs/api/java/security/PrivateKey.html">PrivateKey&lt;/a>&lt;/li>
&lt;li>Example: &lt;code>.withKeyPairAuth(&amp;quot;USERNAME&amp;quot;,&lt;/code> &lt;a href="https://docs.oracle.com/javase/8/docs/api/java/security/PrivateKey.html">PrivateKey&lt;/a>&lt;code>)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>.withKeyPairPathAuth(username, privateKeyPath, privateKeyPassphrase)&lt;/code>
&lt;ul>
&lt;li>Sets key pair authentication using username, path to private key file and passphrase.&lt;/li>
&lt;li>Example: &lt;code>.withKeyPairPathAuth(&amp;quot;USERNAME&amp;quot;, &amp;quot;PATH/TO/KEY.P8&amp;quot;, &amp;quot;PASSPHRASE&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>.withKeyPairRawAuth(username, rawPrivateKey, privateKeyPassphrase)&lt;/code>
&lt;ul>
&lt;li>Sets key pair authentication using username, private key and passphrase.&lt;/li>
&lt;li>Example: &lt;code>.withKeyPairRawAuth(&amp;quot;USERNAME&amp;quot;, &amp;quot;PRIVATE_KEY&amp;quot;, &amp;quot;PASSPHRASE&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note&lt;/strong> - either &lt;code>.withUrl(...)&lt;/code> or &lt;code>.withServerName(...)&lt;/code> &lt;strong>is required&lt;/strong>.&lt;/p>
&lt;h2 id="pipeline-options">Pipeline options&lt;/h2>
&lt;p>Use Beam’s &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/options/PipelineOptions.html">Pipeline options&lt;/a> to set options via the command line.&lt;/p>
&lt;h3 id="snowflake-pipeline-options">Snowflake Pipeline options&lt;/h3>
&lt;p>Snowflake IO library supports following options that can be passed via the &lt;a href="https://beam.apache.org/documentation/io/built-in/snowflake/#running-main-command-with-pipeline-options">command line&lt;/a> by default when a Pipeline uses them:&lt;/p>
&lt;p>&lt;code>--url&lt;/code> Snowflake&amp;rsquo;s JDBC-like url including account name and region without any parameters.&lt;/p>
&lt;p>&lt;code>--serverName&lt;/code> Full server name with account, zone and domain.&lt;/p>
&lt;p>&lt;code>--username&lt;/code> Required for username/password and Private Key authentication.&lt;/p>
&lt;p>&lt;code>--oauthToken&lt;/code> Required for OAuth authentication only.&lt;/p>
&lt;p>&lt;code>--password&lt;/code> Required for username/password authentication only.&lt;/p>
&lt;p>&lt;code>--privateKeyPath&lt;/code> Path to Private Key file. Required for Private Key authentication only.&lt;/p>
&lt;p>&lt;code>--rawPrivateKey&lt;/code> Private Key. Required for Private Key authentication only.&lt;/p>
&lt;p>&lt;code>--privateKeyPassphrase&lt;/code> Private Key&amp;rsquo;s passphrase. Required for Private Key authentication only.&lt;/p>
&lt;p>&lt;code>--stagingBucketName&lt;/code> External bucket path ending with &lt;code>/&lt;/code>. I.e. &lt;code>gs://bucket/&lt;/code>. Sub-directories are allowed.&lt;/p>
&lt;p>&lt;code>--storageIntegrationName&lt;/code> Storage integration name&lt;/p>
&lt;p>&lt;code>--warehouse&lt;/code> Warehouse to use. Optional.&lt;/p>
&lt;p>&lt;code>--database&lt;/code> Database name to connect to. Optional.&lt;/p>
&lt;p>&lt;code>--schema&lt;/code> Schema to use. Optional.&lt;/p>
&lt;p>&lt;code>--table&lt;/code> Table to use. Optional.&lt;/p>
&lt;p>&lt;code>--query&lt;/code> Query to use. Optional.&lt;/p>
&lt;p>&lt;code>--role&lt;/code> Role to use. Optional.&lt;/p>
&lt;p>&lt;code>--authenticator&lt;/code> Authenticator to use. Optional.&lt;/p>
&lt;p>&lt;code>--portNumber&lt;/code> Port number. Optional.&lt;/p>
&lt;p>&lt;code>--loginTimeout&lt;/code> Login timeout. Optional.&lt;/p>
&lt;p>&lt;code>--snowPipe&lt;/code> SnowPipe name. Optional.&lt;/p>
&lt;h3 id="running-main-command-with-pipeline-options">Running main command with Pipeline options&lt;/h3>
&lt;p>To pass Pipeline options via the command line, use &lt;code>--args&lt;/code> in a gradle command as follows:&lt;/p>
&lt;p>
&lt;pre>&lt;code>./gradle run
--args=&amp;#34;
--serverName=&amp;lt;SNOWFLAKE SERVER NAME&amp;gt;
Example: --serverName=account.region.gcp.snowflakecomputing.com
--username=&amp;lt;SNOWFLAKE USERNAME&amp;gt;
Example: --username=testuser
--password=&amp;lt;SNOWFLAKE PASSWORD&amp;gt;
Example: --password=mypassword
--database=&amp;lt;SNOWFLAKE DATABASE&amp;gt;
Example: --database=TEST_DATABASE
--schema=&amp;lt;SNOWFLAKE SCHEMA&amp;gt;
Example: --schema=public
--table=&amp;lt;SNOWFLAKE TABLE IN DATABASE&amp;gt;
Example: --table=TEST_TABLE
--query=&amp;lt;IF NOT TABLE THEN QUERY&amp;gt;
Example: --query=‘SELECT column FROM TABLE’
--storageIntegrationName=&amp;lt;SNOWFLAKE STORAGE INTEGRATION NAME&amp;gt;
Example: --storageIntegrationName=my_integration
--stagingBucketName=&amp;lt;GCS BUCKET NAME&amp;gt;
Example: --stagingBucketName=gs://my_gcp_bucket/
--runner=&amp;lt;DirectRunner/DataflowRunner&amp;gt;
Example: --runner=DataflowRunner
--project=&amp;lt;FOR DATAFLOW RUNNER: GCP PROJECT NAME&amp;gt;
Example: --project=my_project
--tempLocation=&amp;lt;FOR DATAFLOW RUNNER: GCS TEMP LOCATION STARTING
WITH gs://…&amp;gt;
Example: --tempLocation=gs://my_bucket/temp/
--region=&amp;lt;FOR DATAFLOW RUNNER: GCP REGION&amp;gt;
Example: --region=us-east-1
--appName=&amp;lt;OPTIONAL: DATAFLOW JOB NAME PREFIX&amp;gt;
Example: --appName=my_job&amp;#34;&lt;/code>&lt;/pre>
Then in the code it is possible to access the parameters with arguments using the options.getStagingBucketName(); command.&lt;/p>
&lt;h3 id="running-test-command-with-pipeline-options">Running test command with Pipeline options&lt;/h3>
&lt;p>To pass Pipeline options via the command line, use &lt;code>-DintegrationTestPipelineOptions&lt;/code> in a gradle command as follows:
&lt;pre>&lt;code>./gradlew test --tests nameOfTest
-DintegrationTestPipelineOptions=&amp;#39;[
&amp;#34;--serverName=&amp;lt;SNOWFLAKE SERVER NAME&amp;gt;&amp;#34;,
Example: --serverName=account.region.gcp.snowflakecomputing.com
&amp;#34;--username=&amp;lt;SNOWFLAKE USERNAME&amp;gt;&amp;#34;,
Example: --username=testuser
&amp;#34;--password=&amp;lt;SNOWFLAKE PASSWORD&amp;gt;&amp;#34;,
Example: --password=mypassword
&amp;#34;--schema=&amp;lt;SNOWFLAKE SCHEMA&amp;gt;&amp;#34;,
Example: --schema=PUBLIC
&amp;#34;--table=&amp;lt;SNOWFLAKE TABLE IN DATABASE&amp;gt;&amp;#34;,
Example: --table=TEST_TABLE
&amp;#34;--database=&amp;lt;SNOWFLAKE DATABASE&amp;gt;&amp;#34;,
Example: --database=TEST_DATABASE
&amp;#34;--storageIntegrationName=&amp;lt;SNOWFLAKE STORAGE INTEGRATION NAME&amp;gt;&amp;#34;,
Example: --storageIntegrationName=my_integration
&amp;#34;--stagingBucketName=&amp;lt;GCS BUCKET NAME&amp;gt;&amp;#34;,
Example: --stagingBucketName=gs://my_gcp_bucket
&amp;#34;--externalLocation=&amp;lt;GCS BUCKET URL STARTING WITH GS://&amp;gt;&amp;#34;,
Example: --tempLocation=gs://my_bucket/temp/
]&amp;#39; --no-build-cache&lt;/code>&lt;/pre>
&lt;/p>
&lt;p>Where all parameters are starting with “&amp;ndash;”, they are surrounded with double quotation and separated with comma:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>--serverName=&amp;lt;SNOWFLAKE SERVER NAME&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Specifies the full name of your account (provided by Snowflake). Note that your full account name might include additional segments that identify the region and cloud platform where your account is hosted.&lt;/li>
&lt;li>Example: &lt;code>--serverName=xy12345.eu-west-1.gcp..snowflakecomputing.com&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--username=&amp;lt;SNOWFLAKE USERNAME&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Specifies the login name of the user.&lt;/li>
&lt;li>Example: &lt;code>--username=my_username&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--password=&amp;lt;SNOWFLAKE PASSWORD&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Specifies the password for the specified user.&lt;/li>
&lt;li>Example: &lt;code>--password=my_secret&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--schema=&amp;lt;SNOWFLAKE SCHEMA&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Specifies the schema to use for the specified database once connected. The specified schema should be an existing schema for which the specified user’s role has privileges.&lt;/li>
&lt;li>Example: &lt;code>--schema=PUBLIC&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--table=&amp;lt;SNOWFLAKE TABLE IN DATABASE&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Example: &lt;code>--table=MY_TABLE&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--database=&amp;lt;SNOWFLAKE DATABASE&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Specifies the database to use once connected. The specified database should be an existing database for which the specified user’s role has privileges.&lt;/li>
&lt;li>Example: &lt;code>--database=MY_DATABASE&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--storageIntegrationName=&amp;lt;SNOWFLAKE STORAGE INTEGRATION NAME&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Name of storage integration created in &lt;a href="https://docs.snowflake.com/en/sql-reference/sql/create-storage-integration.html">Snowflake&lt;/a> for a cloud storage of choice.&lt;/li>
&lt;li>Example: &lt;code>--storageIntegrationName=my_google_integration&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="running-pipelines-on-dataflow">Running pipelines on Dataflow&lt;/h2>
&lt;p>By default, pipelines are run on &lt;a href="https://beam.apache.org/documentation/runners/direct/">Direct Runner&lt;/a> on your local machine. To run a pipeline on &lt;a href="https://cloud.google.com/dataflow/">Google Dataflow&lt;/a>, you must provide the following Pipeline options:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>--runner=DataflowRunner&lt;/code>&lt;/p>
&lt;ul>
&lt;li>The Dataflow’s specific runner.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--project=&amp;lt;GCS PROJECT&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Name of the Google Cloud Platform project.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--stagingBucketName=&amp;lt;GCS BUCKET NAME&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Google Cloud Services bucket where the Beam files will be staged.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--maxNumWorkers=5&lt;/code>&lt;/p>
&lt;ul>
&lt;li>(optional) Maximum number of workers.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--appName=&amp;lt;JOB NAME&amp;gt;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>(optional) Prefix for the job name in the Dataflow Dashboard.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>More pipeline options for Dataflow can be found &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/runners/dataflow/options/DataflowPipelineOptions.html">here&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Note&lt;/strong>: To properly authenticate with Google Cloud, please use &lt;a href="https://cloud.google.com/sdk/gcloud/">gcloud&lt;/a> or follow the &lt;a href="https://cloud.google.com/docs/authentication/">Google Cloud documentation&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Important&lt;/strong>: Please acknowledge &lt;a href="https://cloud.google.com/dataflow/pricing">Google Dataflow pricing&lt;/a>&lt;/p>
&lt;h3 id="running-pipeline-templates-on-dataflow">Running pipeline templates on Dataflow&lt;/h3>
&lt;p>Google Dataflow is supporting &lt;a href="https://cloud.google.com/dataflow/docs/guides/templates/overview">template&lt;/a> creation which means staging pipelines on Cloud Storage and running them with ability to pass runtime parameters that are only available during pipeline execution.&lt;/p>
&lt;p>The process of creating own Dataflow template is following&lt;/p>
&lt;ol>
&lt;li>Create your own pipeline.&lt;/li>
&lt;li>Create &lt;a href="https://cloud.google.com/dataflow/docs/guides/templates/creating-templates#creating-and-staging-templates">Dataflow template&lt;/a> with checking which options SnowflakeIO is supporting at runtime.&lt;/li>
&lt;li>Run a Dataflow template using &lt;a href="https://cloud.google.com/dataflow/docs/guides/templates/running-templates#using-the-cloud-console">Cloud Console&lt;/a>, &lt;a href="https://cloud.google.com/dataflow/docs/guides/templates/running-templates#using-the-rest-api">REST API&lt;/a> or &lt;a href="https://cloud.google.com/dataflow/docs/guides/templates/running-templates#using-gcloud">gcloud&lt;/a>.&lt;/li>
&lt;/ol>
&lt;p>Currently, SnowflakeIO supports following options at runtime:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>--serverName&lt;/code> Full server name with account, zone and domain.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--username&lt;/code> Required for username/password and Private Key authentication.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--password&lt;/code> Required for username/password authentication only.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--rawPrivateKey&lt;/code> Private Key file. Required for Private Key authentication only.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--privateKeyPassphrase&lt;/code> Private Key&amp;rsquo;s passphrase. Required for Private Key authentication only.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--stagingBucketName&lt;/code> external bucket path ending with &lt;code>/&lt;/code>. I.e. &lt;code>gs://bucket/&lt;/code>. Sub-directories are allowed.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--storageIntegrationName&lt;/code> Storage integration name.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--warehouse&lt;/code> Warehouse to use. Optional.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--database&lt;/code> Database name to connect to. Optional.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--schema&lt;/code> Schema to use. Optional.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--table&lt;/code> Table to use. Optional. Note: table is not in default pipeline options.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--query&lt;/code> Query to use. Optional. Note: query is not in default pipeline options.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--role&lt;/code> Role to use. Optional.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--snowPipe&lt;/code> SnowPipe name. Optional.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note&lt;/strong>: table and query is not in pipeline options by default, it may be added by &lt;a href="https://beam.apache.org/documentation/io/built-in/snowflake/#extending-pipeline-options">extending&lt;/a> PipelineOptions.&lt;/p>
&lt;p>Currently, SnowflakeIO &lt;strong>doesn&amp;rsquo;t support&lt;/strong> following options at runtime:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>--url&lt;/code> Snowflake&amp;rsquo;s JDBC-like url including account name and region without any parameters.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--oauthToken&lt;/code> Required for OAuth authentication only.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--privateKeyPath&lt;/code> Path to Private Key file. Required for Private Key authentication only.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--authenticator&lt;/code> Authenticator to use. Optional.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--portNumber&lt;/code> Port number. Optional.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--loginTimeout&lt;/code> Login timeout. Optional.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="writing-to-snowflake-tables">Writing to Snowflake tables&lt;/h2>
&lt;p>One of the functions of SnowflakeIO is writing to Snowflake tables. This transformation enables you to finish the Beam pipeline with an output operation that sends the user&amp;rsquo;s &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/values/PCollection.html">PCollection&lt;/a> to your Snowflake database.&lt;/p>
&lt;h3 id="batch-write-from-a-bounded-source">Batch write (from a bounded source)&lt;/h3>
&lt;p>The basic .&lt;code>write()&lt;/code> operation usage is as follows:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">type&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDataSourceConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dc&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">toTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;MY_TABLE&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStagingBucketName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;BUCKET NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStorageIntegrationName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STORAGE INTEGRATION NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withUserDataMapper&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mapper&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
Replace type with the data type of the PCollection object to write; for example, SnowflakeIO.&lt;String> for an input PCollection of Strings.&lt;/p>
&lt;p>All the below parameters are required:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>.withDataSourceConfiguration()&lt;/code> Accepts a DatasourceConfiguration object.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.toTable()&lt;/code> Accepts the target Snowflake table name.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withStagingBucketName()&lt;/code> Accepts a cloud bucket path ended with slash.
-Example: &lt;code>.withStagingBucketName(&amp;quot;gs://mybucket/my/dir/&amp;quot;)&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withStorageIntegrationName()&lt;/code> Accepts a name of a Snowflake storage integration object created according to Snowflake documentationt. Example:
&lt;pre>&lt;code>CREATE OR REPLACE STORAGE INTEGRATION test_integration
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = GCS
ENABLED = TRUE
STORAGE_ALLOWED_LOCATIONS = (&amp;#39;gcs://bucket/&amp;#39;);&lt;/code>&lt;/pre>
Then:
&lt;pre>&lt;code>.withStorageIntegrationName(test_integration)&lt;/code>&lt;/pre>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withUserDataMapper()&lt;/code> Accepts the UserDataMapper function that will map a user&amp;rsquo;s PCollection to an array of String values &lt;code>(String[])&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note&lt;/strong>:
SnowflakeIO uses COPY statements behind the scenes to write (using &lt;a href="https://docs.snowflake.net/manuals/sql-reference/sql/copy-into-table.html">COPY to table&lt;/a>). StagingBucketName will be used to save CSV files which will end up in Snowflake. Those CSV files will be saved under the “stagingBucketName” path.&lt;/p>
&lt;p>&lt;strong>Optional&lt;/strong> for batching:&lt;/p>
&lt;ul>
&lt;li>&lt;code>.withQuotationMark()&lt;/code>
&lt;ul>
&lt;li>Default value: &lt;code>‘&lt;/code> (single quotation mark).&lt;/li>
&lt;li>Accepts String with one character. It will surround all text (String) fields saved to CSV. It should be one of the accepted characters by &lt;a href="https://docs.snowflake.com/en/sql-reference/sql/create-file-format.html">Snowflake’s&lt;/a> &lt;a href="https://docs.snowflake.com/en/sql-reference/sql/create-file-format.html">FIELD_OPTIONALLY_ENCLOSED_BY&lt;/a> parameter (double quotation mark, single quotation mark or none).&lt;/li>
&lt;li>Example: &lt;code>.withQuotationMark(&amp;quot;'&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="streaming-write--from-unbounded-source">Streaming write (from unbounded source)&lt;/h3>
&lt;p>It is required to create a &lt;a href="https://docs.snowflake.com/en/user-guide/data-load-snowpipe.html">SnowPipe&lt;/a> in the Snowflake console. SnowPipe should use the same integration and the same bucket as specified by .withStagingBucketName and .withStorageIntegrationName methods. The write operation might look as follows:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">type&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStagingBucketName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;BUCKET NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStorageIntegrationName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STORAGE INTEGRATION NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDataSourceConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dc&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withUserDataMapper&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mapper&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withSnowPipe&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;MY_SNOW_PIPE&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withFlushTimeLimit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">millis&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">time&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withFlushRowLimit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">rowsNumber&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withShardsNumber&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">shardsNumber&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;h4 id="parameters">Parameters&lt;/h4>
&lt;p>&lt;strong>Required&lt;/strong> for streaming:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code> .withDataSourceConfiguration()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Accepts a DatasourceConfiguration object.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.toTable()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Accepts the target Snowflake table name.&lt;/li>
&lt;li>Example: &lt;code>.toTable(&amp;quot;MY_TABLE)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withStagingBucketName()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Accepts a cloud bucket path ended with slash.&lt;/li>
&lt;li>Example: &lt;code>.withStagingBucketName(&amp;quot;gs://mybucket/my/dir/&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withStorageIntegrationName()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Accepts a name of a Snowflake storage integration object created according to Snowflake documentationt.&lt;/li>
&lt;li>Example:
&lt;pre>&lt;code>CREATE OR REPLACE STORAGE INTEGRATION test_integration
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = GCS
ENABLED = TRUE
STORAGE_ALLOWED_LOCATIONS = (&amp;#39;gcs://bucket/&amp;#39;);&lt;/code>&lt;/pre>
Then:
&lt;pre>&lt;code>.withStorageIntegrationName(test_integration)&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withSnowPipe()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Accepts the target SnowPipe name. &lt;code>.withSnowPipe()&lt;/code> accepts the exact name of snowpipe.
Example:
&lt;pre>&lt;code>CREATE OR REPLACE PIPE test_database.public.test_gcs_pipe
AS COPY INTO stream_table from @streamstage;&lt;/code>&lt;/pre>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Then:
&lt;pre>&lt;code>.withSnowPipe(test_gcs_pipe)&lt;/code>&lt;/pre>
&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note&lt;/strong>: this is important to provide &lt;strong>schema&lt;/strong> and &lt;strong>database&lt;/strong> names.&lt;/p>
&lt;ul>
&lt;li>&lt;code>.withUserDataMapper()&lt;/code>
&lt;ul>
&lt;li>Accepts the &lt;a href="https://beam.apache.org/documentation/io/built-in/snowflake/#userdatamapper-function">UserDataMapper&lt;/a> function that will map a user&amp;rsquo;s PCollection to an array of String values &lt;code>(String[]).&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note&lt;/strong>:&lt;/p>
&lt;p>SnowflakeIO uses COPY statements behind the scenes to write (using &lt;a href="https://docs.snowflake.net/manuals/sql-reference/sql/copy-into-table.html">COPY to table&lt;/a>). StagingBucketName will be used to save CSV files which will end up in Snowflake. Those CSV files will be saved under the “stagingBucketName” path.&lt;/p>
&lt;p>&lt;strong>Optional&lt;/strong> for streaming:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>.withFlushTimeLimit()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Default value: 30 seconds&lt;/li>
&lt;li>Accepts Duration objects with the specified time after each the streaming write will be repeated&lt;/li>
&lt;li>Example: &lt;code>.withFlushTimeLimit(Duration.millis(180000))&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withFlushRowLimit()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Default value: 10,000 rows&lt;/li>
&lt;li>Limit of rows written to each staged file&lt;/li>
&lt;li>Example: &lt;code>.withFlushRowLimit(500000)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withShardNumber()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Default value: 1 shard&lt;/li>
&lt;li>Number of files that will be saved in every flush (for purposes of parallel write).&lt;/li>
&lt;li>Example: &lt;code>.withShardNumber(5)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withQuotationMark()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Default value: &lt;code>‘&lt;/code> (single quotation mark).&lt;/li>
&lt;li>Accepts String with one character. It will surround all text (String) fields saved to CSV. It should be one of the accepted characters by &lt;a href="https://docs.snowflake.com/en/sql-reference/sql/create-file-format.html">Snowflake’s&lt;/a> &lt;a href="https://docs.snowflake.com/en/sql-reference/sql/create-file-format.html">FIELD_OPTIONALLY_ENCLOSED_BY&lt;/a> parameter (double quotation mark, single quotation mark or none). Example: .withQuotationMark(&amp;quot;&amp;quot;) (no quotation marks)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withDebugMode()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Accepts:
&lt;ul>
&lt;li>&lt;code>SnowflakeIO.StreamingLogLevel.INFO&lt;/code> - shows whole info about loaded files&lt;/li>
&lt;li>&lt;code>SnowflakeIO.StreamingLogLevel.ERROR&lt;/code> - shows only errors.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Shows logs about streamed files to Snowflake similarly to &lt;a href="https://docs.snowflake.com/en/user-guide/data-load-snowpipe-rest-apis.html#endpoint-insertreport">insertReport&lt;/a>. Enabling debug mode may influence performance.&lt;/li>
&lt;li>Example: &lt;code>.withDebugMode(SnowflakeIO.StreamingLogLevel.INFO)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Important notice&lt;/strong>: Streaming accepts only &lt;strong>key pair authentication&lt;/strong>.&lt;/p>
&lt;h4 id="flush-time-duration--number-of-rows">Flush time: duration &amp;amp; number of rows&lt;/h4>
&lt;p>Duration: streaming write will write periodically files on stage according to time duration specified in flush time limit (for example. every 1 minute).&lt;/p>
&lt;p>Number of rows: files staged for write will have number of rows specified in flush row limit unless the flush time limit will be reached (for example if the limit is 1000 rows and buffor collected 99 rows and the 1 minute flush time passes, the rows will be sent to SnowPipe for insertion).&lt;/p>
&lt;p>Size of staged files will depend on the rows size and used compression (GZIP).&lt;/p>
&lt;h3 id="userdatamapper-function">UserDataMapper function&lt;/h3>
&lt;p>The UserDataMapper function is required to map data from a PCollection to an array of String values before the &lt;code>write()&lt;/code> operation saves the data to temporary .csv files. For example:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">UserDataMapper&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">getCsvMapper&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">UserDataMapper&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;)&lt;/span> &lt;span class="n">recordLine&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="o">{&lt;/span>&lt;span class="n">recordLine&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">()};&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;h3 id="additional-write-options">Additional write options&lt;/h3>
&lt;h4 id="transformation-query">Transformation query&lt;/h4>
&lt;p>The &lt;code>.withQueryTransformation()&lt;/code> option for the &lt;code>write()&lt;/code> operation accepts a SQL query as a String value, which will be performed while transfering data staged in CSV files directly to the target Snowflake table. For information about the transformation SQL syntax, see the &lt;a href="https://docs.snowflake.net/manuals/sql-reference/sql/copy-into-table.html#transformation-parameters">Snowflake Documentation&lt;/a>.&lt;/p>
&lt;p>Usage:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">String&lt;/span> &lt;span class="n">query&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;SELECT t.$1 from YOUR_TABLE;&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&amp;lt;~&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDataSourceConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dc&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">toTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;MY_TABLE&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStagingBucketName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;BUCKET NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStorageIntegrationName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STORAGE INTEGRATION NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withUserDataMapper&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mapper&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withQueryTransformation&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">query&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;h4 id="write-disposition">Write disposition&lt;/h4>
&lt;p>Define the write behaviour based on the table where data will be written to by specifying the &lt;code>.withWriteDisposition(...)&lt;/code> option for the &lt;code>write()&lt;/code> operation. The following values are supported:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>APPEND - Default behaviour. Written data is added to the existing rows in the table,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>EMPTY - The target table must be empty; otherwise, the write operation fails,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>TRUNCATE - The write operation deletes all rows from the target table before writing to it.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Example of usage:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&amp;lt;~&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDataSourceConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dc&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">toTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;MY_TABLE&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStagingBucketName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;BUCKET NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStorageIntegrationName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STORAGE INTEGRATION NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withUserDataMapper&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mapper&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withWriteDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TRUNCATE&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;h4 id="create-disposition">Create disposition&lt;/h4>
&lt;p>The &lt;code>.withCreateDisposition()&lt;/code> option defines the behavior of the write operation if the target table does not exist . The following values are supported:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>CREATE_IF_NEEDED - default behaviour. The write operation checks whether the specified target table exists; if it does not, the write operation attempts to create the table Specify the schema for the target table using the &lt;code>.withTableSchema()&lt;/code> option.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>CREATE_NEVER - The write operation fails if the target table does not exist.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Usage:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&amp;lt;~&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDataSourceConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dc&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">toTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;MY_TABLE&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStagingBucketName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;BUCKET NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStorageIntegrationName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STORAGE INTEGRATION NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withUserDataMapper&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mapper&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withCreateDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CREATE_NEVER&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;h4 id="table-schema-disposition">Table schema disposition&lt;/h4>
&lt;p>When the &lt;code>.withCreateDisposition()&lt;/code> .option is set to &lt;code>CREATE_IF_NEEDED&lt;/code>, the &lt;code>.withTableSchema()&lt;/code> option enables specifying the schema for the created target table.
A table schema is a list of &lt;code>SFColumn&lt;/code> objects with name and type corresponding to column type for each column in the table.&lt;/p>
&lt;p>Usage:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">SFTableSchema&lt;/span> &lt;span class="n">tableSchema&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">SFTableSchema&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">SFColumn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;my_date&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">SFDate&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">SFColumn&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;id&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">SFNumber&lt;/span>&lt;span class="o">()),&lt;/span>
&lt;span class="n">SFColumn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">SFText&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&amp;lt;~&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDataSourceConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dc&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">toTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;MY_TABLE&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStagingBucketName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;BUCKET NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStorageIntegrationName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STORAGE INTEGRATION NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withUserDataMapper&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mapper&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withTableSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableSchema&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;h2 id="reading-from-snowflake">Reading from Snowflake&lt;/h2>
&lt;p>One of the functions of SnowflakeIO is reading Snowflake tables - either full tables via table name or custom data via query. Output of the read transform is a &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/values/PCollection.html">PCollection&lt;/a> of user-defined data type.&lt;/p>
&lt;h3 id="general-usage-1">General usage&lt;/h3>
&lt;p>The basic &lt;code>.read()&lt;/code> operation usage:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">USER_DATA_TYPE&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">USER_DATA_TYPE&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withDataSourceConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dc&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">fromTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;MY_TABLE&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="c1">// or .fromQuery(&amp;#34;QUERY&amp;#34;)
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withStagingBucketName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;BUCKET NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withStorageIntegrationName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STORAGE INTEGRATION NAME&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withCsvMapper&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mapper&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withCoder&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">coder&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="o">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
Where all below parameters are required:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>.withDataSourceConfiguration(...)&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Accepts a DataSourceConfiguration object.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.fromTable(...) or .fromQuery(...)&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Specifies a Snowflake table name or custom SQL query.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withStagingBucketName()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Accepts a cloud bucket name.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withStorageIntegrationName()&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Accepts a name of a Snowflake storage integration object created according to Snowflake documentation. Example:
&lt;pre>&lt;code>CREATE OR REPLACE STORAGE INTEGRATION test_integration
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = GCS
ENABLED = TRUE
STORAGE_ALLOWED_LOCATIONS = (&amp;#39;gcs://bucket/&amp;#39;);&lt;/code>&lt;/pre>
Then:
&lt;pre>&lt;code>.withStorageIntegrationName(test_integration)&lt;/code>&lt;/pre>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withCsvMapper(mapper)&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Accepts a &lt;a href="https://beam.apache.org/documentation/io/built-in/snowflake/#csvmapper">CSVMapper&lt;/a> instance for mapping String[] to USER_DATA_TYPE.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.withCoder(coder)&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Accepts the &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/coders/Coder.html">Coder&lt;/a> for USER_DATA_TYPE.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note&lt;/strong>:
SnowflakeIO uses COPY statements behind the scenes to read (using &lt;a href="https://docs.snowflake.net/manuals/sql-reference/sql/copy-into-location.html">COPY to location&lt;/a>) files staged in cloud storage.StagingBucketName will be used as a temporary location for storing CSV files. Those temporary directories will be named &lt;code>sf_copy_csv_DATE_TIME_RANDOMSUFFIX&lt;/code> and they will be removed automatically once Read operation finishes.&lt;/p>
&lt;h3 id="csvmapper">CSVMapper&lt;/h3>
&lt;p>SnowflakeIO uses a &lt;a href="https://docs.snowflake.net/manuals/sql-reference/sql/copy-into-location.html">COPY INTO &lt;location>&lt;/a> statement to move data from a Snowflake table to Google Cloud Storage as CSV files. These files are then downloaded via &lt;a href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/io/FileIO.html">FileIO&lt;/a> and processed line by line. Each line is split into an array of Strings using the &lt;a href="http://opencsv.sourceforge.net/">OpenCSV&lt;/a> library.&lt;/p>
&lt;p>The CSVMapper’s job is to give the user the possibility to convert the array of Strings to a user-defined type, ie. GenericRecord for Avro or Parquet files, or custom POJO.&lt;/p>
&lt;p>Example implementation of CsvMapper for GenericRecord:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">static&lt;/span> &lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CsvMapper&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">GenericRecord&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">getCsvMapper&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">SnowflakeIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CsvMapper&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">GenericRecord&lt;/span>&lt;span class="o">&amp;gt;)&lt;/span>
&lt;span class="n">parts&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">GenericRecordBuilder&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">PARQUET_SCHEMA&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;ID&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">parts&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">]))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;NAME&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">parts&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">])&lt;/span>
&lt;span class="o">[...]&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">};&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;h2 id="using-snowflakeio-in-python-sdk">Using SnowflakeIO in Python SDK&lt;/h2>
&lt;h3 id="intro">Intro&lt;/h3>
&lt;p>Snowflake cross-language implementation is supporting both reading and writing operations for Python programming language, thanks to
cross-language which is part of &lt;a href="https://beam.apache.org/roadmap/portability/">Portability Framework Roadmap&lt;/a> which aims to provide full interoperability
across the Beam ecosystem. From a developer perspective it means the possibility of combining transforms written in different languages(Java/Python/Go).&lt;/p>
&lt;p>For more information about cross-language please see &lt;a href="https://beam.apache.org/roadmap/connectors-multi-sdk/">multi sdk efforts&lt;/a>
and &lt;a href="https://beam.apache.org/roadmap/connectors-multi-sdk/#cross-language-transforms-api-and-expansion-service">Cross-language transforms API and expansion service&lt;/a> articles.&lt;/p>
&lt;h3 id="reading-from-snowflake-1">Reading from Snowflake&lt;/h3>
&lt;p>One of the functions of SnowflakeIO is reading Snowflake tables - either full tables via table name or custom data via query. Output of the read transform is a &lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.pvalue.html#apache_beam.pvalue.PCollection">PCollection&lt;/a> of user-defined data type.&lt;/p>
&lt;h4 id="general-usage-2">General usage&lt;/h4>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">OPTIONS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;--runner=FlinkRunner&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">TestPipeline&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">PipelineOptions&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">OPTIONS&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">ReadFromSnowflake&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">FURTHER&lt;/span> &lt;span class="n">TRANSFORMS&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="required-parameters">Required parameters&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>&lt;code>server_name&lt;/code> Full Snowflake server name with an account, zone, and domain.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>schema&lt;/code> Name of the Snowflake schema in the database to use.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>database&lt;/code> Name of the Snowflake database to use.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>staging_bucket_name&lt;/code> Name of the Google Cloud Storage bucket. Bucket will be used as a temporary location for storing CSV files. Those temporary directories will be named &lt;code>sf_copy_csv_DATE_TIME_RANDOMSUFFIX&lt;/code> and they will be removed automatically once Read operation finishes.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>storage_integration_name&lt;/code> Is the name of a Snowflake storage integration object created according to &lt;a href="https://docs.snowflake.net/manuals/sql-reference/sql/create-storage-integration.html">Snowflake documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>csv_mapper&lt;/code> Specifies a function which must translate user-defined object to array of strings. SnowflakeIO uses a &lt;a href="https://docs.snowflake.net/manuals/sql-reference/sql/copy-into-location.html">COPY INTO &lt;location>&lt;/a> statement to move data from a Snowflake table to Google Cloud Storage as CSV files. These files are then downloaded via &lt;a href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/io/FileIO.html">FileIO&lt;/a> and processed line by line. Each line is split into an array of Strings using the &lt;a href="http://opencsv.sourceforge.net/">OpenCSV&lt;/a> library. The csv_mapper function job is to give the user the possibility to convert the array of Strings to a user-defined type, ie. GenericRecord for Avro or Parquet files, or custom objects.
Example:
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">def&lt;/span> &lt;span class="nf">csv_mapper&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">strings_array&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">User&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">strings_array&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">strings_array&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>table&lt;/code> or &lt;code>query&lt;/code> Specifies a Snowflake table name or custom SQL query&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="authentication-parameters">Authentication parameters&lt;/h4>
&lt;p>It’s required to pass one of the following combinations of valid parameters for authentication:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>username&lt;/code> and &lt;code>password&lt;/code> Specifies username and password for username/password authentication method.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>private_key_path&lt;/code> and &lt;code>private_key_passphrase&lt;/code> Specifies a path to private key and passphrase for key/pair authentication method.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>raw_private_key&lt;/code> and &lt;code>private_key_passphrase&lt;/code> Specifies a private key and passphrase for key/pair authentication method.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>o_auth_token&lt;/code> Specifies access token for OAuth authentication method.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="additional-parameters">Additional parameters&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>&lt;code>role&lt;/code> specifies Snowflake role. If not specified the user&amp;rsquo;s default will be used.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>warehouse&lt;/code> specifies Snowflake warehouse name. If not specified the user&amp;rsquo;s default will be used.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>expansion_service&lt;/code> specifies URL of expansion service.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="writing-to-snowflake">Writing to Snowflake&lt;/h3>
&lt;p>One of the functions of SnowflakeIO is writing to Snowflake tables. This transformation enables you to finish the Beam pipeline with an output operation that sends the user&amp;rsquo;s &lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.pvalue.html#apache_beam.pvalue.PCollection">PCollection&lt;/a> to your Snowflake database.&lt;/p>
&lt;h4 id="general-usage-3">General usage&lt;/h4>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">OPTIONS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;--runner=FlinkRunner&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">TestPipeline&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">PipelineOptions&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">OPTIONS&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">SOURCE&lt;/span> &lt;span class="n">OF&lt;/span> &lt;span class="n">DATA&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">WriteToSnowflake&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">server_name&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">SERVER&lt;/span> &lt;span class="n">NAME&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">username&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">USERNAME&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">password&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">PASSWORD&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">o_auth_token&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">OAUTH&lt;/span> &lt;span class="n">TOKEN&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">private_key_path&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">PATH&lt;/span> &lt;span class="n">TO&lt;/span> &lt;span class="n">P8&lt;/span> &lt;span class="n">FILE&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">raw_private_key&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">PRIVATE_KEY&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="n">private_key_passphrase&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">PASSWORD&lt;/span> &lt;span class="n">FOR&lt;/span> &lt;span class="n">KEY&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">schema&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">SCHEMA&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">database&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">DATABASE&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">staging_bucket_name&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">GCS&lt;/span> &lt;span class="n">BUCKET&lt;/span> &lt;span class="n">NAME&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">storage_integration_name&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">STORAGE&lt;/span> &lt;span class="n">INTEGRATION&lt;/span> &lt;span class="n">NAME&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">create_disposition&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">CREATE&lt;/span> &lt;span class="n">DISPOSITION&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">write_disposition&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">WRITE&lt;/span> &lt;span class="n">DISPOSITION&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">table_schema&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">TABLE&lt;/span> &lt;span class="n">SCHEMA&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">user_data_mapper&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">USER&lt;/span> &lt;span class="n">DATA&lt;/span> &lt;span class="n">MAPPER&lt;/span> &lt;span class="n">FUNCTION&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">table&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">TABLE&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">query&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">IF&lt;/span> &lt;span class="n">NOT&lt;/span> &lt;span class="n">TABLE&lt;/span> &lt;span class="n">THEN&lt;/span> &lt;span class="n">QUERY&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">role&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">ROLE&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">warehouse&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">SNOWFLAKE&lt;/span> &lt;span class="n">WAREHOUSE&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">expansion_service&lt;/span>&lt;span class="o">=&amp;lt;&lt;/span>&lt;span class="n">EXPANSION&lt;/span> &lt;span class="n">SERVICE&lt;/span> &lt;span class="n">ADDRESS&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="required-parameters-1">Required parameters&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>&lt;code>server_name&lt;/code> Full Snowflake server name with account, zone and domain.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>schema&lt;/code> Name of the Snowflake schema in the database to use.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>database&lt;/code> Name of the Snowflake database to use.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>staging_bucket_name&lt;/code> Path to Google Cloud Storage bucket ended with slash. Bucket will be used to save CSV files which will end up in Snowflake. Those CSV files will be saved under “staging_bucket_name” path.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>storage_integration_name&lt;/code> Is the name of a Snowflake storage integration object created according to &lt;a href="https://docs.snowflake.net/manuals/sql-reference/sql/create-storage-integration.html">Snowflake documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>user_data_mapper&lt;/code> Specifies a function which maps data from a PCollection to an array of String values before the write operation saves the data to temporary .csv files.
Example:
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">def&lt;/span> &lt;span class="nf">user_data_mapper&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">user&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">user&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">user&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">age&lt;/span>&lt;span class="p">)]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>table&lt;/code> or &lt;code>query&lt;/code> Specifies a Snowflake table name or custom SQL query&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="authentication-parameters-1">Authentication parameters&lt;/h4>
&lt;p>It’s required to pass one of the following combination of valid parameters for authentication:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>username&lt;/code> and &lt;code>password&lt;/code> Specifies username/password authentication method.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>private_key_path&lt;/code> and &lt;code>private_key_passphrase&lt;/code> Specifies a path to private key and passphrase for key/pair authentication method.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>raw_private_key&lt;/code> and &lt;code>private_key_passphrase&lt;/code> Specifies a private key and passphrase for key/pair authentication method.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>o_auth_token&lt;/code> Specifies access token for OAuth authentication method.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="additional-parameters-1">Additional parameters&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>&lt;code>role&lt;/code> specifies Snowflake role. If not specified the user&amp;rsquo;s default will be used.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>warehouse&lt;/code> specifies Snowflake warehouse name. If not specified the user&amp;rsquo;s default will be used.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>create_disposition&lt;/code> Defines the behaviour of the write operation if the target table does not exist. The following values are supported:&lt;/p>
&lt;ul>
&lt;li>CREATE_IF_NEEDED - default behaviour. The write operation checks whether the specified target table exists; if it does not, the write operation attempts to create the table Specify the schema for the target table using the table_schema parameter.&lt;/li>
&lt;li>CREATE_NEVER - The write operation fails if the target table does not exist.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>write_disposition&lt;/code> Defines the write behaviour based on the table where data will be written to. The following values are supported:&lt;/p>
&lt;ul>
&lt;li>APPEND - Default behaviour. Written data is added to the existing rows in the table,&lt;/li>
&lt;li>EMPTY - The target table must be empty; otherwise, the write operation fails,&lt;/li>
&lt;li>TRUNCATE - The write operation deletes all rows from the target table before writing to it.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>table_schema&lt;/code> When the &lt;code>create_disposition&lt;/code> parameter is set to CREATE_IF_NEEDED, the table_schema parameter enables specifying the schema for the created target table. A table schema is a JSON array with the following structure:
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;schema&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s2">&amp;#34;dataType&amp;#34;&lt;/span>&lt;span class="p">:{&lt;/span>&lt;span class="s2">&amp;#34;type&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="s2">&amp;#34;&amp;lt;COLUMN DATA TYPE&amp;gt;&amp;#34;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="s2">&amp;#34;&amp;lt;COLUMN NAME&amp;gt; &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;nullable&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">NULLABLE&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="p">]}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
All supported data types:
&lt;pre>&lt;code>{&amp;#34;type&amp;#34;:&amp;#34;date&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;datetime&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;time&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;timestamp&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;timestamp_ltz&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;timestamp_ntz&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;timestamp_tz&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;boolean&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;decimal&amp;#34;,&amp;#34;precision&amp;#34;:38,&amp;#34;scale&amp;#34;:1},
{&amp;#34;type&amp;#34;:&amp;#34;double&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;float&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;integer&amp;#34;,&amp;#34;precision&amp;#34;:38,&amp;#34;scale&amp;#34;:0},
{&amp;#34;type&amp;#34;:&amp;#34;number&amp;#34;,&amp;#34;precision&amp;#34;:38,&amp;#34;scale&amp;#34;:1},
{&amp;#34;type&amp;#34;:&amp;#34;numeric&amp;#34;,&amp;#34;precision&amp;#34;:38,&amp;#34;scale&amp;#34;:2},
{&amp;#34;type&amp;#34;:&amp;#34;real&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;array&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;object&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;variant&amp;#34;},
{&amp;#34;type&amp;#34;:&amp;#34;binary&amp;#34;,&amp;#34;size&amp;#34;:null},
{&amp;#34;type&amp;#34;:&amp;#34;char&amp;#34;,&amp;#34;length&amp;#34;:1},
{&amp;#34;type&amp;#34;:&amp;#34;string&amp;#34;,&amp;#34;length&amp;#34;:null},
{&amp;#34;type&amp;#34;:&amp;#34;text&amp;#34;,&amp;#34;length&amp;#34;:null},
{&amp;#34;type&amp;#34;:&amp;#34;varbinary&amp;#34;,&amp;#34;size&amp;#34;:null},
{&amp;#34;type&amp;#34;:&amp;#34;varchar&amp;#34;,&amp;#34;length&amp;#34;:100}]&lt;/code>&lt;/pre>
You can read about Snowflake data types at &lt;a href="https://docs.snowflake.com/en/sql-reference/data-types.html">Snowflake data types&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>expansion_service&lt;/code> Specifies URL of expansion service.&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Documentation: ApproximateQuantiles</title><link>/documentation/transforms/java/aggregation/approximatequantiles/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/approximatequantiles/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="approximatequantiles">ApproximateQuantiles&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/ApproximateQuantiles.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Takes a comparison function and the desired number of quantiles &lt;em>n&lt;/em>, either
globally or per-key. Using an approximation algorithm, it returns the
minimum value, &lt;em>n-2&lt;/em> intermediate values, and the maximum value.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>&lt;strong>Example&lt;/strong>: to compute the quartiles of a &lt;code>PCollection&lt;/code> of integers, we
would use &lt;code>ApproximateQuantiles.globally(5)&lt;/code>. This will produce a list
containing 5 values: the minimum value, Quartile 1 value, Quartile 2
value, Quartile 3 value, and the maximum value.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/approximateunique">ApproximateUnique&lt;/a>
estimates the number of distinct elements or distinct values in key-value pairs&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/combine">Combine&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Documentation: ApproximateQuantiles</title><link>/documentation/transforms/python/aggregation/approximatequantiles/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/approximatequantiles/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="approximatequantiles">ApproximateQuantiles&lt;/h1>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7390">BEAM-7390&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2></description></item><item><title>Documentation: ApproximateUnique</title><link>/documentation/transforms/java/aggregation/approximateunique/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/approximateunique/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="approximateunique">ApproximateUnique&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/ApproximateUnique.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Transforms for estimating the number of distinct elements in a collection
or the number of distinct values associated with each key in a collection
of key-value pairs.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7703">BEAM-7703&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/hllcount">HllCount&lt;/a>
estimates the number of distinct elements and creates re-aggregatable sketches using the HyperLogLog++ algorithm.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/count">Count&lt;/a>
counts the number of elements within each aggregation.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/distinct">Distinct&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Documentation: ApproximateUnique</title><link>/documentation/transforms/python/aggregation/approximateunique/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/approximateunique/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="approximateunique">ApproximateUnique&lt;/h1>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7390">BEAM-7390&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2></description></item><item><title>Documentation: Beam Programming Guide</title><link>/documentation/programming-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/programming-guide/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="apache-beam-programming-guide">Apache Beam Programming Guide&lt;/h1>
&lt;p>The &lt;strong>Beam Programming Guide&lt;/strong> is intended for Beam users who want to use the
Beam SDKs to create data processing pipelines. It provides guidance for using
the Beam SDK classes to build and test your pipeline. It is not intended as an
exhaustive reference, but as a language-agnostic, high-level guide to
programmatically building your Beam pipeline. As the programming guide is filled
out, the text will include code samples in multiple languages to help illustrate
how to implement Beam concepts in your pipelines.&lt;/p>
&lt;nav class="language-switcher">
&lt;strong>Adapt for:&lt;/strong>
&lt;ul>
&lt;li data-type="language-java" class="active">Java SDK&lt;/li>
&lt;li data-type="language-py">Python SDK&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;p class="language-py">The Python SDK supports Python 2.7, 3.5, 3.6, and 3.7. New Python SDK releases will stop supporting Python 2.7 in 2020 (&lt;a href="https://issues.apache.org/jira/browse/BEAM-8371">BEAM-8371&lt;/a>). For best results, use Beam with Python 3.&lt;/p>
&lt;h2 id="overview">1. Overview&lt;/h2>
&lt;p>To use Beam, you need to first create a driver program using the classes in one
of the Beam SDKs. Your driver program &lt;em>defines&lt;/em> your pipeline, including all of
the inputs, transforms, and outputs; it also sets execution options for your
pipeline (typically passed in using command-line options). These include the
Pipeline Runner, which, in turn, determines what back-end your pipeline will run
on.&lt;/p>
&lt;p>The Beam SDKs provide a number of abstractions that simplify the mechanics of
large-scale distributed data processing. The same Beam abstractions work with
both batch and streaming data sources. When you create your Beam pipeline, you
can think about your data processing task in terms of these abstractions. They
include:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>Pipeline&lt;/code>: A &lt;code>Pipeline&lt;/code> encapsulates your entire data processing task, from
start to finish. This includes reading input data, transforming that data, and
writing output data. All Beam driver programs must create a &lt;code>Pipeline&lt;/code>. When
you create the &lt;code>Pipeline&lt;/code>, you must also specify the execution options that
tell the &lt;code>Pipeline&lt;/code> where and how to run.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>PCollection&lt;/code>: A &lt;code>PCollection&lt;/code> represents a distributed data set that your
Beam pipeline operates on. The data set can be &lt;em>bounded&lt;/em>, meaning it comes
from a fixed source like a file, or &lt;em>unbounded&lt;/em>, meaning it comes from a
continuously updating source via a subscription or other mechanism. Your
pipeline typically creates an initial &lt;code>PCollection&lt;/code> by reading data from an
external data source, but you can also create a &lt;code>PCollection&lt;/code> from in-memory
data within your driver program. From there, &lt;code>PCollection&lt;/code>s are the inputs and
outputs for each step in your pipeline.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>PTransform&lt;/code>: A &lt;code>PTransform&lt;/code> represents a data processing operation, or a step,
in your pipeline. Every &lt;code>PTransform&lt;/code> takes one or more &lt;code>PCollection&lt;/code> objects as
input, performs a processing function that you provide on the elements of that
&lt;code>PCollection&lt;/code>, and produces zero or more output &lt;code>PCollection&lt;/code> objects.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>I/O transforms: Beam comes with a number of &amp;ldquo;IOs&amp;rdquo; - library &lt;code>PTransform&lt;/code>s that
read or write data to various external storage systems.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>A typical Beam driver program works as follows:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Create&lt;/strong> a &lt;code>Pipeline&lt;/code> object and set the pipeline execution options, including
the Pipeline Runner.&lt;/li>
&lt;li>Create an initial &lt;code>PCollection&lt;/code> for pipeline data, either using the IOs
to read data from an external storage system, or using a &lt;code>Create&lt;/code> transform to
build a &lt;code>PCollection&lt;/code> from in-memory data.&lt;/li>
&lt;li>&lt;strong>Apply&lt;/strong> &lt;code>PTransform&lt;/code>s to each &lt;code>PCollection&lt;/code>. Transforms can change, filter,
group, analyze, or otherwise process the elements in a &lt;code>PCollection&lt;/code>. A
transform creates a new output &lt;code>PCollection&lt;/code> &lt;em>without modifying the input
collection&lt;/em>. A typical pipeline applies subsequent transforms to each new
output &lt;code>PCollection&lt;/code> in turn until processing is complete. However, note that
a pipeline does not have to be a single straight line of transforms applied
one after another: think of &lt;code>PCollection&lt;/code>s as variables and &lt;code>PTransform&lt;/code>s as
functions applied to these variables: the shape of the pipeline can be an
arbitrarily complex processing graph.&lt;/li>
&lt;li>Use IOs to write the final, transformed &lt;code>PCollection&lt;/code>(s) to an external source.&lt;/li>
&lt;li>&lt;strong>Run&lt;/strong> the pipeline using the designated Pipeline Runner.&lt;/li>
&lt;/ul>
&lt;p>When you run your Beam driver program, the Pipeline Runner that you designate
constructs a &lt;strong>workflow graph&lt;/strong> of your pipeline based on the &lt;code>PCollection&lt;/code>
objects you&amp;rsquo;ve created and transforms that you&amp;rsquo;ve applied. That graph is then
executed using the appropriate distributed processing back-end, becoming an
asynchronous &amp;ldquo;job&amp;rdquo; (or equivalent) on that back-end.&lt;/p>
&lt;h2 id="creating-a-pipeline">2. Creating a pipeline&lt;/h2>
&lt;p>The &lt;code>Pipeline&lt;/code> abstraction encapsulates all the data and steps in your data
processing task. Your Beam driver program typically starts by constructing a
&lt;span class="language-java">&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/index.html?org/apache/beam/sdk/Pipeline.html">Pipeline&lt;/a>&lt;/span>
&lt;span class="language-py">&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/pipeline.py">Pipeline&lt;/a>&lt;/span>
object, and then using that object as the basis for creating the pipeline&amp;rsquo;s data
sets as &lt;code>PCollection&lt;/code>s and its operations as &lt;code>Transform&lt;/code>s.&lt;/p>
&lt;p>To use Beam, your driver program must first create an instance of the Beam SDK
class &lt;code>Pipeline&lt;/code> (typically in the &lt;code>main()&lt;/code> function). When you create your
&lt;code>Pipeline&lt;/code>, you&amp;rsquo;ll also need to set some &lt;strong>configuration options&lt;/strong>. You can set
your pipeline&amp;rsquo;s configuration options programmatically, but it&amp;rsquo;s often easier to
set the options ahead of time (or read them from the command line) and pass them
to the &lt;code>Pipeline&lt;/code> object when you create the object.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Start by defining the options for the pipeline.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PipelineOptions&lt;/span> &lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PipelineOptionsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// Then create the pipeline.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">Pipeline&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam.options.pipeline_options&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">PipelineOptions&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">PipelineOptions&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">pass&lt;/span> &lt;span class="c1"># build your pipeline here&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-go>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">// In order to start creating the pipeline for execution, a Pipeline object and a Scope object are needed.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="nx">p&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">s&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">beam&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">NewPipelineWithRoot&lt;/span>&lt;span class="p">()&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="configuring-pipeline-options">2.1. Configuring pipeline options&lt;/h3>
&lt;p>Use the pipeline options to configure different aspects of your pipeline, such
as the pipeline runner that will execute your pipeline and any runner-specific
configuration required by the chosen runner. Your pipeline options will
potentially include information such as your project ID or a location for
storing files.&lt;/p>
&lt;p>When you run the pipeline on a runner of your choice, a copy of the
PipelineOptions will be available to your code. For example, if you add a PipelineOptions parameter
to a DoFn&amp;rsquo;s &lt;code>@ProcessElement&lt;/code> method, it will be populated by the system.&lt;/p>
&lt;h4 id="pipeline-options-cli">2.1.1. Setting PipelineOptions from command-line arguments&lt;/h4>
&lt;p>While you can configure your pipeline by creating a &lt;code>PipelineOptions&lt;/code> object and
setting the fields directly, the Beam SDKs include a command-line parser that
you can use to set fields in &lt;code>PipelineOptions&lt;/code> using command-line arguments.&lt;/p>
&lt;p>To read options from the command-line, construct your &lt;code>PipelineOptions&lt;/code> object
as demonstrated in the following example code:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PipelineOptions&lt;/span> &lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">PipelineOptionsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fromArgs&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">withValidation&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">();&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam.options.pipeline_options&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">PipelineOptions&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">PipelineOptions&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">pass&lt;/span> &lt;span class="c1"># build your pipeline here&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-go>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">// If beamx or Go flags are used, flags must be parsed first.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="nx">flag&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Parse&lt;/span>&lt;span class="p">()&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>This interprets command-line arguments that follow the format:&lt;/p>
&lt;pre>&lt;code>--&amp;lt;option&amp;gt;=&amp;lt;value&amp;gt;
&lt;/code>&lt;/pre>&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> Appending the method &lt;code>.withValidation&lt;/code> will check for required
command-line arguments and validate argument values.&lt;/p>
&lt;/blockquote>
&lt;p>Building your &lt;code>PipelineOptions&lt;/code> this way lets you specify any of the options as
a command-line argument.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> The &lt;a href="/get-started/wordcount-example">WordCount example pipeline&lt;/a>
demonstrates how to set pipeline options at runtime by using command-line
options.&lt;/p>
&lt;/blockquote>
&lt;h4 id="creating-custom-options">2.1.2. Creating custom options&lt;/h4>
&lt;p>You can add your own custom options in addition to the standard
&lt;code>PipelineOptions&lt;/code>. To add your own options, define an interface with getter and
setter methods for each option, as in the following example for
adding &lt;code>input&lt;/code> and &lt;code>output&lt;/code> custom options:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">interface&lt;/span> &lt;span class="nc">MyOptions&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PipelineOptions&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="nf">getInput&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">setInput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="nf">getOutput&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">setOutput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam.options.pipeline_options&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">PipelineOptions&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">MyOptions&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">PipelineOptions&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="nd">@classmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">_add_argparse_args&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">cls&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">parser&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">parser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add_argument&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;--input&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">parser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add_argument&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;--output&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-go>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="kd">var&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="nx">input&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">flag&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">String&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;input&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nx">output&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">flag&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">String&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;output&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>You can also specify a description, which appears when a user passes &lt;code>--help&lt;/code> as
a command-line argument, and a default value.&lt;/p>
&lt;p>You set the description and default value using annotations, as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">interface&lt;/span> &lt;span class="nc">MyOptions&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PipelineOptions&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@Description&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Input for the pipeline&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="nd">@Default.String&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gs://my-bucket/input&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="nf">getInput&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">setInput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@Description&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Output for the pipeline&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="nd">@Default.String&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gs://my-bucket/output&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="nf">getOutput&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">setOutput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam.options.pipeline_options&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">PipelineOptions&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">MyOptions&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">PipelineOptions&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="nd">@classmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">_add_argparse_args&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">cls&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">parser&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">parser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add_argument&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s1">&amp;#39;--input&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">help&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;Input for the pipeline&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">default&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;gs://my-bucket/input&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">parser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add_argument&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s1">&amp;#39;--output&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">help&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;Output for the pipeline&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">default&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;gs://my-bucket/output&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-go>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="kd">var&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="nx">input&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">flag&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">String&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;input&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;gs://my-bucket/input&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;Input for the pipeline&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nx">output&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">flag&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">String&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;output&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;gs://my-bucket/output&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;Output for the pipeline&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">It&amp;rsquo;s recommended that you register your interface with &lt;code>PipelineOptionsFactory&lt;/code>
and then pass the interface when creating the &lt;code>PipelineOptions&lt;/code> object. When you
register your interface with &lt;code>PipelineOptionsFactory&lt;/code>, the &lt;code>--help&lt;/code> can find
your custom options interface and add it to the output of the &lt;code>--help&lt;/code> command.
&lt;code>PipelineOptionsFactory&lt;/code> will also validate that your custom options are
compatible with all other registered options.&lt;/p>
&lt;p class="language-java">The following example code shows how to register your custom options interface
with &lt;code>PipelineOptionsFactory&lt;/code>:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PipelineOptionsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">register&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MyOptions&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">MyOptions&lt;/span> &lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PipelineOptionsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fromArgs&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withValidation&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">as&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MyOptions&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Now your pipeline can accept &lt;code>--input=value&lt;/code> and &lt;code>--output=value&lt;/code> as command-line arguments.&lt;/p>
&lt;h2 id="pcollections">3. PCollections&lt;/h2>
&lt;p>The &lt;span class="language-java">&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/index.html?org/apache/beam/sdk/values/PCollection.html">PCollection&lt;/a>&lt;/span>
&lt;span class="language-py">&lt;code>PCollection&lt;/code>&lt;/span> abstraction represents a
potentially distributed, multi-element data set. You can think of a
&lt;code>PCollection&lt;/code> as &amp;ldquo;pipeline&amp;rdquo; data; Beam transforms use &lt;code>PCollection&lt;/code> objects as
inputs and outputs. As such, if you want to work with data in your pipeline, it
must be in the form of a &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>After you&amp;rsquo;ve created your &lt;code>Pipeline&lt;/code>, you&amp;rsquo;ll need to begin by creating at least
one &lt;code>PCollection&lt;/code> in some form. The &lt;code>PCollection&lt;/code> you create serves as the input
for the first operation in your pipeline.&lt;/p>
&lt;h3 id="creating-a-pcollection">3.1. Creating a PCollection&lt;/h3>
&lt;p>You create a &lt;code>PCollection&lt;/code> by either reading data from an external source using
Beam&amp;rsquo;s &lt;a href="#pipeline-io">Source API&lt;/a>, or you can create a &lt;code>PCollection&lt;/code> of data
stored in an in-memory collection class in your driver program. The former is
typically how a production pipeline would ingest data; Beam&amp;rsquo;s Source APIs
contain adapters to help you read from external sources like large cloud-based
files, databases, or subscription services. The latter is primarily useful for
testing and debugging purposes.&lt;/p>
&lt;h4 id="reading-external-source">3.1.1. Reading from an external source&lt;/h4>
&lt;p>To read from an external source, you use one of the &lt;a href="#pipeline-io">Beam-provided I/O
adapters&lt;/a>. The adapters vary in their exact usage, but all of them
read from some external data source and return a &lt;code>PCollection&lt;/code> whose elements
represent the data records in that source.&lt;/p>
&lt;p>Each data source adapter has a &lt;code>Read&lt;/code> transform; to read, you must apply that
transform to the &lt;code>Pipeline&lt;/code> object itself.
&lt;span class="language-java">&lt;code>TextIO.Read&lt;/code>&lt;/span>
&lt;span class="language-py">&lt;code>io.TextFileSource&lt;/code>&lt;/span>, for example, reads from an
external text file and returns a &lt;code>PCollection&lt;/code> whose elements are of type
&lt;code>String&lt;/code>, each &lt;code>String&lt;/code> represents one line from the text file. Here&amp;rsquo;s how you
would apply &lt;span class="language-java">&lt;code>TextIO.Read&lt;/code>&lt;/span>
&lt;span class="language-py">&lt;code>io.TextFileSource&lt;/code>&lt;/span> to your &lt;code>Pipeline&lt;/code> to create
a &lt;code>PCollection&lt;/code>:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Create the pipeline.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">PipelineOptions&lt;/span> &lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">PipelineOptionsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fromArgs&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">Pipeline&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Create the PCollection &amp;#39;lines&amp;#39; by applying a &amp;#39;Read&amp;#39; transform.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;ReadMyFile&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">from&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gs://some/inputData.txt&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;ReadMyFile&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ReadFromText&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s1">&amp;#39;gs://some/inputData.txt&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-go>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="nx">lines&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">textio&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Read&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">s&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;gs://some/inputData.txt&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>See the &lt;a href="#pipeline-io">section on I/O&lt;/a> to learn more about how to read from the
various data sources supported by the Beam SDK.&lt;/p>
&lt;h4 id="creating-pcollection-in-memory">3.1.2. Creating a PCollection from in-memory data&lt;/h4>
&lt;p class="language-java">To create a &lt;code>PCollection&lt;/code> from an in-memory Java &lt;code>Collection&lt;/code>, you use the
Beam-provided &lt;code>Create&lt;/code> transform. Much like a data adapter&amp;rsquo;s &lt;code>Read&lt;/code>, you apply
&lt;code>Create&lt;/code> directly to your &lt;code>Pipeline&lt;/code> object itself.&lt;/p>
&lt;p class="language-java">As parameters, &lt;code>Create&lt;/code> accepts the Java &lt;code>Collection&lt;/code> and a &lt;code>Coder&lt;/code> object. The
&lt;code>Coder&lt;/code> specifies how the elements in the &lt;code>Collection&lt;/code> should be
&lt;a href="#element-type">encoded&lt;/a>.&lt;/p>
&lt;p class="language-py">To create a &lt;code>PCollection&lt;/code> from an in-memory &lt;code>list&lt;/code>, you use the Beam-provided
&lt;code>Create&lt;/code> transform. Apply this transform directly to your &lt;code>Pipeline&lt;/code> object
itself.&lt;/p>
&lt;p>The following example code shows how to create a &lt;code>PCollection&lt;/code> from an in-memory
&lt;span class="language-java">&lt;code>List&lt;/code>&lt;/span>&lt;span class="language-py">&lt;code>list&lt;/code>&lt;/span>:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Create a Java Collection, in this case a List of Strings.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">LINES&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;To be, or not to be: that is the question: &amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;Whether &amp;#39;tis nobler in the mind to suffer &amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;The slings and arrows of outrageous fortune, &amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;Or to take arms against a sea of troubles, &amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Create the pipeline.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">PipelineOptions&lt;/span> &lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">PipelineOptionsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fromArgs&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">Pipeline&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Apply Create, passing the list and the coder, to create the PCollection.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">LINES&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">setCoder&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">StringUtf8Coder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam.options.pipeline_options&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">PipelineOptions&lt;/span>
&lt;span class="c1"># argv = None # if None, uses sys.argv&lt;/span>
&lt;span class="n">pipeline_options&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PipelineOptions&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">pipeline_options&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="s1">&amp;#39;To be, or not to be: that is the question: &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;Whether &amp;#39;tis nobler in the mind to suffer &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;The slings and arrows of outrageous fortune, &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;Or to take arms against a sea of troubles, &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="pcollection-characteristics">3.2. PCollection characteristics&lt;/h3>
&lt;p>A &lt;code>PCollection&lt;/code> is owned by the specific &lt;code>Pipeline&lt;/code> object for which it is
created; multiple pipelines cannot share a &lt;code>PCollection&lt;/code>. &lt;span language="java">
In some respects, a &lt;code>PCollection&lt;/code> functions like a &lt;code>Collection&lt;/code> class. However,
a &lt;code>PCollection&lt;/code> can differ in a few key ways:&lt;/span>&lt;/p>
&lt;h4 id="element-type">3.2.1. Element type&lt;/h4>
&lt;p>The elements of a &lt;code>PCollection&lt;/code> may be of any type, but must all be of the same
type. However, to support distributed processing, Beam needs to be able to
encode each individual element as a byte string (so elements can be passed
around to distributed workers). The Beam SDKs provide a data encoding mechanism
that includes built-in encoding for commonly-used types as well as support for
specifying custom encodings as needed.&lt;/p>
&lt;h4 id="element-schema">3.2.2. Element schema&lt;/h4>
&lt;p>In many cases, the element type in a &lt;code>PCollection&lt;/code> has a structure that can introspected.
Examples are JSON, Protocol Buffer, Avro, and database records. Schemas provide a way to
express types as a set of named fields, allowing for more-expressive aggregations.&lt;/p>
&lt;h4 id="immutability">3.2.3. Immutability&lt;/h4>
&lt;p>A &lt;code>PCollection&lt;/code> is immutable. Once created, you cannot add, remove, or change
individual elements. A Beam Transform might process each element of a
&lt;code>PCollection&lt;/code> and generate new pipeline data (as a new &lt;code>PCollection&lt;/code>), &lt;em>but it
does not consume or modify the original input collection&lt;/em>.&lt;/p>
&lt;h4 id="random-access">3.2.4. Random access&lt;/h4>
&lt;p>A &lt;code>PCollection&lt;/code> does not support random access to individual elements. Instead,
Beam Transforms consider every element in a &lt;code>PCollection&lt;/code> individually.&lt;/p>
&lt;h4 id="size-and-boundedness">3.2.5. Size and boundedness&lt;/h4>
&lt;p>A &lt;code>PCollection&lt;/code> is a large, immutable &amp;ldquo;bag&amp;rdquo; of elements. There is no upper limit
on how many elements a &lt;code>PCollection&lt;/code> can contain; any given &lt;code>PCollection&lt;/code> might
fit in memory on a single machine, or it might represent a very large
distributed data set backed by a persistent data store.&lt;/p>
&lt;p>A &lt;code>PCollection&lt;/code> can be either &lt;strong>bounded&lt;/strong> or &lt;strong>unbounded&lt;/strong> in size. A
&lt;strong>bounded&lt;/strong> &lt;code>PCollection&lt;/code> represents a data set of a known, fixed size, while an
&lt;strong>unbounded&lt;/strong> &lt;code>PCollection&lt;/code> represents a data set of unlimited size. Whether a
&lt;code>PCollection&lt;/code> is bounded or unbounded depends on the source of the data set that
it represents. Reading from a batch data source, such as a file or a database,
creates a bounded &lt;code>PCollection&lt;/code>. Reading from a streaming or
continuously-updating data source, such as Pub/Sub or Kafka, creates an unbounded
&lt;code>PCollection&lt;/code> (unless you explicitly tell it not to).&lt;/p>
&lt;p>The bounded (or unbounded) nature of your &lt;code>PCollection&lt;/code> affects how Beam
processes your data. A bounded &lt;code>PCollection&lt;/code> can be processed using a batch job,
which might read the entire data set once, and perform processing in a job of
finite length. An unbounded &lt;code>PCollection&lt;/code> must be processed using a streaming
job that runs continuously, as the entire collection can never be available for
processing at any one time.&lt;/p>
&lt;p>Beam uses &lt;a href="#windowing">windowing&lt;/a> to divide a continuously updating unbounded
&lt;code>PCollection&lt;/code> into logical windows of finite size. These logical windows are
determined by some characteristic associated with a data element, such as a
&lt;strong>timestamp&lt;/strong>. Aggregation transforms (such as &lt;code>GroupByKey&lt;/code> and &lt;code>Combine&lt;/code>) work
on a per-window basis — as the data set is generated, they process each
&lt;code>PCollection&lt;/code> as a succession of these finite windows.&lt;/p>
&lt;h4 id="element-timestamps">3.2.6. Element timestamps&lt;/h4>
&lt;p>Each element in a &lt;code>PCollection&lt;/code> has an associated intrinsic &lt;strong>timestamp&lt;/strong>. The
timestamp for each element is initially assigned by the &lt;a href="#pipeline-io">Source&lt;/a>
that creates the &lt;code>PCollection&lt;/code>. Sources that create an unbounded &lt;code>PCollection&lt;/code>
often assign each new element a timestamp that corresponds to when the element
was read or added.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: Sources that create a bounded &lt;code>PCollection&lt;/code> for a fixed data set
also automatically assign timestamps, but the most common behavior is to
assign every element the same timestamp (&lt;code>Long.MIN_VALUE&lt;/code>).&lt;/p>
&lt;/blockquote>
&lt;p>Timestamps are useful for a &lt;code>PCollection&lt;/code> that contains elements with an
inherent notion of time. If your pipeline is reading a stream of events, like
Tweets or other social media messages, each element might use the time the event
was posted as the element timestamp.&lt;/p>
&lt;p>You can manually assign timestamps to the elements of a &lt;code>PCollection&lt;/code> if the
source doesn&amp;rsquo;t do it for you. You&amp;rsquo;ll want to do this if the elements have an
inherent timestamp, but the timestamp is somewhere in the structure of the
element itself (such as a &amp;ldquo;time&amp;rdquo; field in a server log entry). Beam has
&lt;a href="#transforms">Transforms&lt;/a> that take a &lt;code>PCollection&lt;/code> as input and output an
identical &lt;code>PCollection&lt;/code> with timestamps attached; see &lt;a href="#adding-timestamps-to-a-pcollections-elements">Adding
Timestamps&lt;/a> for more information
about how to do so.&lt;/p>
&lt;h2 id="transforms">4. Transforms&lt;/h2>
&lt;p>Transforms are the operations in your pipeline, and provide a generic
processing framework. You provide processing logic in the form of a function
object (colloquially referred to as &amp;ldquo;user code&amp;rdquo;), and your user code is applied
to each element of an input &lt;code>PCollection&lt;/code> (or more than one &lt;code>PCollection&lt;/code>).
Depending on the pipeline runner and back-end that you choose, many different
workers across a cluster may execute instances of your user code in parallel.
The user code running on each worker generates the output elements that are
ultimately added to the final output &lt;code>PCollection&lt;/code> that the transform produces.&lt;/p>
&lt;p>The Beam SDKs contain a number of different transforms that you can apply to
your pipeline&amp;rsquo;s &lt;code>PCollection&lt;/code>s. These include general-purpose core transforms,
such as &lt;a href="#pardo">ParDo&lt;/a> or &lt;a href="#combine">Combine&lt;/a>. There are also pre-written
&lt;a href="#composite-transforms">composite transforms&lt;/a> included in the SDKs, which
combine one or more of the core transforms in a useful processing pattern, such
as counting or combining elements in a collection. You can also define your own
more complex composite transforms to fit your pipeline&amp;rsquo;s exact use case.&lt;/p>
&lt;h3 id="applying-transforms">4.1. Applying transforms&lt;/h3>
&lt;p>To invoke a transform, you must &lt;strong>apply&lt;/strong> it to the input &lt;code>PCollection&lt;/code>. Each
transform in the Beam SDKs has a generic &lt;code>apply&lt;/code> method &lt;span class="language-py">(or pipe operator &lt;code>|&lt;/code>)&lt;/span>.
Invoking multiple Beam transforms is similar to &lt;em>method chaining&lt;/em>, but with one
slight difference: You apply the transform to the input &lt;code>PCollection&lt;/code>, passing
the transform itself as an argument, and the operation returns the output
&lt;code>PCollection&lt;/code>. This takes the general form:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">[&lt;/span>&lt;span class="n">Output&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">[&lt;/span>&lt;span class="n">Input&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">].&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">([&lt;/span>&lt;span class="n">Transform&lt;/span>&lt;span class="o">])&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="p">[&lt;/span>&lt;span class="n">Output&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Input&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Transform&lt;/span>&lt;span class="p">]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Because Beam uses a generic &lt;code>apply&lt;/code> method for &lt;code>PCollection&lt;/code>, you can both chain
transforms sequentially and also apply transforms that contain other transforms
nested within (called &lt;a href="#composite-transforms">composite transforms&lt;/a> in the Beam
SDKs).&lt;/p>
&lt;p>How you apply your pipeline&amp;rsquo;s transforms determines the structure of your
pipeline. The best way to think of your pipeline is as a directed acyclic graph,
where &lt;code>PTransform&lt;/code> nodes are subroutines that accept &lt;code>PCollection&lt;/code> nodes as
inputs and emit &lt;code>PCollection&lt;/code> nodes as outputs. For example, you can chain
together transforms to create a pipeline that successively modifies input data:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">[&lt;/span>&lt;span class="n">Final&lt;/span> &lt;span class="n">Output&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">[&lt;/span>&lt;span class="n">Initial&lt;/span> &lt;span class="n">Input&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">].&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">([&lt;/span>&lt;span class="n">First&lt;/span> &lt;span class="n">Transform&lt;/span>&lt;span class="o">])&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">([&lt;/span>&lt;span class="n">Second&lt;/span> &lt;span class="n">Transform&lt;/span>&lt;span class="o">])&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">([&lt;/span>&lt;span class="n">Third&lt;/span> &lt;span class="n">Transform&lt;/span>&lt;span class="o">])&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="p">[&lt;/span>&lt;span class="n">Final&lt;/span> &lt;span class="n">Output&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">([&lt;/span>&lt;span class="n">Initial&lt;/span> &lt;span class="n">Input&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">First&lt;/span> &lt;span class="n">Transform&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Second&lt;/span> &lt;span class="n">Transform&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Third&lt;/span> &lt;span class="n">Transform&lt;/span>&lt;span class="p">])&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The graph of this pipeline looks like the following:&lt;/p>
&lt;p>&lt;img src="/images/design-your-pipeline-linear.svg" alt="This linear pipeline starts with one input collection, sequentially appliesthree transforms, and ends with one output collection.">&lt;/p>
&lt;p>&lt;em>Figure 1: A linear pipeline with three sequential transforms.&lt;/em>&lt;/p>
&lt;p>However, note that a transform &lt;em>does not consume or otherwise alter&lt;/em> the input
collection — remember that a &lt;code>PCollection&lt;/code> is immutable by definition. This means
that you can apply multiple transforms to the same input &lt;code>PCollection&lt;/code> to create
a branching pipeline, like so:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="n">database&lt;/span> &lt;span class="n">table&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">[&lt;/span>&lt;span class="n">Database&lt;/span> &lt;span class="n">Table&lt;/span> &lt;span class="n">Reader&lt;/span>&lt;span class="o">].&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">([&lt;/span>&lt;span class="n">Read&lt;/span> &lt;span class="n">Transform&lt;/span>&lt;span class="o">])&lt;/span>
&lt;span class="o">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="sc">&amp;#39;A&amp;#39;&lt;/span> &lt;span class="n">names&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="n">database&lt;/span> &lt;span class="n">table&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="o">].&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">([&lt;/span>&lt;span class="n">Transform&lt;/span> &lt;span class="n">A&lt;/span>&lt;span class="o">])&lt;/span>
&lt;span class="o">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="sc">&amp;#39;B&amp;#39;&lt;/span> &lt;span class="n">names&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="n">database&lt;/span> &lt;span class="n">table&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="o">].&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">([&lt;/span>&lt;span class="n">Transform&lt;/span> &lt;span class="n">B&lt;/span>&lt;span class="o">])&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="p">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="n">database&lt;/span> &lt;span class="n">table&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Database&lt;/span> &lt;span class="n">Table&lt;/span> &lt;span class="n">Reader&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Read&lt;/span> &lt;span class="n">Transform&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="p">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="s1">&amp;#39;A&amp;#39;&lt;/span> &lt;span class="n">names&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="n">database&lt;/span> &lt;span class="n">table&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Transform&lt;/span> &lt;span class="n">A&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="p">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="s1">&amp;#39;B&amp;#39;&lt;/span> &lt;span class="n">names&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">PCollection&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="n">database&lt;/span> &lt;span class="n">table&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Transform&lt;/span> &lt;span class="n">B&lt;/span>&lt;span class="p">]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The graph of this branching pipeline looks like the following:&lt;/p>
&lt;p>&lt;img src="/images/design-your-pipeline-multiple-pcollections.svg" alt="This pipeline applies two transforms to a single input collection. Eachtransform produces an output collection.">&lt;/p>
&lt;p>&lt;em>Figure 2: A branching pipeline. Two transforms are applied to a single
PCollection of database table rows.&lt;/em>&lt;/p>
&lt;p>You can also build your own &lt;a href="#composite-transforms">composite transforms&lt;/a> that
nest multiple transforms inside a single, larger transform. Composite transforms
are particularly useful for building a reusable sequence of simple steps that
get used in a lot of different places.&lt;/p>
&lt;h3 id="core-beam-transforms">4.2. Core Beam transforms&lt;/h3>
&lt;p>Beam provides the following core transforms, each of which represents a different
processing paradigm:&lt;/p>
&lt;ul>
&lt;li>&lt;code>ParDo&lt;/code>&lt;/li>
&lt;li>&lt;code>GroupByKey&lt;/code>&lt;/li>
&lt;li>&lt;code>CoGroupByKey&lt;/code>&lt;/li>
&lt;li>&lt;code>Combine&lt;/code>&lt;/li>
&lt;li>&lt;code>Flatten&lt;/code>&lt;/li>
&lt;li>&lt;code>Partition&lt;/code>&lt;/li>
&lt;/ul>
&lt;h4 id="pardo">4.2.1. ParDo&lt;/h4>
&lt;p>&lt;code>ParDo&lt;/code> is a Beam transform for generic parallel processing. The &lt;code>ParDo&lt;/code>
processing paradigm is similar to the &amp;ldquo;Map&amp;rdquo; phase of a
&lt;a href="https://en.wikipedia.org/wiki/MapReduce">Map/Shuffle/Reduce&lt;/a>-style
algorithm: a &lt;code>ParDo&lt;/code> transform considers each element in the input
&lt;code>PCollection&lt;/code>, performs some processing function (your user code) on that
element, and emits zero, one, or multiple elements to an output &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>&lt;code>ParDo&lt;/code> is useful for a variety of common data processing operations, including:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Filtering a data set.&lt;/strong> You can use &lt;code>ParDo&lt;/code> to consider each element in a
&lt;code>PCollection&lt;/code> and either output that element to a new collection or discard
it.&lt;/li>
&lt;li>&lt;strong>Formatting or type-converting each element in a data set.&lt;/strong> If your input
&lt;code>PCollection&lt;/code> contains elements that are of a different type or format than
you want, you can use &lt;code>ParDo&lt;/code> to perform a conversion on each element and
output the result to a new &lt;code>PCollection&lt;/code>.&lt;/li>
&lt;li>&lt;strong>Extracting parts of each element in a data set.&lt;/strong> If you have a
&lt;code>PCollection&lt;/code> of records with multiple fields, for example, you can use a
&lt;code>ParDo&lt;/code> to parse out just the fields you want to consider into a new
&lt;code>PCollection&lt;/code>.&lt;/li>
&lt;li>&lt;strong>Performing computations on each element in a data set.&lt;/strong> You can use &lt;code>ParDo&lt;/code>
to perform simple or complex computations on every element, or certain
elements, of a &lt;code>PCollection&lt;/code> and output the results as a new &lt;code>PCollection&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>In such roles, &lt;code>ParDo&lt;/code> is a common intermediate step in a pipeline. You might
use it to extract certain fields from a set of raw input records, or convert raw
input into a different format; you might also use &lt;code>ParDo&lt;/code> to convert processed
data into a format suitable for output, like database table rows or printable
strings.&lt;/p>
&lt;p>When you apply a &lt;code>ParDo&lt;/code> transform, you&amp;rsquo;ll need to provide user code in the form
of a &lt;code>DoFn&lt;/code> object. &lt;code>DoFn&lt;/code> is a Beam SDK class that defines a distributed
processing function.&lt;/p>
&lt;blockquote>
&lt;p>When you create a subclass of &lt;code>DoFn&lt;/code>, note that your subclass should adhere to
the &lt;a href="#requirements-for-writing-user-code-for-beam-transforms">Requirements for writing user code for Beam transforms&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;h5 id="applying-pardo">4.2.1.1. Applying ParDo&lt;/h5>
&lt;p>Like all Beam transforms, you apply &lt;code>ParDo&lt;/code> by calling the &lt;code>apply&lt;/code> method on the
input &lt;code>PCollection&lt;/code> and passing &lt;code>ParDo&lt;/code> as an argument, as shown in the
following example code:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// The input PCollection of Strings.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="c1">// The DoFn to perform on each element in the input PCollection.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">ComputeWordLengthFn&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="c1">// Apply a ParDo to the PCollection &amp;#34;words&amp;#34; to compute lengths for each word.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">wordLengths&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">ParDo&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">ComputeWordLengthFn&lt;/span>&lt;span class="o">()));&lt;/span> &lt;span class="c1">// The DoFn to perform on each element, which
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">//&lt;/span> &lt;span class="n">we&lt;/span> &lt;span class="n">define&lt;/span> &lt;span class="n">above&lt;/span>&lt;span class="o">.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># The input PCollection of Strings.&lt;/span>
&lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="c1"># The DoFn to perform on each element in the input PCollection.&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">ComputeWordLengthFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;span class="c1"># Apply a ParDo to the PCollection &amp;#34;words&amp;#34; to compute lengths for each word.&lt;/span>
&lt;span class="n">word_lengths&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ComputeWordLengthFn&lt;/span>&lt;span class="p">())&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-go>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">// words is the input PCollection of strings
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">var&lt;/span> &lt;span class="nx">words&lt;/span> &lt;span class="nx">beam&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">PCollection&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="nf">computeWordLengthFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">word&lt;/span> &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">word&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="nx">wordLengths&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">beam&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">s&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">computeWordLengthFn&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">words&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>In the example, our input &lt;code>PCollection&lt;/code> contains &lt;code>String&lt;/code> values. We apply a
&lt;code>ParDo&lt;/code> transform that specifies a function (&lt;code>ComputeWordLengthFn&lt;/code>) to compute
the length of each string, and outputs the result to a new &lt;code>PCollection&lt;/code> of
&lt;code>Integer&lt;/code> values that stores the length of each word.&lt;/p>
&lt;h5 id="4212-creating-a-dofn">4.2.1.2. Creating a DoFn&lt;/h5>
&lt;p>The &lt;code>DoFn&lt;/code> object that you pass to &lt;code>ParDo&lt;/code> contains the processing logic that
gets applied to the elements in the input collection. When you use Beam, often
the most important pieces of code you&amp;rsquo;ll write are these &lt;code>DoFn&lt;/code>s - they&amp;rsquo;re what
define your pipeline&amp;rsquo;s exact data processing tasks.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> When you create your &lt;code>DoFn&lt;/code>, be mindful of the &lt;a href="#requirements-for-writing-user-code-for-beam-transforms">Requirements
for writing user code for Beam transforms&lt;/a>
and ensure that your code follows them.&lt;/p>
&lt;/blockquote>
&lt;p class="language-java">A &lt;code>DoFn&lt;/code> processes one element at a time from the input &lt;code>PCollection&lt;/code>. When you
create a subclass of &lt;code>DoFn&lt;/code>, you&amp;rsquo;ll need to provide type parameters that match
the types of the input and output elements. If your &lt;code>DoFn&lt;/code> processes incoming
&lt;code>String&lt;/code> elements and produces &lt;code>Integer&lt;/code> elements for the output collection
(like our previous example, &lt;code>ComputeWordLengthFn&lt;/code>), your class declaration would
look like this:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">ComputeWordLengthFn&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">Inside your &lt;code>DoFn&lt;/code> subclass, you&amp;rsquo;ll write a method annotated with
&lt;code>@ProcessElement&lt;/code> where you provide the actual processing logic. You don&amp;rsquo;t need
to manually extract the elements from the input collection; the Beam SDKs handle
that for you. Your &lt;code>@ProcessElement&lt;/code> method should accept a parameter tagged with
&lt;code>@Element&lt;/code>, which will be populated with the input element. In order to output
elements, the method can also take a parameter of type &lt;code>OutputReceiver&lt;/code> which
provides a method for emitting elements. The parameter types must match the input
and output types of your &lt;code>DoFn&lt;/code> or the framework will raise an error. Note: &lt;code>@Element&lt;/code> and
&lt;code>OutputReceiver&lt;/code> were introduced in Beam 2.5.0; if using an earlier release of Beam, a
&lt;code>ProcessContext&lt;/code> parameter should be used instead.&lt;/p>
&lt;p class="language-py">Inside your &lt;code>DoFn&lt;/code> subclass, you&amp;rsquo;ll write a method &lt;code>process&lt;/code> where you provide
the actual processing logic. You don&amp;rsquo;t need to manually extract the elements
from the input collection; the Beam SDKs handle that for you. Your &lt;code>process&lt;/code> method
should accept an argument &lt;code>element&lt;/code>, which is the input element, and return an
iterable with its output values. You can accomplish this by emitting individual
elements with &lt;code>yield&lt;/code> statements. You can also use a &lt;code>return&lt;/code> statement
with an iterable, like a list or a generator.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">ComputeWordLengthFn&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">OutputReceiver&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Use OutputReceiver.output to emit the output element.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">length&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">class&lt;/span> &lt;span class="nc">ComputeWordLengthFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="p">)]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> If the elements in your input &lt;code>PCollection&lt;/code> are key/value pairs, you
can access the key or value by using &lt;code>element.getKey()&lt;/code> or
&lt;code>element.getValue()&lt;/code>, respectively.&lt;/p>
&lt;/blockquote>&lt;/p>
&lt;p>A given &lt;code>DoFn&lt;/code> instance generally gets invoked one or more times to process some
arbitrary bundle of elements. However, Beam doesn&amp;rsquo;t guarantee an exact number of
invocations; it may be invoked multiple times on a given worker node to account
for failures and retries. As such, you can cache information across multiple
calls to your processing method, but if you do so, make sure the implementation
&lt;strong>does not depend on the number of invocations&lt;/strong>.&lt;/p>
&lt;p>In your processing method, you&amp;rsquo;ll also need to meet some immutability
requirements to ensure that Beam and the processing back-end can safely
serialize and cache the values in your pipeline. Your method should meet the
following requirements:&lt;/p>
&lt;p class="language-java">&lt;ul>
&lt;li>You should not in any way modify an element returned by
the &lt;code>@Element&lt;/code> annotation or &lt;code>ProcessContext.sideInput()&lt;/code> (the incoming
elements from the input collection).&lt;/li>
&lt;li>Once you output a value using &lt;code>OutputReceiver.output()&lt;/code> you should not modify
that value in any way.&lt;/li>
&lt;/ul>&lt;/p>
&lt;p class="language-python">&lt;ul>
&lt;li>You should not in any way modify the &lt;code>element&lt;/code> argument provided to the
&lt;code>process&lt;/code> method, or any side inputs.&lt;/li>
&lt;li>Once you output a value using &lt;code>yield&lt;/code> or &lt;code>return&lt;/code>, you should not modify
that value in any way.&lt;/li>
&lt;/ul>&lt;/p>
&lt;h5 id="lightweight-dofns">4.2.1.3. Lightweight DoFns and other abstractions&lt;/h5>
&lt;p>If your function is relatively straightforward, you can simplify your use of
&lt;code>ParDo&lt;/code> by providing a lightweight &lt;code>DoFn&lt;/code> in-line, as
&lt;span class="language-java">an anonymous inner class instance&lt;/span>
&lt;span class="language-py">a lambda function&lt;/span>.&lt;/p>
&lt;p>Here&amp;rsquo;s the previous example, &lt;code>ParDo&lt;/code> with &lt;code>ComputeLengthWordsFn&lt;/code>, with the
&lt;code>DoFn&lt;/code> specified as
&lt;span class="language-java">an anonymous inner class instance&lt;/span>
&lt;span class="language-py">a lambda function&lt;/span>:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// The input PCollection.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="c1">// Apply a ParDo with an anonymous DoFn to the PCollection words.
&lt;/span>&lt;span class="c1">// Save the result as the PCollection wordLengths.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">wordLengths&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;ComputeWordLengths&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="c1">// the transform name
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="c1">// a DoFn as an anonymous inner class instance
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">OutputReceiver&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">length&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># The input PCollection of strings.&lt;/span>
&lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="c1"># Apply a lambda function to the PCollection words.&lt;/span>
&lt;span class="c1"># Save the result as the PCollection word_lengths.&lt;/span>
&lt;span class="n">word_lengths&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="p">)])&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-go>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">// words is the input PCollection of strings
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">var&lt;/span> &lt;span class="nx">words&lt;/span> &lt;span class="nx">beam&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">PCollection&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="nx">lengths&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">beam&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">s&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kd">func&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">word&lt;/span> &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">word&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">},&lt;/span> &lt;span class="nx">words&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>If your &lt;code>ParDo&lt;/code> performs a one-to-one mapping of input elements to output
elements&amp;ndash;that is, for each input element, it applies a function that produces
&lt;em>exactly one&lt;/em> output element, you can use the higher-level
&lt;span class="language-java">&lt;code>MapElements&lt;/code>&lt;/span>&lt;span class="language-py">&lt;code>Map&lt;/code>&lt;/span>
transform. &lt;span class="language-java">&lt;code>MapElements&lt;/code> can accept an anonymous
Java 8 lambda function for additional brevity.&lt;/span>&lt;/p>
&lt;p>Here&amp;rsquo;s the previous example using &lt;span class="language-java">&lt;code>MapElements&lt;/code>&lt;/span>
&lt;span class="language-py">&lt;code>Map&lt;/code>&lt;/span>:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// The input PCollection.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="c1">// Apply a MapElements with an anonymous lambda function to the PCollection words.
&lt;/span>&lt;span class="c1">// Save the result as the PCollection wordLengths.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">wordLengths&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">integers&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">((&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">length&lt;/span>&lt;span class="o">()));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># The input PCollection of string.&lt;/span>
&lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="c1"># Apply a Map with a lambda function to the PCollection words.&lt;/span>
&lt;span class="c1"># Save the result as the PCollection word_lengths.&lt;/span>
&lt;span class="n">word_lengths&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> You can use Java 8 lambda functions with several other Beam
transforms, including &lt;code>Filter&lt;/code>, &lt;code>FlatMapElements&lt;/code>, and &lt;code>Partition&lt;/code>.&lt;/p>
&lt;/blockquote>&lt;/p>
&lt;h5 id="dofn">4.2.1.4. DoFn lifecycle&lt;/h5>
&lt;p>Here is a sequence diagram that shows the lifecycle of the DoFn during
the execution of the ParDo transform. The comments give useful
information to pipeline developers such as the constraints that
apply to the objects or particular cases such as failover or
instance reuse. They also give instantiation use cases.&lt;/p>
&lt;!-- The source for the sequence diagram can be found in the the SVG resource. -->
&lt;p>&lt;img src="/images/dofn-sequence-diagram.svg" alt="This is a sequence diagram that shows the lifecycle of the DoFn">&lt;/p>
&lt;h4 id="groupbykey">4.2.2. GroupByKey&lt;/h4>
&lt;p>&lt;code>GroupByKey&lt;/code> is a Beam transform for processing collections of key/value pairs.
It&amp;rsquo;s a parallel reduction operation, analogous to the Shuffle phase of a
Map/Shuffle/Reduce-style algorithm. The input to &lt;code>GroupByKey&lt;/code> is a collection of
key/value pairs that represents a &lt;em>multimap&lt;/em>, where the collection contains
multiple pairs that have the same key, but different values. Given such a
collection, you use &lt;code>GroupByKey&lt;/code> to collect all of the values associated with
each unique key.&lt;/p>
&lt;p>&lt;code>GroupByKey&lt;/code> is a good way to aggregate data that has something in common. For
example, if you have a collection that stores records of customer orders, you
might want to group together all the orders from the same postal code (wherein
the &amp;ldquo;key&amp;rdquo; of the key/value pair is the postal code field, and the &amp;ldquo;value&amp;rdquo; is the
remainder of the record).&lt;/p>
&lt;p>Let&amp;rsquo;s examine the mechanics of &lt;code>GroupByKey&lt;/code> with a simple example case, where
our data set consists of words from a text file and the line number on which
they appear. We want to group together all the line numbers (values) that share
the same word (key), letting us see all the places in the text where a
particular word appears.&lt;/p>
&lt;p>Our input is a &lt;code>PCollection&lt;/code> of key/value pairs where each word is a key, and
the value is a line number in the file where the word appears. Here&amp;rsquo;s a list of
the key/value pairs in the input collection:&lt;/p>
&lt;pre>&lt;code>cat, 1
dog, 5
and, 1
jump, 3
tree, 2
cat, 5
dog, 2
and, 2
cat, 9
and, 6
...
&lt;/code>&lt;/pre>&lt;p>&lt;code>GroupByKey&lt;/code> gathers up all the values with the same key and outputs a new pair
consisting of the unique key and a collection of all of the values that were
associated with that key in the input collection. If we apply &lt;code>GroupByKey&lt;/code> to
our input collection above, the output collection would look like this:&lt;/p>
&lt;pre>&lt;code>cat, [1,5,9]
dog, [5,2]
and, [1,2,6]
jump, [3]
tree, [2]
...
&lt;/code>&lt;/pre>&lt;p>Thus, &lt;code>GroupByKey&lt;/code> represents a transform from a multimap (multiple keys to
individual values) to a uni-map (unique keys to collections of values).&lt;/p>
&lt;h5 id="groupbykey-and-unbounded-pcollections">4.2.2.1 GroupByKey and unbounded PCollections&lt;/h5>
&lt;p>If you are using unbounded &lt;code>PCollection&lt;/code>s, you must use either &lt;a href="#setting-your-pcollections-windowing-function">non-global
windowing&lt;/a> or an
&lt;a href="#triggers">aggregation trigger&lt;/a> in order to perform a &lt;code>GroupByKey&lt;/code> or
&lt;a href="#cogroupbykey">CoGroupByKey&lt;/a>. This is because a bounded &lt;code>GroupByKey&lt;/code> or
&lt;code>CoGroupByKey&lt;/code> must wait for all the data with a certain key to be collected,
but with unbounded collections, the data is unlimited. Windowing and/or triggers
allow grouping to operate on logical, finite bundles of data within the
unbounded data streams.&lt;/p>
&lt;p>If you do apply &lt;code>GroupByKey&lt;/code> or &lt;code>CoGroupByKey&lt;/code> to a group of unbounded
&lt;code>PCollection&lt;/code>s without setting either a non-global windowing strategy, a trigger
strategy, or both for each collection, Beam generates an IllegalStateException
error at pipeline construction time.&lt;/p>
&lt;p>When using &lt;code>GroupByKey&lt;/code> or &lt;code>CoGroupByKey&lt;/code> to group &lt;code>PCollection&lt;/code>s that have a
&lt;a href="#windowing">windowing strategy&lt;/a> applied, all of the &lt;code>PCollection&lt;/code>s you want to
group &lt;em>must use the same windowing strategy&lt;/em> and window sizing. For example, all
of the collections you are merging must use (hypothetically) identical 5-minute
fixed windows, or 4-minute sliding windows starting every 30 seconds.&lt;/p>
&lt;p>If your pipeline attempts to use &lt;code>GroupByKey&lt;/code> or &lt;code>CoGroupByKey&lt;/code> to merge
&lt;code>PCollection&lt;/code>s with incompatible windows, Beam generates an
IllegalStateException error at pipeline construction time.&lt;/p>
&lt;h4 id="cogroupbykey">4.2.3. CoGroupByKey&lt;/h4>
&lt;p>&lt;code>CoGroupByKey&lt;/code> performs a relational join of two or more key/value
&lt;code>PCollection&lt;/code>s that have the same key type.
&lt;a href="/documentation/pipelines/design-your-pipeline/#multiple-sources">Design Your Pipeline&lt;/a>
shows an example pipeline that uses a join.&lt;/p>
&lt;p>Consider using &lt;code>CoGroupByKey&lt;/code> if you have multiple data sets that provide
information about related things. For example, let&amp;rsquo;s say you have two different
files with user data: one file has names and email addresses; the other file
has names and phone numbers. You can join those two data sets, using the user
name as a common key and the other data as the associated values. After the
join, you have one data set that contains all of the information (email
addresses and phone numbers) associated with each name.&lt;/p>
&lt;p>If you are using unbounded &lt;code>PCollection&lt;/code>s, you must use either &lt;a href="#setting-your-pcollections-windowing-function">non-global
windowing&lt;/a> or an
&lt;a href="#triggers">aggregation trigger&lt;/a> in order to perform a &lt;code>CoGroupByKey&lt;/code>. See
&lt;a href="#groupbykey-and-unbounded-pcollections">GroupByKey and unbounded PCollections&lt;/a>
for more details.&lt;/p>
&lt;span class="language-java">
In the Beam SDK for Java, `CoGroupByKey` accepts a tuple of keyed
`PCollection`s (`PCollection&lt;KV&lt;K, V>>`) as input. For type safety, the SDK
requires you to pass each `PCollection` as part of a `KeyedPCollectionTuple`.
You must declare a `TupleTag` for each input `PCollection` in the
`KeyedPCollectionTuple` that you want to pass to `CoGroupByKey`. As output,
`CoGroupByKey` returns a `PCollection&lt;KV&lt;K, CoGbkResult>>`, which groups values
from all the input `PCollection`s by their common keys. Each key (all of type
`K`) will have a different `CoGbkResult`, which is a map from `TupleTag&lt;T>` to
`Iterable&lt;T>`. You can access a specific collection in an `CoGbkResult` object
by using the `TupleTag` that you supplied with the initial collection.
&lt;/span>
&lt;span class="language-py">
In the Beam SDK for Python, `CoGroupByKey` accepts a dictionary of keyed
`PCollection`s as input. As output, `CoGroupByKey` creates a single output
`PCollection` that contains one key/value tuple for each key in the input
`PCollection`s. Each key's value is a dictionary that maps each tag to an
iterable of the values under they key in the corresponding `PCollection`.
&lt;/span>
&lt;p>The following conceptual examples use two input collections to show the mechanics of
&lt;code>CoGroupByKey&lt;/code>.&lt;/p>
&lt;span class="language-java">
The first set of data has a `TupleTag&lt;String>` called `emailsTag` and contains names
and email addresses. The second set of data has a `TupleTag&lt;String>` called
`phonesTag` and contains names and phone numbers.
&lt;/span>
&lt;span class="language-py">
The first set of data contains names and email addresses. The second set of
data contains names and phone numbers.
&lt;/span>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">final&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">emailsList&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;amy&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;amy@example.com&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;carl&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;carl@example.com&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;julia&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;julia@example.com&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;carl&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;carl@email.com&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">phonesList&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;amy&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;111-222-3333&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;james&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;222-333-4444&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;amy&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;333-444-5555&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;carl&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;444-555-6666&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">emails&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;CreateEmails&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">emailsList&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">phones&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;CreatePhones&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">phonesList&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">emails_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;amy&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;amy@example.com&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;carl&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;carl@example.com&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;julia&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;julia@example.com&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;carl&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;carl@email.com&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="n">phones_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;amy&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;111-222-3333&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;james&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;222-333-4444&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;amy&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;333-444-5555&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;carl&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;444-555-6666&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="n">emails&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;CreateEmails&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">emails_list&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">phones&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;CreatePhones&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">phones_list&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>After &lt;code>CoGroupByKey&lt;/code>, the resulting data contains all data associated with each
unique key from any of the input collections.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">emailsTag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;();&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">phonesTag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;();&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">expectedResults&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;amy&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">emailsTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;amy@example.com&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">phonesTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;111-222-3333&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;333-444-5555&amp;#34;&lt;/span>&lt;span class="o">))),&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;carl&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">emailsTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;carl@email.com&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;carl@example.com&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">phonesTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;444-555-6666&amp;#34;&lt;/span>&lt;span class="o">))),&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;james&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">emailsTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">phonesTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;222-333-4444&amp;#34;&lt;/span>&lt;span class="o">))),&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;julia&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">emailsTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;julia@example.com&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">phonesTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">())));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">results&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="p">(&lt;/span>
&lt;span class="s1">&amp;#39;amy&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;emails&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;amy@example.com&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;span class="s1">&amp;#39;phones&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;111-222-3333&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;333-444-5555&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="p">}),&lt;/span>
&lt;span class="p">(&lt;/span>
&lt;span class="s1">&amp;#39;carl&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;emails&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;carl@email.com&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;carl@example.com&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;span class="s1">&amp;#39;phones&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;444-555-6666&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="p">}),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;james&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;emails&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[],&lt;/span> &lt;span class="s1">&amp;#39;phones&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;222-333-4444&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="p">}),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;julia&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;emails&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;julia@example.com&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="s1">&amp;#39;phones&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="p">}),&lt;/span>
&lt;span class="p">]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The following code example joins the two &lt;code>PCollection&lt;/code>s with &lt;code>CoGroupByKey&lt;/code>,
followed by a &lt;code>ParDo&lt;/code> to consume the result. Then, the code uses tags to look up
and format data from each collection.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">results&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">KeyedPCollectionTuple&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">emailsTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">emails&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">phonesTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">phones&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CoGroupByKey&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">contactLines&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">results&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">e&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getKey&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">emailsIter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getAll&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">emailsTag&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">phonesIter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getAll&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">phonesTag&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">formattedResult&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">Snippets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">formatCoGbkResults&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">emailsIter&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">phonesIter&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">formattedResult&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># The result PCollection contains one key-value element for each key in the&lt;/span>
&lt;span class="c1"># input PCollections. The key of the pair will be the key from the input and&lt;/span>
&lt;span class="c1"># the value will be a dictionary with two entries: &amp;#39;emails&amp;#39; - an iterable of&lt;/span>
&lt;span class="c1"># all values for the current key in the emails PCollection and &amp;#39;phones&amp;#39;: an&lt;/span>
&lt;span class="c1"># iterable of all values for the current key in the phones PCollection.&lt;/span>
&lt;span class="n">results&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">({&lt;/span>&lt;span class="s1">&amp;#39;emails&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">emails&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;phones&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">phones&lt;/span>&lt;span class="p">}&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CoGroupByKey&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">join_info&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name_info&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">info&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">name_info&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s1">; &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s1">; &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span> &lt;span class="o">%&lt;/span>\
&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">sorted&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">info&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;emails&amp;#39;&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="nb">sorted&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">info&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;phones&amp;#39;&lt;/span>&lt;span class="p">]))&lt;/span>
&lt;span class="n">contact_lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">results&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">join_info&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The formatted data looks like this:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">final&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">formattedResults&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;amy; [&amp;#39;amy@example.com&amp;#39;]; [&amp;#39;111-222-3333&amp;#39;, &amp;#39;333-444-5555&amp;#39;]&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;carl; [&amp;#39;carl@email.com&amp;#39;, &amp;#39;carl@example.com&amp;#39;]; [&amp;#39;444-555-6666&amp;#39;]&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;james; []; [&amp;#39;222-333-4444&amp;#39;]&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;julia; [&amp;#39;julia@example.com&amp;#39;]; []&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">formatted_results&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="s2">&amp;#34;amy; [&amp;#39;amy@example.com&amp;#39;]; [&amp;#39;111-222-3333&amp;#39;, &amp;#39;333-444-5555&amp;#39;]&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;carl; [&amp;#39;carl@email.com&amp;#39;, &amp;#39;carl@example.com&amp;#39;]; [&amp;#39;444-555-6666&amp;#39;]&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;james; []; [&amp;#39;222-333-4444&amp;#39;]&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;julia; [&amp;#39;julia@example.com&amp;#39;]; []&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="combine">4.2.4. Combine&lt;/h4>
&lt;p>&lt;span class="language-java">&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/index.html?org/apache/beam/sdk/transforms/Combine.html">&lt;code>Combine&lt;/code>&lt;/a>&lt;/span>
&lt;span class="language-py">&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/transforms/core.py">&lt;code>Combine&lt;/code>&lt;/a>&lt;/span>
is a Beam transform for combining collections of elements or values in your
data. &lt;code>Combine&lt;/code> has variants that work on entire &lt;code>PCollection&lt;/code>s, and some that
combine the values for each key in &lt;code>PCollection&lt;/code>s of key/value pairs.&lt;/p>
&lt;p>When you apply a &lt;code>Combine&lt;/code> transform, you must provide the function that
contains the logic for combining the elements or values. The combining function
should be commutative and associative, as the function is not necessarily
invoked exactly once on all values with a given key. Because the input data
(including the value collection) may be distributed across multiple workers, the
combining function might be called multiple times to perform partial combining
on subsets of the value collection. The Beam SDK also provides some pre-built
combine functions for common numeric combination operations such as sum, min,
and max.&lt;/p>
&lt;p>Simple combine operations, such as sums, can usually be implemented as a simple
function. More complex combination operations might require you to create a
subclass of &lt;code>CombineFn&lt;/code> that has an accumulation type distinct from the
input/output type.&lt;/p>
&lt;h5 id="simple-combines">4.2.4.1. Simple combinations using simple functions&lt;/h5>
&lt;p>The following example code shows a simple combine function.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Sum a collection of Integer values. The function SumInts implements the interface SerializableFunction.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">SumInts&lt;/span> &lt;span class="kd">implements&lt;/span> &lt;span class="n">SerializableFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Integer&lt;/span> &lt;span class="nf">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">item&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">sum&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">item&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">sum&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">100&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1000&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">bounded_sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">bound&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">500&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">bound&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">small_sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pc&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bounded_sum&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># [500]&lt;/span>
&lt;span class="n">large_sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pc&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bounded_sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">bound&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5000&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># [1111]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="advanced-combines">4.2.4.2. Advanced combinations using CombineFn&lt;/h5>
&lt;p>For more complex combine functions, you can define a subclass of &lt;code>CombineFn&lt;/code>.
You should use &lt;code>CombineFn&lt;/code> if the combine function requires a more sophisticated
accumulator, must perform additional pre- or post-processing, might change the
output type, or takes the key into account.&lt;/p>
&lt;p>A general combining operation consists of four operations. When you create a
subclass of &lt;code>CombineFn&lt;/code>, you must provide four operations by overriding the
corresponding methods:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Create Accumulator&lt;/strong> creates a new &amp;ldquo;local&amp;rdquo; accumulator. In the example
case, taking a mean average, a local accumulator tracks the running sum of
values (the numerator value for our final average division) and the number of
values summed so far (the denominator value). It may be called any number of
times in a distributed fashion.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Add Input&lt;/strong> adds an input element to an accumulator, returning the
accumulator value. In our example, it would update the sum and increment the
count. It may also be invoked in parallel.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Merge Accumulators&lt;/strong> merges several accumulators into a single accumulator;
this is how data in multiple accumulators is combined before the final
calculation. In the case of the mean average computation, the accumulators
representing each portion of the division are merged together. It may be
called again on its outputs any number of times.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Extract Output&lt;/strong> performs the final computation. In the case of computing a
mean average, this means dividing the combined sum of all the values by the
number of values summed. It is called once on the final, merged accumulator.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The following example code shows how to define a &lt;code>CombineFn&lt;/code> that computes a
mean average:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">AverageFn&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">CombineFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">AverageFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Accum&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Accum&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Accum&lt;/span> &lt;span class="nf">createAccumulator&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Accum&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Accum&lt;/span> &lt;span class="nf">addInput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Accum&lt;/span> &lt;span class="n">accum&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">accum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">sum&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="n">accum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">count&lt;/span>&lt;span class="o">++;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">accum&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Accum&lt;/span> &lt;span class="nf">mergeAccumulators&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Accum&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">accums&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Accum&lt;/span> &lt;span class="n">merged&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">createAccumulator&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Accum&lt;/span> &lt;span class="n">accum&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">accums&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">merged&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">sum&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">accum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">sum&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="n">merged&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">count&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">accum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">count&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">merged&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Double&lt;/span> &lt;span class="nf">extractOutput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Accum&lt;/span> &lt;span class="n">accum&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="o">((&lt;/span>&lt;span class="kt">double&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">accum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">sum&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">accum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">count&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">AverageFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">create_accumulator&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mf">0.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">add_input&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">sum_count&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sum_count&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">sum&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">merge_accumulators&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulators&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">sums&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">counts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">accumulators&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sums&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">counts&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">extract_output&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">sum_count&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sum_count&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">sum&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="nb">float&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;NaN&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="combining-pcollection">4.2.4.3. Combining a PCollection into a single value&lt;/h5>
&lt;p>Use the global combine to transform all of the elements in a given &lt;code>PCollection&lt;/code>
into a single value, represented in your pipeline as a new &lt;code>PCollection&lt;/code>
containing one element. The following example code shows how to apply the Beam
provided sum combine function to produce a single sum value for a &lt;code>PCollection&lt;/code>
of integers.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Sum.SumIntegerFn() combines the elements in the input PCollection. The resulting PCollection, called sum,
&lt;/span>&lt;span class="c1">// contains one value: the sum of all the elements in the input PCollection.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Combine&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">globally&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">Sum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">SumIntegerFn&lt;/span>&lt;span class="o">()));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># sum combines the elements in the input PCollection.&lt;/span>
&lt;span class="c1"># The resulting PCollection, called result, contains one value: the sum of all&lt;/span>
&lt;span class="c1"># the elements in the input PCollection.&lt;/span>
&lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="n">average&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pc&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">AverageFn&lt;/span>&lt;span class="p">())&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="combine-global-windowing">4.2.4.4. Combine and global windowing&lt;/h5>
&lt;p>If your input &lt;code>PCollection&lt;/code> uses the default global windowing, the default
behavior is to return a &lt;code>PCollection&lt;/code> containing one item. That item&amp;rsquo;s value
comes from the accumulator in the combine function that you specified when
applying &lt;code>Combine&lt;/code>. For example, the Beam provided sum combine function returns
a zero value (the sum of an empty input), while the min combine function returns
a maximal or infinite value.&lt;/p>
&lt;p>To have &lt;code>Combine&lt;/code> instead return an empty &lt;code>PCollection&lt;/code> if the input is empty,
specify &lt;code>.withoutDefaults&lt;/code> when you apply your &lt;code>Combine&lt;/code> transform, as in the
following code example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Combine&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">globally&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">Sum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">SumIntegerFn&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">withoutDefaults&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="nb">sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pc&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">without_defaults&lt;/span>&lt;span class="p">()&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="combine-non-global-windowing">4.2.4.5. Combine and non-global windowing&lt;/h5>
&lt;p>If your &lt;code>PCollection&lt;/code> uses any non-global windowing function, Beam does not
provide the default behavior. You must specify one of the following options when
applying &lt;code>Combine&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>Specify &lt;code>.withoutDefaults&lt;/code>, where windows that are empty in the input
&lt;code>PCollection&lt;/code> will likewise be empty in the output collection.&lt;/li>
&lt;li>Specify &lt;code>.asSingletonView&lt;/code>, in which the output is immediately converted to a
&lt;code>PCollectionView&lt;/code>, which will provide a default value for each empty window
when used as a side input. You&amp;rsquo;ll generally only need to use this option if
the result of your pipeline&amp;rsquo;s &lt;code>Combine&lt;/code> is to be used as a side input later in
the pipeline.&lt;/li>
&lt;/ul>
&lt;h5 id="combining-values-in-a-keyed-pcollection">4.2.4.6. Combining values in a keyed PCollection&lt;/h5>
&lt;p>After creating a keyed PCollection (for example, by using a &lt;code>GroupByKey&lt;/code>
transform), a common pattern is to combine the collection of values associated
with each key into a single, merged value. Drawing on the previous example from
&lt;code>GroupByKey&lt;/code>, a key-grouped &lt;code>PCollection&lt;/code> called &lt;code>groupedWords&lt;/code> looks like this:&lt;/p>
&lt;pre>&lt;code> cat, [1,5,9]
dog, [5,2]
and, [1,2,6]
jump, [3]
tree, [2]
...
&lt;/code>&lt;/pre>&lt;p>In the above &lt;code>PCollection&lt;/code>, each element has a string key (for example, &amp;ldquo;cat&amp;rdquo;)
and an iterable of integers for its value (in the first element, containing [1,
5, 9]). If our pipeline&amp;rsquo;s next processing step combines the values (rather than
considering them individually), you can combine the iterable of integers to
create a single, merged value to be paired with each key. This pattern of a
&lt;code>GroupByKey&lt;/code> followed by merging the collection of values is equivalent to
Beam&amp;rsquo;s Combine PerKey transform. The combine function you supply to Combine
PerKey must be an associative reduction function or a subclass of &lt;code>CombineFn&lt;/code>.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// PCollection is grouped by key and the Double values associated with each key are combined into a Double.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">salesRecords&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">totalSalesPerPerson&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">salesRecords&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Combine&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">perKey&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">Sum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">SumDoubleFn&lt;/span>&lt;span class="o">()));&lt;/span>
&lt;span class="c1">// The combined value is of a different type than the original collection of values per key. PCollection has
&lt;/span>&lt;span class="c1">// keys of type String and values of type Integer, and the combined value is a Double.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">playerAccuracy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">avgAccuracyPerPlayer&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">playerAccuracy&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Combine&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">perKey&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">MeanInts&lt;/span>&lt;span class="o">())));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># PCollection is grouped by key and the numeric values associated with each key&lt;/span>
&lt;span class="c1"># are averaged into a float.&lt;/span>
&lt;span class="n">player_accuracies&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="n">avg_accuracy_per_player&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">player_accuracies&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombinePerKey&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">combiners&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MeanCombineFn&lt;/span>&lt;span class="p">()))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="flatten">4.2.5. Flatten&lt;/h4>
&lt;p>&lt;span class="language-java">&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/index.html?org/apache/beam/sdk/transforms/Flatten.html">&lt;code>Flatten&lt;/code>&lt;/a>&lt;/span>
&lt;span class="language-py">&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/transforms/core.py">&lt;code>Flatten&lt;/code>&lt;/a>&lt;/span>
is a Beam transform for &lt;code>PCollection&lt;/code> objects that store the same data type.
&lt;code>Flatten&lt;/code> merges multiple &lt;code>PCollection&lt;/code> objects into a single logical
&lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>The following example shows how to apply a &lt;code>Flatten&lt;/code> transform to merge multiple
&lt;code>PCollection&lt;/code> objects.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Flatten takes a PCollectionList of PCollection objects of a given type.
&lt;/span>&lt;span class="c1">// Returns a single PCollection that contains all of the elements in the PCollection objects in that list.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollectionList&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">collections&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PCollectionList&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">pc1&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">pc2&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">pc3&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">merged&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">collections&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Flatten&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">pCollections&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># Flatten takes a tuple of PCollection objects.&lt;/span>
&lt;span class="c1"># Returns a single PCollection that contains all of the elements in the PCollection objects in that tuple.&lt;/span>
&lt;span class="n">merged&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="n">pcoll1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pcoll2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pcoll3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># A list of tuples can be &amp;#34;piped&amp;#34; directly into a Flatten transform.&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Flatten&lt;/span>&lt;span class="p">())&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="data-encoding-merged-collections">4.2.5.1. Data encoding in merged collections&lt;/h5>
&lt;p>By default, the coder for the output &lt;code>PCollection&lt;/code> is the same as the coder for
the first &lt;code>PCollection&lt;/code> in the input &lt;code>PCollectionList&lt;/code>. However, the input
&lt;code>PCollection&lt;/code> objects can each use different coders, as long as they all contain
the same data type in your chosen language.&lt;/p>
&lt;h5 id="merging-windowed-collections">4.2.5.2. Merging windowed collections&lt;/h5>
&lt;p>When using &lt;code>Flatten&lt;/code> to merge &lt;code>PCollection&lt;/code> objects that have a windowing
strategy applied, all of the &lt;code>PCollection&lt;/code> objects you want to merge must use a
compatible windowing strategy and window sizing. For example, all the
collections you&amp;rsquo;re merging must all use (hypothetically) identical 5-minute
fixed windows or 4-minute sliding windows starting every 30 seconds.&lt;/p>
&lt;p>If your pipeline attempts to use &lt;code>Flatten&lt;/code> to merge &lt;code>PCollection&lt;/code> objects with
incompatible windows, Beam generates an &lt;code>IllegalStateException&lt;/code> error when your
pipeline is constructed.&lt;/p>
&lt;h4 id="partition">4.2.6. Partition&lt;/h4>
&lt;p>&lt;span class="language-java">&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/index.html?org/apache/beam/sdk/transforms/Partition.html">&lt;code>Partition&lt;/code>&lt;/a>&lt;/span>
&lt;span class="language-py">&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/transforms/core.py">&lt;code>Partition&lt;/code>&lt;/a>&lt;/span>
is a Beam transform for &lt;code>PCollection&lt;/code> objects that store the same data
type. &lt;code>Partition&lt;/code> splits a single &lt;code>PCollection&lt;/code> into a fixed number of smaller
collections.&lt;/p>
&lt;p>&lt;code>Partition&lt;/code> divides the elements of a &lt;code>PCollection&lt;/code> according to a partitioning
function that you provide. The partitioning function contains the logic that
determines how to split up the elements of the input &lt;code>PCollection&lt;/code> into each
resulting partition &lt;code>PCollection&lt;/code>. The number of partitions must be determined
at graph construction time. You can, for example, pass the number of partitions
as a command-line option at runtime (which will then be used to build your
pipeline graph), but you cannot determine the number of partitions in
mid-pipeline (based on data calculated after your pipeline graph is constructed,
for instance).&lt;/p>
&lt;p>The following example divides a &lt;code>PCollection&lt;/code> into percentile groups.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Provide an int value with the desired number of result partitions, and a PartitionFn that represents the
&lt;/span>&lt;span class="c1">// partitioning function. In this example, we define the PartitionFn in-line. Returns a PCollectionList
&lt;/span>&lt;span class="c1">// containing each of the resulting partitions as individual PCollection objects.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Student&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">students&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="c1">// Split students up into 10 partitions, by percentile:
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollectionList&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Student&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">studentsByPercentile&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">students&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Partition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">10&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">PartitionFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Student&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="nf">partitionFor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Student&lt;/span> &lt;span class="n">student&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">numPartitions&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">student&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getPercentile&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="c1">// 0..99
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">numPartitions&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">100&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}}));&lt;/span>
&lt;span class="c1">// You can extract each partition from the PCollectionList using the get method, as follows:
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Student&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">fortiethPercentile&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">studentsByPercentile&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">4&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># Provide an int value with the desired number of result partitions, and a partitioning function (partition_fn in this example).&lt;/span>
&lt;span class="c1"># Returns a tuple of PCollection objects containing each of the resulting partitions as individual PCollection objects.&lt;/span>
&lt;span class="n">students&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">partition_fn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">student&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">num_partitions&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">get_percentile&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">student&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">num_partitions&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">100&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">by_decile&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">students&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Partition&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">partition_fn&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># You can extract each partition from the tuple of PCollection objects as follows:&lt;/span>
&lt;span class="n">fortieth_percentile&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">by_decile&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="requirements-for-writing-user-code-for-beam-transforms">4.3. Requirements for writing user code for Beam transforms&lt;/h3>
&lt;p>When you build user code for a Beam transform, you should keep in mind the
distributed nature of execution. For example, there might be many copies of your
function running on a lot of different machines in parallel, and those copies
function independently, without communicating or sharing state with any of the
other copies. Depending on the Pipeline Runner and processing back-end you
choose for your pipeline, each copy of your user code function may be retried or
run multiple times. As such, you should be cautious about including things like
state dependency in your user code.&lt;/p>
&lt;p>In general, your user code must fulfill at least these requirements:&lt;/p>
&lt;ul>
&lt;li>Your function object must be &lt;strong>serializable&lt;/strong>.&lt;/li>
&lt;li>Your function object must be &lt;strong>thread-compatible&lt;/strong>, and be aware that &lt;em>the
Beam SDKs are not thread-safe&lt;/em>.&lt;/li>
&lt;/ul>
&lt;p>In addition, it&amp;rsquo;s recommended that you make your function object &lt;strong>idempotent&lt;/strong>.
Non-idempotent functions are supported by Beam, but require additional
thought to ensure correctness when there are external side effects.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> These requirements apply to subclasses of &lt;code>DoFn&lt;/code> (a function object
used with the &lt;a href="#pardo">ParDo&lt;/a> transform), &lt;code>CombineFn&lt;/code> (a function object used
with the &lt;a href="#combine">Combine&lt;/a> transform), and &lt;code>WindowFn&lt;/code> (a function object
used with the &lt;a href="#windowing">Window&lt;/a> transform).&lt;/p>
&lt;/blockquote>
&lt;h4 id="user-code-serializability">4.3.1. Serializability&lt;/h4>
&lt;p>Any function object you provide to a transform must be &lt;strong>fully serializable&lt;/strong>.
This is because a copy of the function needs to be serialized and transmitted to
a remote worker in your processing cluster. The base classes for user code, such
as &lt;code>DoFn&lt;/code>, &lt;code>CombineFn&lt;/code>, and &lt;code>WindowFn&lt;/code>, already implement &lt;code>Serializable&lt;/code>;
however, your subclass must not add any non-serializable members.&lt;/p>
&lt;p>Some other serializability factors you should keep in mind are:&lt;/p>
&lt;ul>
&lt;li>Transient fields in your function object are &lt;em>not&lt;/em> transmitted to worker
instances, because they are not automatically serialized.&lt;/li>
&lt;li>Avoid loading a field with a large amount of data before serialization.&lt;/li>
&lt;li>Individual instances of your function object cannot share data.&lt;/li>
&lt;li>Mutating a function object after it gets applied will have no effect.&lt;/li>
&lt;li>Take care when declaring your function object inline by using an anonymous
inner class instance. In a non-static context, your inner class instance will
implicitly contain a pointer to the enclosing class and that class&amp;rsquo; state.
That enclosing class will also be serialized, and thus the same considerations
that apply to the function object itself also apply to this outer class.&lt;/li>
&lt;/ul>
&lt;h4 id="user-code-thread-compatibility">4.3.2. Thread-compatibility&lt;/h4>
&lt;p>Your function object should be thread-compatible. Each instance of your function
object is accessed by a single thread at a time on a worker instance, unless you
explicitly create your own threads. Note, however, that &lt;strong>the Beam SDKs are not
thread-safe&lt;/strong>. If you create your own threads in your user code, you must
provide your own synchronization. Note that static members in your function
object are not passed to worker instances and that multiple instances of your
function may be accessed from different threads.&lt;/p>
&lt;h4 id="user-code-idempotence">4.3.3. Idempotence&lt;/h4>
&lt;p>It&amp;rsquo;s recommended that you make your function object idempotent&amp;ndash;that is, that it
can be repeated or retried as often as necessary without causing unintended side
effects. Non-idempotent functions are supported, however the Beam model provides
no guarantees as to the number of times your user code might be invoked or retried;
as such, keeping your function object idempotent keeps your pipeline&amp;rsquo;s output
deterministic, and your transforms&amp;rsquo; behavior more predictable and easier to debug.&lt;/p>
&lt;h3 id="side-inputs">4.4. Side inputs&lt;/h3>
&lt;p>In addition to the main input &lt;code>PCollection&lt;/code>, you can provide additional inputs
to a &lt;code>ParDo&lt;/code> transform in the form of side inputs. A side input is an additional
input that your &lt;code>DoFn&lt;/code> can access each time it processes an element in the input
&lt;code>PCollection&lt;/code>. When you specify a side input, you create a view of some other
data that can be read from within the &lt;code>ParDo&lt;/code> transform&amp;rsquo;s &lt;code>DoFn&lt;/code> while processing
each element.&lt;/p>
&lt;p>Side inputs are useful if your &lt;code>ParDo&lt;/code> needs to inject additional data when
processing each element in the input &lt;code>PCollection&lt;/code>, but the additional data
needs to be determined at runtime (and not hard-coded). Such values might be
determined by the input data, or depend on a different branch of your pipeline.&lt;/p>
&lt;h4 id="side-inputs-pardo">4.4.1. Passing side inputs to ParDo&lt;/h4>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="c1">// Pass side inputs to your ParDo transform by invoking .withSideInputs.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// Inside your DoFn, access the side input by using the method DoFn.ProcessContext.sideInput.
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// The input PCollection to ParDo.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="c1">// A PCollection of word lengths that we&amp;#39;ll combine into a single value.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">wordLengths&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span> &lt;span class="c1">// Singleton PCollection
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// Create a singleton PCollectionView from wordLengths using Combine.globally and View.asSingleton.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">PCollectionView&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">maxWordLengthCutOffView&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">wordLengths&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Combine&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">globally&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">Max&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">MaxIntFn&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">asSingletonView&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="c1">// Apply a ParDo that takes maxWordLengthCutOffView as a side input.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">wordsBelowCutOff&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">words&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">OutputReceiver&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// In our DoFn, access the side input.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">lengthCutOff&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">sideInput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">maxWordLengthCutOffView&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">length&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">lengthCutOff&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}).&lt;/span>&lt;span class="na">withSideInputs&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">maxWordLengthCutOffView&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># Side inputs are available as extra arguments in the DoFn&amp;#39;s process method or Map / FlatMap&amp;#39;s callable.&lt;/span>
&lt;span class="c1"># Optional, positional, and keyword arguments are all supported. Deferred arguments are unwrapped into their&lt;/span>
&lt;span class="c1"># actual values. For example, using pvalue.AsIteor(pcoll) at pipeline construction time results in an iterable&lt;/span>
&lt;span class="c1"># of the actual elements of pcoll being passed into each process invocation. In this example, side inputs are&lt;/span>
&lt;span class="c1"># passed to a FlatMap transform as extra arguments and consumed by filter_using_length.&lt;/span>
&lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="c1"># Callable takes additional arguments.&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">filter_using_length&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">lower_bound&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">upper_bound&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">float&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;inf&amp;#39;&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">lower_bound&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">upper_bound&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">word&lt;/span>
&lt;span class="c1"># Construct a deferred side input.&lt;/span>
&lt;span class="n">avg_word_len&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">words&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">combiners&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MeanCombineFn&lt;/span>&lt;span class="p">()))&lt;/span>
&lt;span class="c1"># Call with explicit side inputs.&lt;/span>
&lt;span class="n">small_words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;small&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filter_using_length&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># A single deferred side input.&lt;/span>
&lt;span class="n">larger_than_average&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">words&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;large&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">filter_using_length&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">lower_bound&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsSingleton&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">avg_word_len&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Mix and match.&lt;/span>
&lt;span class="n">small_but_nontrivial&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">filter_using_length&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">lower_bound&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">upper_bound&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsSingleton&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">avg_word_len&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="c1"># We can also pass side inputs to a ParDo transform, which will get passed to its process method.&lt;/span>
&lt;span class="c1"># The first two arguments for the process method would be self and element.&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">FilterUsingLength&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">lower_bound&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">upper_bound&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">float&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;inf&amp;#39;&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">lower_bound&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">upper_bound&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">element&lt;/span>
&lt;span class="n">small_words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">FilterUsingLength&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">...&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="side-inputs-windowing">4.4.2. Side inputs and windowing&lt;/h4>
&lt;p>A windowed &lt;code>PCollection&lt;/code> may be infinite and thus cannot be compressed into a
single value (or single collection class). When you create a &lt;code>PCollectionView&lt;/code>
of a windowed &lt;code>PCollection&lt;/code>, the &lt;code>PCollectionView&lt;/code> represents a single entity
per window (one singleton per window, one list per window, etc.).&lt;/p>
&lt;p>Beam uses the window(s) for the main input element to look up the appropriate
window for the side input element. Beam projects the main input element&amp;rsquo;s window
into the side input&amp;rsquo;s window set, and then uses the side input from the
resulting window. If the main input and side inputs have identical windows, the
projection provides the exact corresponding window. However, if the inputs have
different windows, Beam uses the projection to choose the most appropriate side
input window.&lt;/p>
&lt;p>For example, if the main input is windowed using fixed-time windows of one
minute, and the side input is windowed using fixed-time windows of one hour,
Beam projects the main input window against the side input window set and
selects the side input value from the appropriate hour-long side input window.&lt;/p>
&lt;p>If the main input element exists in more than one window, then &lt;code>processElement&lt;/code>
gets called multiple times, once for each window. Each call to &lt;code>processElement&lt;/code>
projects the &amp;ldquo;current&amp;rdquo; window for the main input element, and thus might provide
a different view of the side input each time.&lt;/p>
&lt;p>If the side input has multiple trigger firings, Beam uses the value from the
latest trigger firing. This is particularly useful if you use a side input with
a single global window and specify a trigger.&lt;/p>
&lt;h3 id="additional-outputs">4.5. Additional outputs&lt;/h3>
&lt;p>While &lt;code>ParDo&lt;/code> always produces a main output &lt;code>PCollection&lt;/code> (as the return value
from &lt;code>apply&lt;/code>), you can also have your &lt;code>ParDo&lt;/code> produce any number of additional
output &lt;code>PCollection&lt;/code>s. If you choose to have multiple outputs, your &lt;code>ParDo&lt;/code>
returns all of the output &lt;code>PCollection&lt;/code>s (including the main output) bundled
together.&lt;/p>
&lt;h4 id="output-tags">4.5.1. Tags for multiple outputs&lt;/h4>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// To emit elements to multiple output PCollections, create a TupleTag object to identify each collection
&lt;/span>&lt;span class="c1">// that your ParDo produces. For example, if your ParDo produces three output PCollections (the main output
&lt;/span>&lt;span class="c1">// and two additional outputs), you must create three TupleTags. The following example code shows how to
&lt;/span>&lt;span class="c1">// create TupleTags for a ParDo with three output PCollections.
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// Input PCollection to our ParDo.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="c1">// The ParDo will filter words whose length is below a cutoff and add them to
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// the main output PCollection&amp;lt;String&amp;gt;.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// If a word is above the cutoff, the ParDo will add the word length to an
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// output PCollection&amp;lt;Integer&amp;gt;.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// If a word starts with the string &amp;#34;MARKER&amp;#34;, the ParDo will add that word to an
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// output PCollection&amp;lt;String&amp;gt;.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">wordLengthCutOff&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">10&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="c1">// Create three TupleTags, one for each output PCollection.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// Output that contains words below the length cutoff.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">wordsBelowCutOffTag&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;(){};&lt;/span>
&lt;span class="c1">// Output that contains word lengths.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">wordLengthsAboveCutOffTag&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;(){};&lt;/span>
&lt;span class="c1">// Output that contains &amp;#34;MARKER&amp;#34; words.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">markedWordsTag&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;(){};&lt;/span>
&lt;span class="c1">// Passing Output Tags to ParDo:
&lt;/span>&lt;span class="c1">// After you specify the TupleTags for each of your ParDo outputs, pass the tags to your ParDo by invoking
&lt;/span>&lt;span class="c1">// .withOutputTags. You pass the tag for the main output first, and then the tags for any additional outputs
&lt;/span>&lt;span class="c1">// in a TupleTagList. Building on our previous example, we pass the three TupleTags for our three output
&lt;/span>&lt;span class="c1">// PCollections to our ParDo. Note that all of the outputs (including the main output PCollection) are
&lt;/span>&lt;span class="c1">// bundled into the returned PCollectionTuple.
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="n">PCollectionTuple&lt;/span> &lt;span class="n">results&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">words&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// DoFn continues here.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="o">})&lt;/span>
&lt;span class="c1">// Specify the tag for the main output.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withOutputTags&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">wordsBelowCutOffTag&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="c1">// Specify the tags for the two additional outputs as a TupleTagList.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">TupleTagList&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">wordLengthsAboveCutOffTag&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">markedWordsTag&lt;/span>&lt;span class="o">)));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># To emit elements to multiple output PCollections, invoke with_outputs() on the ParDo, and specify the&lt;/span>
&lt;span class="c1"># expected tags for the outputs. with_outputs() returns a DoOutputsTuple object. Tags specified in&lt;/span>
&lt;span class="c1"># with_outputs are attributes on the returned DoOutputsTuple object. The tags give access to the&lt;/span>
&lt;span class="c1"># corresponding output PCollections.&lt;/span>
&lt;span class="n">results&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">words&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ProcessWords&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">cutoff_length&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">marker&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;x&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">with_outputs&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s1">&amp;#39;above_cutoff_lengths&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;marked strings&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">main&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;below_cutoff_strings&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="n">below&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">results&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">below_cutoff_strings&lt;/span>
&lt;span class="n">above&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">results&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">above_cutoff_lengths&lt;/span>
&lt;span class="n">marked&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">results&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;marked strings&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1"># indexing works as well&lt;/span>
&lt;span class="c1"># The result is also iterable, ordered in the same order that the tags were passed to with_outputs(),&lt;/span>
&lt;span class="c1"># the main tag (if specified) first.&lt;/span>
&lt;span class="n">below&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">above&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">marked&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">words&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">ProcessWords&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">cutoff_length&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">marker&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;x&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="n">with_outputs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;above_cutoff_lengths&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;marked strings&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">main&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;below_cutoff_strings&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="multiple-outputs-dofn">4.5.2. Emitting to multiple outputs in your DoFn&lt;/h4>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Inside your ParDo&amp;#39;s DoFn, you can emit an element to a specific output PCollection by providing a
&lt;/span>&lt;span class="c1">// MultiOutputReceiver to your process method, and passing in the appropriate TupleTag to obtain an OutputReceiver.
&lt;/span>&lt;span class="c1">// After your ParDo, extract the resulting output PCollections from the returned PCollectionTuple.
&lt;/span>&lt;span class="c1">// Based on the previous example, this shows the DoFn emitting to the main output and two additional outputs.
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">MultiOutputReceiver&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">length&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">wordLengthCutOff&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Emit short word to the main output.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// In this example, it is the output with tag wordsBelowCutOffTag.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">wordsBelowCutOffTag&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Emit long word length to the output with tag wordLengthsAboveCutOffTag.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">wordLengthsAboveCutOffTag&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">length&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">startsWith&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;MARKER&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Emit word to the output with tag markedWordsTag.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">markedWordsTag&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># Inside your ParDo&amp;#39;s DoFn, you can emit an element to a specific output by wrapping the value and the output tag (str).&lt;/span>
&lt;span class="c1"># using the pvalue.OutputValue wrapper class.&lt;/span>
&lt;span class="c1"># Based on the previous example, this shows the DoFn emitting to the main output and two additional outputs.&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">ProcessWords&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cutoff_length&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">marker&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">cutoff_length&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="c1"># Emit this short word to the main output.&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">element&lt;/span>
&lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="c1"># Emit this word&amp;#39;s long length to the &amp;#39;above_cutoff_lengths&amp;#39; output.&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TaggedOutput&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;above_cutoff_lengths&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">startswith&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">marker&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># Emit this word to a different output with the &amp;#39;marked strings&amp;#39; tag.&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TaggedOutput&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;marked strings&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Producing multiple outputs is also available in Map and FlatMap.&lt;/span>
&lt;span class="c1"># Here is an example that uses FlatMap and shows that the tags do not need to be specified ahead of time.&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">even_odd&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TaggedOutput&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;odd&amp;#39;&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="s1">&amp;#39;even&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="mi">10&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">x&lt;/span>
&lt;span class="n">results&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">numbers&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">even_odd&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">with_outputs&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">evens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">results&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">even&lt;/span>
&lt;span class="n">odds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">results&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">odd&lt;/span>
&lt;span class="n">tens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">results&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="bp">None&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1"># the undeclared main output&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="other-dofn-parameters">4.5.3. Accessing additional parameters in your DoFn&lt;/h4>
&lt;p class="language-java">In addition to the element and the &lt;code>OutputReceiver&lt;/code>, Beam will populate other parameters to your DoFn&amp;rsquo;s &lt;code>@ProcessElement&lt;/code> method.
Any combination of these parameters can be added to your process method in any order.&lt;/p>
&lt;p class="language-py">In addition to the element, Beam will populate other parameters to your DoFn&amp;rsquo;s &lt;code>process&lt;/code> method.
Any combination of these parameters can be added to your process method in any order.&lt;/p>
&lt;p class="language-java">&lt;strong>Timestamp:&lt;/strong>
To access the timestamp of an input element, add a parameter annotated with &lt;code>@Timestamp&lt;/code> of type &lt;code>Instant&lt;/code>. For example:&lt;/p>
&lt;p class="language-py">&lt;strong>Timestamp:&lt;/strong>
To access the timestamp of an input element, add a keyword parameter default to &lt;code>DoFn.TimestampParam&lt;/code>. For example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="nd">@Timestamp&lt;/span> &lt;span class="n">Instant&lt;/span> &lt;span class="n">timestamp&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">}})&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">ProcessRecord&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">timestamp&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimestampParam&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># access timestamp of element.&lt;/span>
&lt;span class="k">pass&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">&lt;strong>Window:&lt;/strong>
To access the window an input element falls into, add a parameter of the type of the window used for the input &lt;code>PCollection&lt;/code>.
If the parameter is a window type (a subclass of &lt;code>BoundedWindow&lt;/code>) that does not match the input &lt;code>PCollection&lt;/code>, then an error
will be raised. If an element falls in multiple windows (for example, this will happen when using &lt;code>SlidingWindows&lt;/code>), then the
&lt;code>@ProcessElement&lt;/code> method will be invoked multiple time for the element, once for each window. For example, when fixed windows
are being used, the window is of type &lt;code>IntervalWindow&lt;/code>.&lt;/p>
&lt;p class="language-py">&lt;strong>Window:&lt;/strong>
To access the window an input element falls into, add a keyword parameter default to &lt;code>DoFn.WindowParam&lt;/code>.
If an element falls in multiple windows (for example, this will happen when using &lt;code>SlidingWindows&lt;/code>), then the
&lt;code>process&lt;/code> method will be invoked multiple time for the element, once for each window.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">IntervalWindow&lt;/span> &lt;span class="n">window&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">}})&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">ProcessRecord&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">window&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowParam&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># access window e.g. window.end.micros&lt;/span>
&lt;span class="k">pass&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">&lt;strong>PaneInfo:&lt;/strong>
When triggers are used, Beam provides a &lt;code>PaneInfo&lt;/code> object that contains information about the current firing. Using &lt;code>PaneInfo&lt;/code>
you can determine whether this is an early or a late firing, and how many times this window has already fired for this key.&lt;/p>
&lt;p class="language-py">&lt;strong>PaneInfo:&lt;/strong>
When triggers are used, Beam provides a &lt;code>DoFn.PaneInfoParam&lt;/code> object that contains information about the current firing. Using &lt;code>DoFn.PaneInfoParam&lt;/code>
you can determine whether this is an early or a late firing, and how many times this window has already fired for this key.
This feature implementation in Python SDK is not fully completed; see more at &lt;a href="https://issues.apache.org/jira/browse/BEAM-3759">BEAM-3759&lt;/a>.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">PaneInfo&lt;/span> &lt;span class="n">paneInfo&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">}})&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">ProcessRecord&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pane_info&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PaneInfoParam&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># access pane info, e.g. pane_info.is_first, pane_info.is_last, pane_info.timing&lt;/span>
&lt;span class="k">pass&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">&lt;strong>PipelineOptions:&lt;/strong>
The &lt;code>PipelineOptions&lt;/code> for the current pipeline can always be accessed in a process method by adding it
as a parameter:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">PipelineOptions&lt;/span> &lt;span class="n">options&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">}})&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">&lt;code>@OnTimer&lt;/code> methods can also access many of these parameters. Timestamp, Window, key, &lt;code>PipelineOptions&lt;/code>, &lt;code>OutputReceiver&lt;/code>, and
&lt;code>MultiOutputReceiver&lt;/code> parameters can all be accessed in an &lt;code>@OnTimer&lt;/code> method. In addition, an &lt;code>@OnTimer&lt;/code> method can take
a parameter of type &lt;code>TimeDomain&lt;/code> which tells whether the timer is based on event time or processing time.
Timers are explained in more detail in the
&lt;a href="/blog/2017/08/28/timely-processing.html">Timely (and Stateful) Processing with Apache Beam&lt;/a> blog post.&lt;/p>
&lt;p class="language-py">&lt;strong>Timer and State:&lt;/strong>
In addition to aforementioned parameters, user defined Timer and State parameters can be used in a stateful DoFn.
Timers and States are explained in more detail in the
&lt;a href="/blog/2017/08/28/timely-processing.html">Timely (and Stateful) Processing with Apache Beam&lt;/a> blog post.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">class&lt;/span> &lt;span class="nc">StatefulDoFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;An example stateful DoFn with state and timer&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span class="n">BUFFER_STATE_1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">BagStateSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;buffer1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BytesCoder&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="n">BUFFER_STATE_2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">BagStateSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;buffer2&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">VarIntCoder&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="n">WATERMARK_TIMER&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;watermark_timer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WATERMARK&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">element&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">timestamp&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimestampParam&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">window&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowParam&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">buffer_1&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BUFFER_STATE_1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">buffer_2&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BUFFER_STATE_2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">watermark_timer&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimerParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">WATERMARK_TIMER&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="c1"># Do your processing here&lt;/span>
&lt;span class="n">key&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">element&lt;/span>
&lt;span class="c1"># Read all the data from buffer1&lt;/span>
&lt;span class="n">all_values_in_buffer_1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">buffer_1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">StatefulDoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_is_clear_buffer_1_required&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">all_values_in_buffer_1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># clear the buffer data if required conditions are met.&lt;/span>
&lt;span class="n">buffer_1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">clear&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="c1"># add the value to buffer 2&lt;/span>
&lt;span class="n">buffer_2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">value&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">StatefulDoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_all_condition_met&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="c1"># Clear the timer if certain condition met and you don&amp;#39;t want to trigger&lt;/span>
&lt;span class="c1"># the callback method.&lt;/span>
&lt;span class="n">watermark_timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">clear&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">element&lt;/span>
&lt;span class="nd">@on_timer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">WATERMARK_TIMER&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">on_expiry_1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">timestamp&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimestampParam&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">window&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowParam&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">key&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">KeyParam&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">buffer_1&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BUFFER_STATE_1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">buffer_2&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BUFFER_STATE_2&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="c1"># Window and key parameters are really useful especially for debugging issues.&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="s1">&amp;#39;expired1&amp;#39;&lt;/span>
&lt;span class="nd">@staticmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">_all_condition_met&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="c1"># some logic&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">True&lt;/span>
&lt;span class="nd">@staticmethod&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">_is_clear_buffer_1_required&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">buffer_1_data&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># Some business logic&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="bp">True&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="composite-transforms">4.6. Composite transforms&lt;/h3>
&lt;p>Transforms can have a nested structure, where a complex transform performs
multiple simpler transforms (such as more than one &lt;code>ParDo&lt;/code>, &lt;code>Combine&lt;/code>,
&lt;code>GroupByKey&lt;/code>, or even other composite transforms). These transforms are called
composite transforms. Nesting multiple transforms inside a single composite
transform can make your code more modular and easier to understand.&lt;/p>
&lt;p>The Beam SDK comes packed with many useful composite transforms. See the API
reference pages for a list of transforms:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/index.html?org/apache/beam/sdk/transforms/package-summary.html">Pre-written Beam transforms for Java&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://beam.apache.org/releases/pydoc/2.24.0/apache_beam.transforms.html">Pre-written Beam transforms for Python&lt;/a>&lt;/li>
&lt;/ul>
&lt;h4 id="composite-transform-example">4.6.1. An example composite transform&lt;/h4>
&lt;p>The &lt;code>CountWords&lt;/code> transform in the &lt;a href="/get-started/wordcount-example/">WordCount example program&lt;/a>
is an example of a composite transform. &lt;code>CountWords&lt;/code> is a &lt;code>PTransform&lt;/code> subclass
that consists of multiple nested transforms.&lt;/p>
&lt;p>In its &lt;code>expand&lt;/code> method, the &lt;code>CountWords&lt;/code> transform applies the following
transform operations:&lt;/p>
&lt;ol>
&lt;li>It applies a &lt;code>ParDo&lt;/code> on the input &lt;code>PCollection&lt;/code> of text lines, producing
an output &lt;code>PCollection&lt;/code> of individual words.&lt;/li>
&lt;li>It applies the Beam SDK library transform &lt;code>Count&lt;/code> on the &lt;code>PCollection&lt;/code> of
words, producing a &lt;code>PCollection&lt;/code> of key/value pairs. Each key represents a
word in the text, and each value represents the number of times that word
appeared in the original data.&lt;/li>
&lt;/ol>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">CountWords&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="nf">expand&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">lines&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Convert lines of text into individual words.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">lines&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">ExtractWordsFn&lt;/span>&lt;span class="o">()));&lt;/span>
&lt;span class="c1">// Count the number of times each word occurs.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">wordCounts&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">words&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Count&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">perElement&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">wordCounts&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># The CountWords Composite Transform inside the WordCount pipeline.&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">CountWords&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PTransform&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">expand&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pcoll&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pcoll&lt;/span>
&lt;span class="c1"># Convert lines of text into individual words.&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;ExtractWords&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ExtractWordsFn&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="c1"># Count the number of times each word occurs.&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">combiners&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Count&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PerElement&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="c1"># Format each word and count into a printable string.&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;FormatCounts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">FormatCountsFn&lt;/span>&lt;span class="p">()))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> Because &lt;code>Count&lt;/code> is itself a composite transform,
&lt;code>CountWords&lt;/code> is also a nested composite transform.&lt;/p>
&lt;/blockquote>
&lt;h4 id="composite-transform-creation">4.6.2. Creating a composite transform&lt;/h4>
&lt;p>To create your own composite transform, create a subclass of the &lt;code>PTransform&lt;/code>
class and override the &lt;code>expand&lt;/code> method to specify the actual processing logic.
You can then use this transform just as you would a built-in transform from the
Beam SDK.&lt;/p>
&lt;p class="language-java">For the &lt;code>PTransform&lt;/code> class type parameters, you pass the &lt;code>PCollection&lt;/code> types
that your transform takes as input, and produces as output. To take multiple
&lt;code>PCollection&lt;/code>s as input, or produce multiple &lt;code>PCollection&lt;/code>s as output, use one
of the multi-collection types for the relevant type parameter.&lt;/p>
&lt;p>The following code sample shows how to declare a &lt;code>PTransform&lt;/code> that accepts a
&lt;code>PCollection&lt;/code> of &lt;code>String&lt;/code>s for input, and outputs a &lt;code>PCollection&lt;/code> of &lt;code>Integer&lt;/code>s:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">ComputeWordLengths&lt;/span>
&lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">class&lt;/span> &lt;span class="nc">ComputeWordLengths&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PTransform&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">expand&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pcoll&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># Transform logic goes here.&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">pcoll&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Within your &lt;code>PTransform&lt;/code> subclass, you&amp;rsquo;ll need to override the &lt;code>expand&lt;/code> method.
The &lt;code>expand&lt;/code> method is where you add the processing logic for the &lt;code>PTransform&lt;/code>.
Your override of &lt;code>expand&lt;/code> must accept the appropriate type of input
&lt;code>PCollection&lt;/code> as a parameter, and specify the output &lt;code>PCollection&lt;/code> as the return
value.&lt;/p>
&lt;p>The following code sample shows how to override &lt;code>expand&lt;/code> for the
&lt;code>ComputeWordLengths&lt;/code> class declared in the previous example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">ComputeWordLengths&lt;/span>
&lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">expand&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="c1">// transform logic goes here
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">class&lt;/span> &lt;span class="nc">ComputeWordLengths&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PTransform&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">expand&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pcoll&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># Transform logic goes here.&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">pcoll&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>As long as you override the &lt;code>expand&lt;/code> method in your &lt;code>PTransform&lt;/code> subclass to
accept the appropriate input &lt;code>PCollection&lt;/code>(s) and return the corresponding
output &lt;code>PCollection&lt;/code>(s), you can include as many transforms as you want. These
transforms can include core transforms, composite transforms, or the transforms
included in the Beam SDK libraries.&lt;/p>
&lt;p>Your composite transform&amp;rsquo;s parameters and return value must match the initial
input type and final return type for the entire transform, even if the
transform&amp;rsquo;s intermediate data changes type multiple times.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> The &lt;code>expand&lt;/code> method of a &lt;code>PTransform&lt;/code> is not meant to be invoked
directly by the user of a transform. Instead, you should call the &lt;code>apply&lt;/code> method
on the &lt;code>PCollection&lt;/code> itself, with the transform as an argument. This allows
transforms to be nested within the structure of your pipeline.&lt;/p>
&lt;h4 id="ptransform-style-guide">4.6.3. PTransform Style Guide&lt;/h4>
&lt;p>The &lt;a href="/contribute/ptransform-style-guide/">PTransform Style Guide&lt;/a>
contains additional information not included here, such as style guidelines,
logging and testing guidance, and language-specific considerations. The guide
is a useful starting point when you want to write new composite PTransforms.&lt;/p>
&lt;h2 id="pipeline-io">5. Pipeline I/O&lt;/h2>
&lt;p>When you create a pipeline, you often need to read data from some external
source, such as a file or a database. Likewise, you may
want your pipeline to output its result data to an external storage system.
Beam provides read and write transforms for a &lt;a href="/documentation/io/built-in/">number of common data storage
types&lt;/a>. If you want your pipeline
to read from or write to a data storage format that isn&amp;rsquo;t supported by the
built-in transforms, you can &lt;a href="/documentation/io/developing-io-overview/">implement your own read and write
transforms&lt;/a>.&lt;/p>
&lt;h3 id="pipeline-io-reading-data">5.1. Reading input data&lt;/h3>
&lt;p>Read transforms read data from an external source and return a &lt;code>PCollection&lt;/code>
representation of the data for use by your pipeline. You can use a read
transform at any point while constructing your pipeline to create a new
&lt;code>PCollection&lt;/code>, though it will be most common at the start of your pipeline.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">from&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gs://some/inputData.txt&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ReadFromText&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;gs://some/inputData.txt&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="pipeline-io-writing-data">5.2. Writing output data&lt;/h3>
&lt;p>Write transforms write the data in a &lt;code>PCollection&lt;/code> to an external data source.
You will most often use write transforms at the end of your pipeline to output
your pipeline&amp;rsquo;s final results. However, you can use a write transform to output
a &lt;code>PCollection&lt;/code>'s data at any point in your pipeline.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">output&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gs://some/outputData&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">output&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WriteToText&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;gs://some/outputData&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="file-based-data">5.3. File-based input and output data&lt;/h3>
&lt;h4 id="file-based-reading-multiple-locations">5.3.1. Reading from multiple locations&lt;/h4>
&lt;p>Many read transforms support reading from multiple input files matching a glob
operator you provide. Note that glob operators are filesystem-specific and obey
filesystem-specific consistency models. The following TextIO example uses a glob
operator (&lt;code>*&lt;/code>) to read all matching input files that have prefix &amp;ldquo;input-&amp;rdquo; and the
suffix &amp;ldquo;.csv&amp;rdquo; in the given location:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;ReadFromText&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">from&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;protocol://my_bucket/path/to/input-*.csv&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;ReadFromText&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ReadFromText&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;path/to/input-*.csv&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>To read data from disparate sources into a single &lt;code>PCollection&lt;/code>, read each one
independently and then use the &lt;a href="#flatten">Flatten&lt;/a> transform to create a single
&lt;code>PCollection&lt;/code>.&lt;/p>
&lt;h4 id="file-based-writing-multiple-files">5.3.2. Writing to multiple output files&lt;/h4>
&lt;p>For file-based output data, write transforms write to multiple output files by
default. When you pass an output file name to a write transform, the file name
is used as the prefix for all output files that the write transform produces.
You can append a suffix to each output file by specifying a suffix.&lt;/p>
&lt;p>The following write transform example writes multiple output files to a
location. Each file has the prefix &amp;ldquo;numbers&amp;rdquo;, a numeric tag, and the suffix
&amp;ldquo;.csv&amp;rdquo;.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">records&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;WriteToText&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;protocol://my_bucket/path/to/numbers&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withSuffix&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;.csv&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">filtered_words&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;WriteToText&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WriteToText&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s1">&amp;#39;/path/to/numbers&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">file_name_suffix&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;.csv&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="provided-io-transforms">5.4. Beam-provided I/O transforms&lt;/h3>
&lt;p>See the &lt;a href="/documentation/io/built-in/">Beam-provided I/O Transforms&lt;/a>
page for a list of the currently available I/O transforms.&lt;/p>
&lt;h2 id="schemas">6. Schemas&lt;/h2>
&lt;p>Often, the types of the records being processed have an obvious structure. Common Beam sources produce
JSON, Avro, Protocol Buffer, or database row objects; all of these types have well defined structures,
structures that can often be determined by examining the type. Even within a SDK pipeline, Simple Java POJOs
(or equivalent structures in other languages) are often used as intermediate types, and these also have a
clear structure that can be inferred by inspecting the class. By understanding the structure of a pipeline’s
records, we can provide much more concise APIs for data processing.&lt;/p>
&lt;h3 id="what-is-a-schema">6.1. What is a schema?&lt;/h3>
&lt;p>Most structured records share some common characteristics:&lt;/p>
&lt;ul>
&lt;li>They can be subdivided into separate named fields. Fields usually have string names, but sometimes - as in the case of indexed
tuples - have numerical indices instead.&lt;/li>
&lt;li>There is a confined list of primitive types that a field can have. These often match primitive types in most programming
languages: int, long, string, etc.&lt;/li>
&lt;li>Often a field type can be marked as optional (sometimes referred to as nullable) or required.&lt;/li>
&lt;/ul>
&lt;p>Often records have a nested structure. A nested structure occurs when a field itself has subfields so the
type of the field itself has a schema. Fields that are array or map types is also a common feature of these structured
records.&lt;/p>
&lt;p>For example, consider the following schema, representing actions in a fictitious e-commerce company:&lt;/p>
&lt;p>&lt;strong>Purchase&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>userId&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>itemId&lt;/td>
&lt;td>INT64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shippingAddress&lt;/td>
&lt;td>ROW(ShippingAddress)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cost&lt;/td>
&lt;td>INT64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>transactions&lt;/td>
&lt;td>ARRAY[ROW(Transaction)]&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>&lt;strong>ShippingAddress&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>streetAddress&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>city&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>state&lt;/td>
&lt;td>nullable STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>country&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>postCode&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>&lt;strong>Transaction&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>bank&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>purchaseAmount&lt;/td>
&lt;td>DOUBLE&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>Purchase event records are represented by the above purchase schema. Each purchase event contains a shipping address, which
is a nested row containing its own schema. Each purchase also contains an array of credit-card transactions
(a list, because a purchase might be split across multiple credit cards); each item in the transaction list is a row
with its own schema.&lt;/p>
&lt;p>This provides an abstract description of the types involved, one that is abstracted away from any specific programming
language.&lt;/p>
&lt;p>Schemas provide us a type-system for Beam records that is independent of any specific programming-language type. There
might be multiple Java classes that all have the same schema (for example a Protocol-Buffer class or a POJO class),
and Beam will allow us to seamlessly convert between these types. Schemas also provide a simple way to reason about
types across different programming-language APIs.&lt;/p>
&lt;p>A &lt;code>PCollection&lt;/code> with a schema does not need to have a &lt;code>Coder&lt;/code> specified, as Beam knows how to encode and decode
Schema rows; Beam uses a special coder to encode schema types.&lt;/p>
&lt;h3 id="schemas-for-pl-types">6.2. Schemas for programming language types&lt;/h3>
&lt;p>While schemas themselves are language independent, they are designed to embed naturally into the programming languages
of the Beam SDK being used. This allows Beam users to continue using native types while reaping the advantage of
having Beam understand their element schemas.&lt;/p>
&lt;p class="language-java">In Java you could use the following set of classes to represent the purchase schema. Beam will automatically
infer the correct schema based on the members of the class.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@DefaultSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JavaBeanSchema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Purchase&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getUserId&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="c1">// Returns the id of the user who made the purchase.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">getItemId&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="c1">// Returns the identifier of the item that was purchased.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="n">ShippingAddress&lt;/span> &lt;span class="nf">getShippingAddress&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="c1">// Returns the shipping address, a nested type.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">getCostCents&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="c1">// Returns the cost of the item.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Transaction&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">getTransactions&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="c1">// Returns the transactions that paid for this purchase (returns a list, since the purchase might be spread out over multiple credit cards).
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="nd">@SchemaCreate&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="nf">Purchase&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">userId&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">itemId&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ShippingAddress&lt;/span> &lt;span class="n">shippingAddress&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">costCents&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Transaction&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">transactions&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@DefaultSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JavaBeanSchema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">ShippingAddress&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getStreetAddress&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getCity&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@Nullable&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getState&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getCountry&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getPostCode&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@SchemaCreate&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="nf">ShippingAddress&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">streetAddress&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">city&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="nd">@Nullable&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">country&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">postCode&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@DefaultSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JavaBeanSchema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Transaction&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getBank&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">double&lt;/span> &lt;span class="nf">getPurchaseAmount&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@SchemaCreate&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="nf">Transaction&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">bank&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">double&lt;/span> &lt;span class="n">purchaseAmount&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Using JavaBean classes as above is one way to map a schema to Java classes. However multiple Java classes might have
the same schema, in which case the different Java types can often be used interchangeably. Beam will add implicit
conversions between types that have matching schemas. For example, the above
&lt;code>Transaction&lt;/code> class has the same schema as the following class:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@DefaultSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JavaFieldSchema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TransactionPojo&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">bank&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">double&lt;/span> &lt;span class="n">purchaseAmount&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>So if we had two &lt;code>PCollection&lt;/code>s as follows&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Transaction&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">transactionBeans&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readTransactionsAsJavaBean&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">TransactionPojos&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">transactionPojos&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readTransactionsAsPojo&lt;/span>&lt;span class="o">();&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Then these two &lt;code>PCollection&lt;/code>s would have the same schema, even though their Java types would be different. This means
for example the following two code snippets are valid:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">transactionBeans&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">TransactionPojo&lt;/span> &lt;span class="n">pojo&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>and
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">transactionPojos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">Transaction&lt;/span> &lt;span class="n">row&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;p>Even though the in both cases the &lt;code>@Element&lt;/code> parameter differs from the the &lt;code>PCollection&lt;/code>'s Java type, since the
schemas are the same Beam will automatically make the conversion. The built-in &lt;code>Convert&lt;/code> transform can also be used
to translate between Java types of equivalent schemas, as detailed below.&lt;/p>
&lt;h3 id="schema-definition">6.3. Schema definition&lt;/h3>
&lt;p>The schema for a &lt;code>PCollection&lt;/code> defines elements of that &lt;code>PCollection&lt;/code> as an ordered list of named fields. Each field
has a name, a type, and possibly a set of user options. The type of a field can be primitive or composite. The following
are the primitive types currently supported by Beam:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>BYTE&lt;/td>
&lt;td>An 8-bit signed value&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT16&lt;/td>
&lt;td>A 16-bit signed value&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT32&lt;/td>
&lt;td>A 32-bit signed value&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT64&lt;/td>
&lt;td>A 64-bit signed value&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>DECIMAL&lt;/td>
&lt;td>An arbitrary-precision decimal type&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FLOAT&lt;/td>
&lt;td>A 32-bit IEEE 754 floating point number&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>DOUBLE&lt;/td>
&lt;td>A 64-bit IEEE 754 floating point number&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>STRING&lt;/td>
&lt;td>A string&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>DATETIME&lt;/td>
&lt;td>A timestamp represented as milliseconds since the epoch&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BOOLEAN&lt;/td>
&lt;td>A boolean value&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BYTES&lt;/td>
&lt;td>A raw byte array&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>A field can also reference a nested schema. In this case, the field will have type ROW, and the nested schema will
be an attribute of this field type.&lt;/p>
&lt;p>Three collection types are supported as field types: ARRAY, ITERABLE and MAP:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>ARRAY&lt;/strong> This represents a repeated value type, where the repeated elements can have any supported type. Arrays of
nested rows are supported, as are arrays of arrays.&lt;/li>
&lt;li>&lt;strong>ITERABLE&lt;/strong> This is very similar to the array type, it represents a repeated value, but one in which the full list of
items is not known until iterated over. This is intended for the case where an iterable might be larger than the
available memory, and backed by external storage (for example, this can happen with the iterable returned by a
&lt;code>GroupByKey&lt;/code>). The repeated elements can have any supported type.&lt;/li>
&lt;li>&lt;strong>MAP&lt;/strong> This represents an associative map from keys to values. All schema types are supported for both keys and values.
Values that contain map types cannot be used as keys in any grouping operation.&lt;/li>
&lt;/ul>
&lt;h3 id="logical-types">6.4. Logical types&lt;/h3>
&lt;p>Users can extend the schema type system to add custom logical types that can be used as a field. A logical type is
identified by a unique identifier and an argument. A logical type also specifies an underlying schema type to be used
for storage, along with conversions to and from that type. As an example, a logical union can always be represented as
a row with nullable fields, where the user ensures that only one of those fields is ever set at a time. However this can
be tedious and complex to manage. The OneOf logical type provides a value class that makes it easier to manage the type
as a union, while still using a row with nullable fields as its underlying storage. Each logical type also has a
unique identifier, so they can be interpreted by other languages as well. More examples of logical types are listed
below.&lt;/p>
&lt;h4 id="defining-a-logical-type">6.4.1. Defining a logical type&lt;/h4>
&lt;p>To define a logical type you must specify a Schema type to be used to represent the underlying type as well as a unique
identifier for that type. A logical type imposes additional semantics on top a schema type. For example, a logical
type to represent nanosecond timestamps is represented as a schema containing an INT64 and an INT32 field. This schema
alone does not say anything about how to interpret this type, however the logical type tells you that this represents
a nanosecond timestamp, with the INT64 field representing seconds and the INT32 field representing nanoseconds.&lt;/p>
&lt;p>Logical types are also specified by an argument, which allows creating a class of related types. For example, a
limited-precision decimal type would have an integer argument indicating how many digits of precision are represented.
The argument is represented by a schema type, so can itself be a complex type.&lt;/p>
&lt;p class="language-java">In Java, a logical type is specified as a subclass of the &lt;code>LogicalType&lt;/code> class. A custom Java class can be specified to represent the logical type and conversion functions must be supplied to convert back and forth between this Java class and the underlying Schema type representation. For example, the logical type representing nanosecond timestamp might be implemented as follows&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// A Logical type using java.time.Instant to represent the logical type.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TimestampNanos&lt;/span> &lt;span class="kd">implements&lt;/span> &lt;span class="n">LogicalType&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Instant&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Row&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// The underlying schema used to represent rows.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">Schema&lt;/span> &lt;span class="n">SCHEMA&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Schema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">builder&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">addInt64Field&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;seconds&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">addInt32Field&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;nanos&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@Override&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getIdentifier&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="s">&amp;#34;timestampNanos&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="n">FieldType&lt;/span> &lt;span class="nf">getBaseType&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">schema&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="c1">// Convert the representation type to the underlying Row type. Called by Beam when necessary.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@Override&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="n">Row&lt;/span> &lt;span class="nf">toBaseType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Instant&lt;/span> &lt;span class="n">instant&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">Row&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">schema&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">addValues&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">instant&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getEpochSecond&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">instant&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getNano&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// Convert the underlying Row type to an Instant. Called by Beam when necessary.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@Override&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="n">Instant&lt;/span> &lt;span class="nf">toInputType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Row&lt;/span> &lt;span class="n">base&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">Instant&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">row&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getInt64&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;seconds&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">row&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getInt32&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;nanos&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="built-in-logical-types">6.4.2. Useful logical types&lt;/h4>
&lt;h5 id="enumerationtype">&lt;strong>EnumerationType&lt;/strong>&lt;/h5>
&lt;p>This logical type allows creating an enumeration type consisting of a set of named constants.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Schema&lt;/span> &lt;span class="n">schema&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Schema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">builder&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="err">…&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">addLogicalTypeField&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;color&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">EnumerationType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;RED&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;GREEN&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;BLUE&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The value of this field is stored in the row as an INT32 type, however the logical type defines a value type that lets
you access the enumeration either as a string or a value. For example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">EnumerationType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Value&lt;/span> &lt;span class="n">enumValue&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">enumType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;RED&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">enumValue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="c1">// Returns 0, the integer value of the constant.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">enumValue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="o">//&lt;/span> &lt;span class="n">Returns&lt;/span> &lt;span class="s">&amp;#34;RED&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">the&lt;/span> &lt;span class="n">string&lt;/span> &lt;span class="n">value&lt;/span> &lt;span class="n">of&lt;/span> &lt;span class="n">the&lt;/span> &lt;span class="n">constant&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Given a row object with an enumeration field, you can also extract the field as the enumeration value.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">EnumerationType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Value&lt;/span> &lt;span class="n">enumValue&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">row&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLogicalTypeValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;color&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">EnumerationType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Value&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Automatic schema inference from Java POJOs and JavaBeans automatically converts Java enums to EnumerationType logical
types.&lt;/p>
&lt;h5 id="oneoftype">&lt;strong>OneOfType&lt;/strong>&lt;/h5>
&lt;p>OneOfType allows creating a disjoint union type over a set of schema fields. For example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Schema&lt;/span> &lt;span class="n">schema&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Schema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">builder&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="err">…&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">addLogicalTypeField&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;oneOfField&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">OneOfType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Field&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;intField&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">FieldType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">INT32&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">Field&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;stringField&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">FieldType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">STRING&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">Field&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;bytesField&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">FieldType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">BYTES&lt;/span>&lt;span class="o">)))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The value of this field is stored in the row as another Row type, where all the fields are marked as nullable. The
logical type however defines a Value object that contains an enumeration value indicating which field was set and allows
getting just that field:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Returns an enumeration indicating all possible case values for the enum.
&lt;/span>&lt;span class="c1">// For the above example, this will be
&lt;/span>&lt;span class="c1">// EnumerationType.create(&amp;#34;intField&amp;#34;, &amp;#34;stringField&amp;#34;, &amp;#34;bytesField&amp;#34;);
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">EnumerationType&lt;/span> &lt;span class="n">oneOfEnum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">onOfType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getCaseEnumType&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// Creates an instance of the union with the string field set.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">OneOfType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Value&lt;/span> &lt;span class="n">oneOfValue&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">oneOfType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">createValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;stringField&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;foobar&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Handle the oneof
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="k">switch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">oneOfValue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getCaseEnumType&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">case&lt;/span> &lt;span class="s">&amp;#34;intField&amp;#34;&lt;/span>&lt;span class="o">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">processInt&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">oneOfValue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="k">case&lt;/span> &lt;span class="s">&amp;#34;stringField&amp;#34;&lt;/span>&lt;span class="o">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">processString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">oneOfValue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="k">case&lt;/span> &lt;span class="s">&amp;#34;bytesField&amp;#34;&lt;/span>&lt;span class="o">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">processBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">oneOfValue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">bytes&lt;/span>&lt;span class="o">[].&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>In the above example we used the field names in the switch statement for clarity, however the enum integer values could
also be used.&lt;/p>
&lt;h3 id="creating-schemas">6.5. Creating Schemas&lt;/h3>
&lt;p>In order to take advantage of schemas, your &lt;code>PCollection&lt;/code>s must have a schema attached to it. Often, the source itself will attach a schema to the PCollection. For example, when using &lt;code>AvroIO&lt;/code> to read Avro files, the source can automatically infer a Beam schema from the Avro schema and attach that to the Beam &lt;code>PCollection&lt;/code>. However not all sources produce schemas. In addition, often Beam pipelines have intermediate stages and types, and those also can benefit from the expressiveness of schemas.&lt;/p>
&lt;h4 id="inferring-schemas">6.5.1. Inferring schemas&lt;/h4>
&lt;p class="language-java">Beam is able to infer schemas from a variety of common Java types. The &lt;code>@DefaultSchema&lt;/code> annotation can be used to tell Beam to infer schemas from a specific type. The annotation takes a &lt;code>SchemaProvider&lt;/code> as an argument, and &lt;code>SchemaProvider&lt;/code> classes are already built in for common Java types. The &lt;code>SchemaRegistry&lt;/code> can also be invoked programmatically for cases where it is not practical to annotate the Java type itself.&lt;/p>
&lt;h5 id="java-pojos">&lt;strong>Java POJOs&lt;/strong>&lt;/h5>
&lt;p>A POJO (Plain Old Java Object) is a Java object that is not bound by any restriction other than the Java Language
Specification. A POJO can contain member variables that are primitives, that are other POJOs, or are collections maps or
arrays thereof. POJOs do not have to extend prespecified classes or extend any specific interfaces.&lt;/p>
&lt;p>If a POJO class is annotated with &lt;code>@DefaultSchema(JavaFieldSchema.class)&lt;/code>, Beam will automatically infer a schema for
this class. Nested classes are supported as are classes with &lt;code>List&lt;/code>, array, and &lt;code>Map&lt;/code> fields.&lt;/p>
&lt;p>For example, annotating the following class tells Beam to infer a schema from this POJO class and apply it to any
&lt;code>PCollection&amp;lt;TransactionPojo&amp;gt;&lt;/code>.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@DefaultSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JavaFieldSchema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TransactionPojo&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">bank&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">double&lt;/span> &lt;span class="n">purchaseAmount&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="nd">@SchemaCreate&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="nf">TransactionPojo&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">bank&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">double&lt;/span> &lt;span class="n">purchaseAmount&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">bank&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">bank&lt;/span>&lt;span class="o">.&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">purchaseAmount&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">purchaseAmount&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// Beam will automatically infer the correct schema for this PCollection. No coder is needed as a result.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">TransactionPojo&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pojos&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPojos&lt;/span>&lt;span class="o">();&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The &lt;code>@SchemaCreate&lt;/code> annotation tells Beam that this constructor can be used to create instances of TransactionPojo,
assuming that constructor parameters have the same names as the field names. &lt;code>@SchemaCreate&lt;/code> can also be used to annotate
static factory methods on the class, allowing the constructor to remain private. If there is no &lt;code>@SchemaCreate&lt;/code>
annotation then all the fields must be non-final and the class must have a zero-argument constructor.&lt;/p>
&lt;p>There are a couple of other useful annotations that affect how Beam infers schemas. By default the schema field names
inferred will match that of the class field names. However &lt;code>@SchemaFieldName&lt;/code> can be used to specify a different name to
be used for the schema field. &lt;code>@SchemaIgnore&lt;/code> can be used to mark specific class fields as excluded from the inferred
schema. For example, it’s common to have ephemeral fields in a class that should not be included in a schema
(e.g. caching the hash value to prevent expensive recomputation of the hash), and &lt;code>@SchemaIgnore&lt;/code> can be used to
exclude these fields. Note that ignored fields will not be included in the encoding of these records.&lt;/p>
&lt;p>In some cases it is not convenient to annotate the POJO class, for example if the POJO is in a different package that is
not owned by the Beam pipeline author. In these cases the schema inference can be triggered programmatically in
pipeline’s main function as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getSchemaRegistry&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">registerPOJO&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TransactionPOJO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="java-beans">&lt;strong>Java Beans&lt;/strong>&lt;/h5>
&lt;p>Java Beans are a de-facto standard for creating reusable property classes in Java. While the full
standard has many characteristics, the key ones are that all properties are accessed via getter and setter classes, and
the name format for these getters and setters is standardized. A Java Bean class can be annotated with
&lt;code>@DefaultSchema(JavaBeanSchema.class)&lt;/code> and Beam will automatically infer a schema for this class. For example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@DefaultSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JavaBeanSchema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TransactionBean&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="nf">TransactionBean&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="err">…&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getBank&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="err">…&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">setBank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">bank&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="err">…&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">double&lt;/span> &lt;span class="nf">getPurchaseAmount&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="err">…&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">setPurchaseAmount&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">double&lt;/span> &lt;span class="n">purchaseAmount&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="err">…&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// Beam will automatically infer the correct schema for this PCollection. No coder is needed as a result.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">TransactionBean&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">beans&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readBeans&lt;/span>&lt;span class="o">();&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The &lt;code>@SchemaCreate&lt;/code> annotation can be used to specify a constructor or a static factory method, in which case the
setters and zero-argument constructor can be omitted.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@DefaultSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JavaBeanSchema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TransactionBean&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@SchemaCreate&lt;/span>
&lt;span class="n">Public&lt;/span> &lt;span class="nf">TransactionBean&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">bank&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">double&lt;/span> &lt;span class="n">purchaseAmount&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="err">…&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getBank&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="err">…&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">double&lt;/span> &lt;span class="nf">getPurchaseAmount&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="err">…&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>&lt;code>@SchemaFieldName&lt;/code> and &lt;code>@SchemaIgnore&lt;/code> can be used to alter the schema inferred, just like with POJO classes.&lt;/p>
&lt;h5 id="autovalue">&lt;strong>AutoValue&lt;/strong>&lt;/h5>
&lt;p>Java value classes are notoriously difficult to generate correctly. There is a lot of boilerplate you must create in
order to properly implement a value class. AutoValue is a popular library for easily generating such classes by
implementing a simple abstract base class.&lt;/p>
&lt;p>Beam can infer a schema from an AutoValue class. For example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@DefaultSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AutoValueSchema&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="nd">@AutoValue&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TransactionValue&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getBank&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kt">double&lt;/span> &lt;span class="nf">getPurchaseAmount&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>This is all that’s needed to generate a simple AutoValue class, and the above &lt;code>@DefaultSchema&lt;/code> annotation tells Beam to
infer a schema from it. This also allows AutoValue elements to be used inside of &lt;code>PCollection&lt;/code>s.&lt;/p>
&lt;p>&lt;code>@SchemaFieldName&lt;/code> and &lt;code>@SchemaIgnore&lt;/code> can be used to alter the schema inferred.&lt;/p>
&lt;h3 id="using-schemas">6.6. Using Schema Transforms&lt;/h3>
&lt;p>A schema on a &lt;code>PCollection&lt;/code> enables a rich variety of relational transforms. The fact that each record is composed of
named fields allows for simple and readable aggregations that reference fields by name, similar to the aggregations in
a SQL expression.&lt;/p>
&lt;h4 id="661-field-selection-syntax">6.6.1. Field selection syntax&lt;/h4>
&lt;p>The advantage of schemas is that they allow referencing of element fields by name. Beam provides a selection syntax for
referencing fields, including nested and repeated fields. This syntax is used by all of the schema transforms when
referencing the fields they operate on. The syntax can also be used inside of a DoFn to specify which schema fields to
process.&lt;/p>
&lt;p>Addressing fields by name still retains type safety as Beam will check that schemas match at the time the pipeline graph
is constructed. If a field is specified that does not exist in the schema, the pipeline will fail to launch. In addition,
if a field is specified with a type that does not match the type of that field in the schema, the pipeline will fail to
launch.&lt;/p>
&lt;p>The following characters are not allowed in field names: . * [ ] { }&lt;/p>
&lt;h5 id="top-level-fields">&lt;strong>Top-level fields&lt;/strong>&lt;/h5>
&lt;p>In order to select a field at the top level of a schema, the name of the field is specified. For example, to select just
the user ids from a &lt;code>PCollection&lt;/code> of purchases one would write (using the &lt;code>Select&lt;/code> transform)&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Select&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="nested-fields">&lt;strong>Nested fields&lt;/strong>&lt;/h5>
&lt;p>Individual nested fields can be specified using the dot operator. For example, to select just the postal code from the
shipping address one would write&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Select&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;shippingAddress.postCode&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="wildcards">&lt;strong>Wildcards&lt;/strong>&lt;/h5>
&lt;p>The * operator can be specified at any nesting level to represent all fields at that level. For example, to select all
shipping-address fields one would write&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Select&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;shippingAddress.*&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="arrays">&lt;strong>Arrays&lt;/strong>&lt;/h5>
&lt;p>An array field, where the array element type is a row, can also have subfields of the element type addressed. When
selected, the result is an array of the selected subfield type. For example&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Select&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;transactions[].bank&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Will result in a row containing an array field with element-type string, containing the list of banks for each
transaction.&lt;/p>
&lt;p>While the use of [] brackets in the selector is recommended, to make it clear that array elements are being selected,
they can be omitted for brevity. In the future, array slicing will be supported, allowing selection of portions of the
array.&lt;/p>
&lt;h5 id="maps">&lt;strong>Maps&lt;/strong>&lt;/h5>
&lt;p>A map field, where the value type is a row, can also have subfields of the value type addressed. When selected, the
result is a map where the keys are the same as in the original map but the value is the specified type. Similar to
arrays, the use of {} curly brackets in the selector is recommended, to make it clear that map value elements are being
selected, they can be omitted for brevity. In the future, map key selectors will be supported, allowing selection of
specific keys from the map. For example, given the following schema:&lt;/p>
&lt;p>&lt;strong>PurchasesByType&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>purchases&lt;/td>
&lt;td>MAP{STRING, ROW{PURCHASE}&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>The following&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchasesByType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Select&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;purchases{}.userId&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Will result in a row containing a map field with key-type string and value-type string. The selected map will contain
all of the keys from the original map, and the values will be the userId contained in the purchase record.&lt;/p>
&lt;p>While the use of {} brackets in the selector is recommended, to make it clear that map value elements are being selected,
they can be omitted for brevity. In the future, map slicing will be supported, allowing selection of specific keys from
the map.&lt;/p>
&lt;h4 id="662-schema-transforms">6.6.2. Schema transforms&lt;/h4>
&lt;p>Beam provides a collection of transforms that operate natively on schemas. These transforms are very expressive,
allowing selections and aggregations in terms of named schema fields. Following are some examples of useful
schema transforms.&lt;/p>
&lt;h5 id="selecting-input">&lt;strong>Selecting input&lt;/strong>&lt;/h5>
&lt;p>Often a computation is only interested in a subset of the fields in an input &lt;code>PCollection&lt;/code>. The &lt;code>Select&lt;/code> transform allows
one to easily project out only the fields of interest. The resulting &lt;code>PCollection&lt;/code> has a schema containing each selected
field as a top-level field. Both top-level and nested fields can be selected. For example, in the Purchase schema, one
could select only the userId and streetAddress fields as follows&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Select&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;shippingAddress.streetAddress&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The resulting &lt;code>PCollection&lt;/code> will have the following schema&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>userId&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>streetAddress&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>The same is true for wildcard selections. The following&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Select&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;shippingAddress.*&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Will result in the following schema&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>userId&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>streetAddress&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>city&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>state&lt;/td>
&lt;td>nullable STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>country&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>postCode&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>When selecting fields nested inside of an array, the same rule applies that each selected field appears separately as a
top-level field in the resulting row. This means that if multiple fields are selected from the same nested row, each
selected field will appear as its own array field. For example&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Select&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fieldNames&lt;/span>&lt;span class="o">(&lt;/span> &lt;span class="s">&amp;#34;transactions.bank&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;transactions.purchaseAmount&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Will result in the following schema&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>bank&lt;/td>
&lt;td>ARRAY[STRING]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>purchaseAmount&lt;/td>
&lt;td>ARRAY[DOUBLE]&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>Wildcard selections are equivalent to separately selecting each field.&lt;/p>
&lt;p>Selecting fields nested inside of maps have the same semantics as arrays. If you select multiple fields from a map
, then each selected field will be expanded to its own map at the top level. This means that the set of map keys will
be copied, once for each selected field.&lt;/p>
&lt;p>Sometimes different nested rows will have fields with the same name. Selecting multiple of these fields would result in
a name conflict, as all selected fields are put in the same row schema. When this situation arises, the
&lt;code>Select.withFieldNameAs&lt;/code> builder method can be used to provide an alternate name for the selected field.&lt;/p>
&lt;p>Another use of the Select transform is to flatten a nested schema into a single flat schema. For example&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Select&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">flattenedSchema&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Will result in the following schema&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>userId&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>itemId&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shippingAddress_streetAddress&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shippingAddress_city&lt;/td>
&lt;td>nullable STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shippingAddress_state&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shippingAddress_country&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shippingAddress_postCode&lt;/td>
&lt;td>STRING&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>costCents&lt;/td>
&lt;td>INT64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>transactions_bank&lt;/td>
&lt;td>ARRAY[STRING]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>transactions_purchaseAmount&lt;/td>
&lt;td>ARRAY[DOUBLE]&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;h5 id="grouping-aggregations">&lt;strong>Grouping aggregations&lt;/strong>&lt;/h5>
&lt;p>The &lt;code>Group&lt;/code> transform allows simply grouping data by any number of fields in the input schema, applying aggregations to
those groupings, and storing the result of those aggregations in a new schema field. The output of the &lt;code>Group&lt;/code> transform
has a schema with one field corresponding to each aggregation performed.&lt;/p>
&lt;p>The simplest usage of &lt;code>Group&lt;/code> specifies no aggregations, in which case all inputs matching the provided set of fields
are grouped together into an &lt;code>ITERABLE&lt;/code> field. For example&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Group&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">byFieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;shippingAddress.streetAddress&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The output schema of this is:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>key&lt;/td>
&lt;td>ROW{userId:STRING, streetAddress:STRING}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>values&lt;/td>
&lt;td>ITERABLE[ROW[Purchase]]&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>The key field contains the grouping key and the values field contains a list of all the values that matched that key.&lt;/p>
&lt;p>The names of the key and values fields in the output schema can be controlled using this withKeyField and withValueField
builders, as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Group&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">byFieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;shippingAddress.streetAddress&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withKeyField&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userAndStreet&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withValueField&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;matchingPurchases&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>It is quite common to apply one or more aggregations to the grouped result. Each aggregation can specify one or more fields
to aggregate, an aggregation function, and the name of the resulting field in the output schema. For example, the
following application computes three aggregations grouped by userId, with all aggregations represented in a single
output schema:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Group&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">byFieldNames&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">aggregateField&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;itemId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Count&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">combineFn&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="s">&amp;#34;numPurchases&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">aggregateField&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;costCents&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Sum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">ofLongs&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="s">&amp;#34;totalSpendCents&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">aggregateField&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;costCents&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Top&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">largestLongsFn&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">10&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="s">&amp;#34;topPurchases&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The result of this aggregation will have the following schema:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>key&lt;/td>
&lt;td>ROW{userId:STRING}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>value&lt;/td>
&lt;td>ROW{numPurchases: INT64, totalSpendCents: INT64, topPurchases: ARRAY[INT64]}&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>Often &lt;code>Selected.flattenedSchema&lt;/code> will be use to flatten the result into a non-nested, flat schema.&lt;/p>
&lt;h5 id="joins">&lt;strong>Joins&lt;/strong>&lt;/h5>
&lt;p>Beam supports equijoins on schema &lt;code>PCollections&lt;/code> - namely joins where the join condition depends on the equality of a
subset of fields. For example, the following examples uses the Purchases schema to join transactions with the reviews
that are likely associated with that transaction (both the user and product match that in the transaction). This is a
&amp;ldquo;natural join&amp;rdquo; - one in which the same field names are used on both the left-hand and right-hand sides of the join -
and is specified with the &lt;code>using&lt;/code> keyword:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Transaction&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">transactions&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readTransactions&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Review&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">reviews&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readReviews&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">joined&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transactions&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Join&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">innerJoin&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">reviews&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">using&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;productId&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The resulting schema is the following:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;b>Field Name&lt;/b>&lt;/th>
&lt;th>&lt;b>Field Type&lt;/b>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>lhs&lt;/td>
&lt;td>ROW{Transaction}&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>rhs&lt;/td>
&lt;td>ROW{Review}&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br/>
&lt;p>Each resulting row contains one Review and one Review that matched the join condition.&lt;/p>
&lt;p>If the fields to match in the two schemas have different names, then the on function can be used. For example, if the
Review schema named those fields differently than the Transaction schema, then we could write the following:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">joined&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transactions&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Join&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">innerJoin&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">reviews&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">on&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">FieldsEqual&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">left&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;productId&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">right&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;reviewUserId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;reviewProductId&amp;#34;&lt;/span>&lt;span class="o">)));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>In addition to inner joins, the Join transform supports full outer joins, left outer joins, and right outer joins.&lt;/p>
&lt;h5 id="complex-joins">&lt;strong>Complex joins&lt;/strong>&lt;/h5>
&lt;p>While most joins tend to be binary joins - joining two inputs together - sometimes you have more than two input
streams that all need to be joined on a common key. The &lt;code>CoGroup&lt;/code> transform allows joining multiple &lt;code>PCollections&lt;/code>
together based on equality of schema fields. Each &lt;code>PCollection&lt;/code> can be marked as required or optional in the final
join record, providing a generalization of outer joins to joins with greater than two input &lt;code>PCollection&lt;/code>s. The output
can optionally be expanded - providing individual joined records, as in the &lt;code>Join&lt;/code> transform. The output can also be
processed in unexpanded format - providing the join key along with Iterables of all records from each input that matched
that key.&lt;/p>
&lt;h5 id="filtering-events">&lt;strong>Filtering events&lt;/strong>&lt;/h5>
&lt;p>The &lt;code>Filter&lt;/code> transform can be configured with a set of predicates, each one based one specified fields. Only records for
which all predicates return true will pass the filter. For example the following&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Filter&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">whereFieldName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;costCents&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">100&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">20&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">whereFieldName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;shippingAddress.country&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">equals&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;de&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Will produce all purchases made from Germany with a purchase price of greater than twenty cents.&lt;/p>
&lt;h5 id="adding-fields-to-a-schema">&lt;strong>Adding fields to a schema&lt;/strong>&lt;/h5>
&lt;p>The AddFields transform can be used to extend a schema with new fields. Input rows will be extended to the new schema by
inserting null values for the new fields, though alternate default values can be specified; if the default null value
is used then the new field type will be marked as nullable. Nested subfields can be added using the field selection
syntax, including nested fields inside arrays or map values.&lt;/p>
&lt;p>For example, the following application&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AddFields&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">create&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">field&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timeOfDaySeconds&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">FieldType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">INT32&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">field&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;shippingAddress.deliveryNotes&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">FieldType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">STRING&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">field&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;transactions.isFlagged&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">FieldType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">BOOLEAN&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Results in a &lt;code>PCollection&lt;/code> with an expanded schema. All of the rows and fields of the input, but also with the specified
fields added to the schema. All resulting rows will have null values filled in for the &lt;strong>timeOfDaySeconds&lt;/strong> and the
&lt;strong>shippingAddress.deliveryNotes&lt;/strong> fields, and a false value filled in for the &lt;strong>transactions.isFlagged&lt;/strong> field.&lt;/p>
&lt;h5 id="removing-fields-from-a-schema">&lt;strong>Removing fields from a schema&lt;/strong>&lt;/h5>
&lt;p>&lt;code>DropFields&lt;/code> allows specific fields to be dropped from a schema. Input rows will have their schemas truncated, and any
values for dropped fields will be removed from the output. Nested fields can also be dropped using the field selection
syntax.&lt;/p>
&lt;p>For example, the following snippet&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">DropFields&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fields&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;shippingAddress.streetAddress&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Results in a copy of the input with those two fields and their corresponding values removed.&lt;/p>
&lt;h5 id="renaming-schema-fields">&lt;strong>Renaming schema fields&lt;/strong>&lt;/h5>
&lt;p>&lt;code>RenameFields&lt;/code> allows specific fields in a schema to be renamed. The field values in input rows are left unchanged, only
the schema is modified. This transform is often used to prepare records for output to a schema-aware sink, such as an
RDBMS, to make sure that the &lt;code>PCollection&lt;/code> schema field names match that of the output. It can also be used to rename
fields generated by other transforms to make them more usable (similar to SELECT AS in SQL). Nested fields can also be
renamed using the field-selection syntax.&lt;/p>
&lt;p>For example, the following snippet&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">RenameFields&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">create&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">rename&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;userIdentifier&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">rename&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;shippingAddress.streetAddress&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;shippingAddress.street&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Results in the same set of unmodified input elements, however the schema on the PCollection has been changed to rename
&lt;strong>userId&lt;/strong> to &lt;strong>userIdentifier&lt;/strong> and &lt;strong>shippingAddress.streetAddress&lt;/strong> to &lt;strong>shippingAddress.street&lt;/strong>.&lt;/p>
&lt;h5 id="converting-between-types">&lt;strong>Converting between types&lt;/strong>&lt;/h5>
&lt;p>As mentioned, Beam can automatically convert between different Java types, as long as those types have equivalent
schemas. One way to do this is by using the &lt;code>Convert&lt;/code> transform, as follows.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PurchaseBean&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">purchaseBeans&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPurchasesAsBeans&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pojoPurchases&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">purchaseBeans&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Convert&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Beam will validate that the inferred schema for &lt;code>PurchasePojo&lt;/code> matches that of the input &lt;code>PCollection&lt;/code>, and will
then cast to a &lt;code>PCollection&amp;lt;PurchasePojo&amp;gt;&lt;/code>.&lt;/p>
&lt;p>Since the &lt;code>Row&lt;/code> class can support any schema, any &lt;code>PCollection&lt;/code> with schema can be cast to a &lt;code>PCollection&lt;/code> of rows, as
follows.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">purchaseRows&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">purchaseBeans&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Convert&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toRows&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>If the source type is a single-field schema, Convert will also convert to the type of the field if asked, effectively
unboxing the row. For example, give a schema with a single INT64 field, the following will convert it to a
&lt;code>PCollection&amp;lt;Long&amp;gt;&lt;/code>&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">longs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Convert&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">longs&lt;/span>&lt;span class="o">()));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>In all cases, type checking is done at pipeline graph construction, and if the types do not match the schema then the
pipeline will fail to launch.&lt;/p>
&lt;h4 id="663-schemas-in-pardo">6.6.3. Schemas in ParDo&lt;/h4>
&lt;p>A &lt;code>PCollection&lt;/code> with a schema can apply a &lt;code>ParDo&lt;/code>, just like any other &lt;code>PCollection&lt;/code>. However the Beam runner is aware
of schemas when applying a &lt;code>ParDo&lt;/code>, which enables additional functionality.&lt;/p>
&lt;h5 id="input-conversion">&lt;strong>Input conversion&lt;/strong>&lt;/h5>
&lt;p>Since Beam knows the schema of the source &lt;code>PCollection&lt;/code>, it can automatically convert the elements to any Java type for
which a matching schema is known. For example, using the above-mentioned Transaction schema, say we have the following
&lt;code>PCollection&lt;/code>:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">purchases&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPurchases&lt;/span>&lt;span class="o">();&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>If there were no schema, then the applied &lt;code>DoFn&lt;/code> would have to accept an element of type &lt;code>TransactionPojo&lt;/code>. However
since there is a schema, you could apply the following DoFn:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">appy&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">PurchaseBean&lt;/span> &lt;span class="n">purchase&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Even though the &lt;code>@Element&lt;/code> parameter does not match the Java type of the &lt;code>PCollection&lt;/code>, since it has a matching schema
Beam will automatically convert elements. If the schema does not match, Beam will detect this at graph-construction time
and will fail the job with a type error.&lt;/p>
&lt;p>Since every schema can be represented by a Row type, Row can also be used here:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">appy&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">Row&lt;/span> &lt;span class="n">purchase&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="input-selection">&lt;strong>Input selection&lt;/strong>&lt;/h5>
&lt;p>Since the input has a schema, you can also automatically select specific fields to process in the DoFn.&lt;/p>
&lt;p>Given the above purchases &lt;code>PCollection&lt;/code>, say you want to process just the userId and the itemId fields. You can do these
using the above-described selection expressions, as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">appy&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@FieldAccess&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;userId&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">userId&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="nd">@FieldAccess&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;itemId&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">itemId&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>You can also select nested fields, as follows.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">purchases&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">appy&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">PurchasePojo&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@FieldAccess&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;shippingAddress.street&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">street&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>For more information, see the section on field-selection expressions. When selecting subschemas, Beam will
automatically convert to any matching schema type, just like when reading the entire row.&lt;/p>
&lt;h2 id="data-encoding-and-type-safety">7. Data encoding and type safety&lt;/h2>
&lt;p>When Beam runners execute your pipeline, they often need to materialize the
intermediate data in your &lt;code>PCollection&lt;/code>s, which requires converting elements to
and from byte strings. The Beam SDKs use objects called &lt;code>Coder&lt;/code>s to describe how
the elements of a given &lt;code>PCollection&lt;/code> may be encoded and decoded.&lt;/p>
&lt;blockquote>
&lt;p>Note that coders are unrelated to parsing or formatting data when interacting
with external data sources or sinks. Such parsing or formatting should
typically be done explicitly, using transforms such as &lt;code>ParDo&lt;/code> or
&lt;code>MapElements&lt;/code>.&lt;/p>
&lt;/blockquote>
&lt;p class="language-java">In the Beam SDK for Java, the type &lt;code>Coder&lt;/code> provides the methods required for
encoding and decoding data. The SDK for Java provides a number of Coder
subclasses that work with a variety of standard Java types, such as Integer,
Long, Double, StringUtf8 and more. You can find all of the available Coder
subclasses in the &lt;a href="https://github.com/apache/beam/tree/master/sdks/java/core/src/main/java/org/apache/beam/sdk/coders">Coder package&lt;/a>.&lt;/p>
&lt;p class="language-py">In the Beam SDK for Python, the type &lt;code>Coder&lt;/code> provides the methods required for
encoding and decoding data. The SDK for Python provides a number of Coder
subclasses that work with a variety of standard Python types, such as primitive
types, Tuple, Iterable, StringUtf8 and more. You can find all of the available
Coder subclasses in the
&lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/coders">apache_beam.coders&lt;/a>
package.&lt;/p>
&lt;blockquote>
&lt;p>Note that coders do not necessarily have a 1:1 relationship with types. For
example, the Integer type can have multiple valid coders, and input and output
data can use different Integer coders. A transform might have Integer-typed
input data that uses BigEndianIntegerCoder, and Integer-typed output data that
uses VarIntCoder.&lt;/p>
&lt;/blockquote>
&lt;h3 id="specifying-coders">7.1. Specifying coders&lt;/h3>
&lt;p>The Beam SDKs require a coder for every &lt;code>PCollection&lt;/code> in your pipeline. In most
cases, the Beam SDK is able to automatically infer a &lt;code>Coder&lt;/code> for a &lt;code>PCollection&lt;/code>
based on its element type or the transform that produces it, however, in some
cases the pipeline author will need to specify a &lt;code>Coder&lt;/code> explicitly, or develop
a &lt;code>Coder&lt;/code> for their custom type.&lt;/p>
&lt;p class="language-java">You can explicitly set the coder for an existing &lt;code>PCollection&lt;/code> by using the
method &lt;code>PCollection.setCoder&lt;/code>. Note that you cannot call &lt;code>setCoder&lt;/code> on a
&lt;code>PCollection&lt;/code> that has been finalized (e.g. by calling &lt;code>.apply&lt;/code> on it).&lt;/p>
&lt;p class="language-java">You can get the coder for an existing &lt;code>PCollection&lt;/code> by using the method
&lt;code>getCoder&lt;/code>. This method will fail with an &lt;code>IllegalStateException&lt;/code> if a coder has
not been set and cannot be inferred for the given &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>Beam SDKs use a variety of mechanisms when attempting to automatically infer the
&lt;code>Coder&lt;/code> for a &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p class="language-java">Each pipeline object has a &lt;code>CoderRegistry&lt;/code>. The &lt;code>CoderRegistry&lt;/code> represents a
mapping of Java types to the default coders that the pipeline should use for
&lt;code>PCollection&lt;/code>s of each type.&lt;/p>
&lt;p class="language-py">The Beam SDK for Python has a &lt;code>CoderRegistry&lt;/code> that represents a mapping of
Python types to the default coder that should be used for &lt;code>PCollection&lt;/code>s of each
type.&lt;/p>
&lt;p class="language-java">By default, the Beam SDK for Java automatically infers the &lt;code>Coder&lt;/code> for the
elements of a &lt;code>PCollection&lt;/code> produced by a &lt;code>PTransform&lt;/code> using the type parameter
from the transform&amp;rsquo;s function object, such as &lt;code>DoFn&lt;/code>. In the case of &lt;code>ParDo&lt;/code>,
for example, a &lt;code>DoFn&amp;lt;Integer, String&amp;gt;&lt;/code> function object accepts an input element
of type &lt;code>Integer&lt;/code> and produces an output element of type &lt;code>String&lt;/code>. In such a
case, the SDK for Java will automatically infer the default &lt;code>Coder&lt;/code> for the
output &lt;code>PCollection&amp;lt;String&amp;gt;&lt;/code> (in the default pipeline &lt;code>CoderRegistry&lt;/code>, this is
&lt;code>StringUtf8Coder&lt;/code>).&lt;/p>
&lt;p class="language-py">By default, the Beam SDK for Python automatically infers the &lt;code>Coder&lt;/code> for the
elements of an output &lt;code>PCollection&lt;/code> using the typehints from the transform&amp;rsquo;s
function object, such as &lt;code>DoFn&lt;/code>. In the case of &lt;code>ParDo&lt;/code>, for example a &lt;code>DoFn&lt;/code>
with the typehints &lt;code>@beam.typehints.with_input_types(int)&lt;/code> and
&lt;code>@beam.typehints.with_output_types(str)&lt;/code> accepts an input element of type int
and produces an output element of type str. In such a case, the Beam SDK for
Python will automatically infer the default &lt;code>Coder&lt;/code> for the output &lt;code>PCollection&lt;/code>
(in the default pipeline &lt;code>CoderRegistry&lt;/code>, this is &lt;code>BytesCoder&lt;/code>).&lt;/p>
&lt;blockquote>
&lt;p>NOTE: If you create your &lt;code>PCollection&lt;/code> from in-memory data by using the
&lt;code>Create&lt;/code> transform, you cannot rely on coder inference and default coders.
&lt;code>Create&lt;/code> does not have access to any typing information for its arguments, and
may not be able to infer a coder if the argument list contains a value whose
exact run-time class doesn&amp;rsquo;t have a default coder registered.&lt;/p>
&lt;/blockquote>
&lt;p class="language-java">When using &lt;code>Create&lt;/code>, the simplest way to ensure that you have the correct coder
is by invoking &lt;code>withCoder&lt;/code> when you apply the &lt;code>Create&lt;/code> transform.&lt;/p>
&lt;h3 id="default-coders-and-the-coderregistry">7.2. Default coders and the CoderRegistry&lt;/h3>
&lt;p>Each Pipeline object has a &lt;code>CoderRegistry&lt;/code> object, which maps language types to
the default coder the pipeline should use for those types. You can use the
&lt;code>CoderRegistry&lt;/code> yourself to look up the default coder for a given type, or to
register a new default coder for a given type.&lt;/p>
&lt;p>&lt;code>CoderRegistry&lt;/code> contains a default mapping of coders to standard
&lt;span class="language-java">Java&lt;/span>&lt;span class="language-py">Python&lt;/span>
types for any pipeline you create using the Beam SDK for
&lt;span class="language-java">Java&lt;/span>&lt;span class="language-py">Python&lt;/span>.
The following table shows the standard mapping:&lt;/p>
&lt;p class="language-java">&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>Java Type&lt;/th>
&lt;th>Default Coder&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td>Double&lt;/td>
&lt;td>DoubleCoder&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>Instant&lt;/td>
&lt;td>InstantCoder&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>Integer&lt;/td>
&lt;td>VarIntCoder&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>Iterable&lt;/td>
&lt;td>IterableCoder&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>KV&lt;/td>
&lt;td>KvCoder&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>List&lt;/td>
&lt;td>ListCoder&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>Map&lt;/td>
&lt;td>MapCoder&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>Long&lt;/td>
&lt;td>VarLongCoder&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>String&lt;/td>
&lt;td>StringUtf8Coder&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>TableRow&lt;/td>
&lt;td>TableRowJsonCoder&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>Void&lt;/td>
&lt;td>VoidCoder&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>byte[ ]&lt;/td>
&lt;td>ByteArrayCoder&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>TimestampedValue&lt;/td>
&lt;td>TimestampedValueCoder&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>&lt;/p>
&lt;p class="language-py">&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>Python Type&lt;/th>
&lt;th>Default Coder&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td>int&lt;/td>
&lt;td>VarIntCoder&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>float&lt;/td>
&lt;td>FloatCoder&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>str&lt;/td>
&lt;td>BytesCoder&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>bytes&lt;/td>
&lt;td>StrUtf8Coder&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>Tuple&lt;/td>
&lt;td>TupleCoder&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>&lt;/p>
&lt;h4 id="default-coder-lookup">7.2.1. Looking up a default coder&lt;/h4>
&lt;p class="language-java">You can use the method &lt;code>CoderRegistry.getCoder&lt;/code> to determine the default
Coder for a Java type. You can access the &lt;code>CoderRegistry&lt;/code> for a given pipeline
by using the method &lt;code>Pipeline.getCoderRegistry&lt;/code>. This allows you to determine
(or set) the default Coder for a Java type on a per-pipeline basis: i.e. &amp;ldquo;for
this pipeline, verify that Integer values are encoded using
&lt;code>BigEndianIntegerCoder&lt;/code>.&amp;rdquo;&lt;/p>
&lt;p class="language-py">You can use the method &lt;code>CoderRegistry.get_coder&lt;/code> to determine the default Coder
for a Python type. You can use &lt;code>coders.registry&lt;/code> to access the &lt;code>CoderRegistry&lt;/code>.
This allows you to determine (or set) the default Coder for a Python type.&lt;/p>
&lt;h4 id="setting-default-coder">7.2.2. Setting the default coder for a type&lt;/h4>
&lt;p>To set the default Coder for a
&lt;span class="language-java">Java&lt;/span>&lt;span class="language-py">Python&lt;/span>
type for a particular pipeline, you obtain and modify the pipeline&amp;rsquo;s
&lt;code>CoderRegistry&lt;/code>. You use the method
&lt;span class="language-java">&lt;code>Pipeline.getCoderRegistry&lt;/code>&lt;/span>
&lt;span class="language-py">&lt;code>coders.registry&lt;/code>&lt;/span>
to get the &lt;code>CoderRegistry&lt;/code> object, and then use the method
&lt;span class="language-java">&lt;code>CoderRegistry.registerCoder&lt;/code>&lt;/span>
&lt;span class="language-py">&lt;code>CoderRegistry.register_coder&lt;/code>&lt;/span>
to register a new &lt;code>Coder&lt;/code> for the target type.&lt;/p>
&lt;p>The following example code demonstrates how to set a default Coder, in this case
&lt;code>BigEndianIntegerCoder&lt;/code>, for
&lt;span class="language-java">Integer&lt;/span>&lt;span class="language-py">int&lt;/span>
values for a pipeline.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PipelineOptions&lt;/span> &lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PipelineOptionsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">Pipeline&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">CoderRegistry&lt;/span> &lt;span class="n">cr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getCoderRegistry&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">cr&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">registerCoder&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">BigEndianIntegerCoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">apache_beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">coders&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">registry&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">register_coder&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">BigEndianIntegerCoder&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="annotating-custom-type-default-coder">7.2.3. Annotating a custom data type with a default coder&lt;/h4>
&lt;p class="language-java">If your pipeline program defines a custom data type, you can use the
&lt;code>@DefaultCoder&lt;/code> annotation to specify the coder to use with that type. For
example, let&amp;rsquo;s say you have a custom data type for which you want to use
&lt;code>SerializableCoder&lt;/code>. You can use the &lt;code>@DefaultCoder&lt;/code> annotation as follows:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@DefaultCoder&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AvroCoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MyCustomDataType&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">If you&amp;rsquo;ve created a custom coder to match your data type, and you want to use
the &lt;code>@DefaultCoder&lt;/code> annotation, your coder class must implement a static
&lt;code>Coder.of(Class&amp;lt;T&amp;gt;)&lt;/code> factory method.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MyCustomCoder&lt;/span> &lt;span class="kd">implements&lt;/span> &lt;span class="n">Coder&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Coder&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Class&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">clazz&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{...}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@DefaultCoder&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MyCustomCoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MyCustomDataType&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-py">The Beam SDK for Python does not support annotating data types with a default
coder. If you would like to set a default coder, use the method described in the
previous section, &lt;em>Setting the default coder for a type&lt;/em>.&lt;/p>
&lt;h2 id="windowing">8. Windowing&lt;/h2>
&lt;p>Windowing subdivides a &lt;code>PCollection&lt;/code> according to the timestamps of its
individual elements. Transforms that aggregate multiple elements, such as
&lt;code>GroupByKey&lt;/code> and &lt;code>Combine&lt;/code>, work implicitly on a per-window basis — they process
each &lt;code>PCollection&lt;/code> as a succession of multiple, finite windows, though the
entire collection itself may be of unbounded size.&lt;/p>
&lt;p>A related concept, called &lt;strong>triggers&lt;/strong>, determines when to emit the results of
aggregation as unbounded data arrives. You can use triggers to refine the
windowing strategy for your &lt;code>PCollection&lt;/code>. Triggers allow you to deal with
late-arriving data or to provide early results. See the &lt;a href="#triggers">triggers&lt;/a>
section for more information.&lt;/p>
&lt;h3 id="windowing-basics">8.1. Windowing basics&lt;/h3>
&lt;p>Some Beam transforms, such as &lt;code>GroupByKey&lt;/code> and &lt;code>Combine&lt;/code>, group multiple
elements by a common key. Ordinarily, that grouping operation groups all of the
elements that have the same key within the entire data set. With an unbounded
data set, it is impossible to collect all of the elements, since new elements
are constantly being added and may be infinitely many (e.g. streaming data). If
you are working with unbounded &lt;code>PCollection&lt;/code>s, windowing is especially useful.&lt;/p>
&lt;p>In the Beam model, any &lt;code>PCollection&lt;/code> (including unbounded &lt;code>PCollection&lt;/code>s) can be
subdivided into logical windows. Each element in a &lt;code>PCollection&lt;/code> is assigned to
one or more windows according to the &lt;code>PCollection&lt;/code>'s windowing function, and
each individual window contains a finite number of elements. Grouping transforms
then consider each &lt;code>PCollection&lt;/code>'s elements on a per-window basis. &lt;code>GroupByKey&lt;/code>,
for example, implicitly groups the elements of a &lt;code>PCollection&lt;/code> by &lt;em>key and
window&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Caution:&lt;/strong> Beam&amp;rsquo;s default windowing behavior is to assign all elements of a
&lt;code>PCollection&lt;/code> to a single, global window and discard late data, &lt;em>even for
unbounded &lt;code>PCollection&lt;/code>s&lt;/em>. Before you use a grouping transform such as
&lt;code>GroupByKey&lt;/code> on an unbounded &lt;code>PCollection&lt;/code>, you must do at least one of the
following:&lt;/p>
&lt;ul>
&lt;li>Set a non-global windowing function. See &lt;a href="#setting-your-pcollections-windowing-function">Setting your PCollection&amp;rsquo;s
windowing function&lt;/a>.&lt;/li>
&lt;li>Set a non-default &lt;a href="#triggers">trigger&lt;/a>. This allows the global window to emit
results under other conditions, since the default windowing behavior (waiting
for all data to arrive) will never occur.&lt;/li>
&lt;/ul>
&lt;p>If you don&amp;rsquo;t set a non-global windowing function or a non-default trigger for
your unbounded &lt;code>PCollection&lt;/code> and subsequently use a grouping transform such as
&lt;code>GroupByKey&lt;/code> or &lt;code>Combine&lt;/code>, your pipeline will generate an error upon
construction and your job will fail.&lt;/p>
&lt;h4 id="windowing-constraints">8.1.1. Windowing constraints&lt;/h4>
&lt;p>After you set the windowing function for a &lt;code>PCollection&lt;/code>, the elements&amp;rsquo; windows
are used the next time you apply a grouping transform to that &lt;code>PCollection&lt;/code>.
Window grouping occurs on an as-needed basis. If you set a windowing function
using the &lt;code>Window&lt;/code> transform, each element is assigned to a window, but the
windows are not considered until &lt;code>GroupByKey&lt;/code> or &lt;code>Combine&lt;/code> aggregates across a
window and key. This can have different effects on your pipeline. Consider the
example pipeline in the figure below:&lt;/p>
&lt;p>&lt;img src="/images/windowing-pipeline-unbounded.svg" alt="Diagram of pipeline applying windowing">&lt;/p>
&lt;p>&lt;strong>Figure 3:&lt;/strong> Pipeline applying windowing&lt;/p>
&lt;p>In the above pipeline, we create an unbounded &lt;code>PCollection&lt;/code> by reading a set of
key/value pairs using &lt;code>KafkaIO&lt;/code>, and then apply a windowing function to that
collection using the &lt;code>Window&lt;/code> transform. We then apply a &lt;code>ParDo&lt;/code> to the the
collection, and then later group the result of that &lt;code>ParDo&lt;/code> using &lt;code>GroupByKey&lt;/code>.
The windowing function has no effect on the &lt;code>ParDo&lt;/code> transform, because the
windows are not actually used until they&amp;rsquo;re needed for the &lt;code>GroupByKey&lt;/code>.
Subsequent transforms, however, are applied to the result of the &lt;code>GroupByKey&lt;/code> &amp;ndash;
data is grouped by both key and window.&lt;/p>
&lt;h4 id="windowing-bounded-collections">8.1.2. Windowing with bounded PCollections&lt;/h4>
&lt;p>You can use windowing with fixed-size data sets in &lt;strong>bounded&lt;/strong> &lt;code>PCollection&lt;/code>s.
However, note that windowing considers only the implicit timestamps attached to
each element of a &lt;code>PCollection&lt;/code>, and data sources that create fixed data sets
(such as &lt;code>TextIO&lt;/code>) assign the same timestamp to every element. This means that
all the elements are by default part of a single, global window.&lt;/p>
&lt;p>To use windowing with fixed data sets, you can assign your own timestamps to
each element. To assign timestamps to elements, use a &lt;code>ParDo&lt;/code> transform with a
&lt;code>DoFn&lt;/code> that outputs each element with a new timestamp (for example, the
&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/index.html?org/apache/beam/sdk/transforms/WithTimestamps.html">WithTimestamps&lt;/a>
transform in the Beam SDK for Java).&lt;/p>
&lt;p>To illustrate how windowing with a bounded &lt;code>PCollection&lt;/code> can affect how your
pipeline processes data, consider the following pipeline:&lt;/p>
&lt;p>&lt;img src="/images/unwindowed-pipeline-bounded.svg" alt="Diagram of GroupByKey and ParDo without windowing, on a bounded collection">&lt;/p>
&lt;p>&lt;strong>Figure 4:&lt;/strong> &lt;code>GroupByKey&lt;/code> and &lt;code>ParDo&lt;/code> without windowing, on a bounded collection.&lt;/p>
&lt;p>In the above pipeline, we create a bounded &lt;code>PCollection&lt;/code> by reading a set of
key/value pairs using &lt;code>TextIO&lt;/code>. We then group the collection using &lt;code>GroupByKey&lt;/code>,
and apply a &lt;code>ParDo&lt;/code> transform to the grouped &lt;code>PCollection&lt;/code>. In this example, the
&lt;code>GroupByKey&lt;/code> creates a collection of unique keys, and then &lt;code>ParDo&lt;/code> gets applied
exactly once per key.&lt;/p>
&lt;p>Note that even if you don’t set a windowing function, there is still a window &amp;ndash;
all elements in your &lt;code>PCollection&lt;/code> are assigned to a single global window.&lt;/p>
&lt;p>Now, consider the same pipeline, but using a windowing function:&lt;/p>
&lt;p>&lt;img src="/images/windowing-pipeline-bounded.svg" alt="Diagram of GroupByKey and ParDo with windowing, on a bounded collection">&lt;/p>
&lt;p>&lt;strong>Figure 5:&lt;/strong> &lt;code>GroupByKey&lt;/code> and &lt;code>ParDo&lt;/code> with windowing, on a bounded collection.&lt;/p>
&lt;p>As before, the pipeline creates a bounded &lt;code>PCollection&lt;/code> of key/value pairs. We
then set a &lt;a href="#setting-your-pcollections-windowing-function">windowing function&lt;/a>
for that &lt;code>PCollection&lt;/code>. The &lt;code>GroupByKey&lt;/code> transform groups the elements of the
&lt;code>PCollection&lt;/code> by both key and window, based on the windowing function. The
subsequent &lt;code>ParDo&lt;/code> transform gets applied multiple times per key, once for each
window.&lt;/p>
&lt;h3 id="provided-windowing-functions">8.2. Provided windowing functions&lt;/h3>
&lt;p>You can define different kinds of windows to divide the elements of your
&lt;code>PCollection&lt;/code>. Beam provides several windowing functions, including:&lt;/p>
&lt;ul>
&lt;li>Fixed Time Windows&lt;/li>
&lt;li>Sliding Time Windows&lt;/li>
&lt;li>Per-Session Windows&lt;/li>
&lt;li>Single Global Window&lt;/li>
&lt;li>Calendar-based Windows (not supported by the Beam SDK for Python)&lt;/li>
&lt;/ul>
&lt;p>You can also define your own &lt;code>WindowFn&lt;/code> if you have a more complex need.&lt;/p>
&lt;p>Note that each element can logically belong to more than one window, depending
on the windowing function you use. Sliding time windowing, for example, creates
overlapping windows wherein a single element can be assigned to multiple
windows.&lt;/p>
&lt;h4 id="fixed-time-windows">8.2.1. Fixed time windows&lt;/h4>
&lt;p>The simplest form of windowing is using &lt;strong>fixed time windows&lt;/strong>: given a
timestamped &lt;code>PCollection&lt;/code> which might be continuously updating, each window
might capture (for example) all elements with timestamps that fall into a 30
second interval.&lt;/p>
&lt;p>A fixed time window represents a consistent duration, non overlapping time
interval in the data stream. Consider windows with a 30 second duration: all
of the elements in your unbounded &lt;code>PCollection&lt;/code> with timestamp values from
0:00:00 up to (but not including) 0:00:30 belong to the first window, elements
with timestamp values from 0:00:30 up to (but not including) 0:01:00 belong to
the second window, and so on.&lt;/p>
&lt;p>&lt;img src="/images/fixed-time-windows.png" alt="Diagram of fixed time windows, 30s in duration">&lt;/p>
&lt;p>&lt;strong>Figure 6:&lt;/strong> Fixed time windows, 30s in duration.&lt;/p>
&lt;h4 id="sliding-time-windows">8.2.2. Sliding time windows&lt;/h4>
&lt;p>A &lt;strong>sliding time window&lt;/strong> also represents time intervals in the data stream;
however, sliding time windows can overlap. For example, each window might
capture 60 seconds worth of data, but a new window starts every 30 seconds.
The frequency with which sliding windows begin is called the &lt;em>period&lt;/em>.
Therefore, our example would have a window &lt;em>duration&lt;/em> of 60 seconds and a
&lt;em>period&lt;/em> of 30 seconds.&lt;/p>
&lt;p>Because multiple windows overlap, most elements in a data set will belong to
more than one window. This kind of windowing is useful for taking running
averages of data; using sliding time windows, you can compute a running average
of the past 60 seconds&amp;rsquo; worth of data, updated every 30 seconds, in our
example.&lt;/p>
&lt;p>&lt;img src="/images/sliding-time-windows.png" alt="Diagram of sliding time windows, with 1 minute window duration and 30s window period">&lt;/p>
&lt;p>&lt;strong>Figure 7:&lt;/strong> Sliding time windows, with 1 minute window duration and 30s window
period.&lt;/p>
&lt;h4 id="session-windows">8.2.3. Session windows&lt;/h4>
&lt;p>A &lt;strong>session window&lt;/strong> function defines windows that contain elements that are
within a certain gap duration of another element. Session windowing applies on a
per-key basis and is useful for data that is irregularly distributed with
respect to time. For example, a data stream representing user mouse activity may
have long periods of idle time interspersed with high concentrations of clicks.
If data arrives after the minimum specified gap duration time, this initiates
the start of a new window.&lt;/p>
&lt;p>&lt;img src="/images/session-windows.png" alt="Diagram of session windows with a minimum gap duration">&lt;/p>
&lt;p>&lt;strong>Figure 8:&lt;/strong> Session windows, with a minimum gap duration. Note how each data key
has different windows, according to its data distribution.&lt;/p>
&lt;h4 id="single-global-window">8.2.4. The single global window&lt;/h4>
&lt;p>By default, all data in a &lt;code>PCollection&lt;/code> is assigned to the single global window,
and late data is discarded. If your data set is of a fixed size, you can use the
global window default for your &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>You can use the single global window if you are working with an unbounded data set
(e.g. from a streaming data source) but use caution when applying aggregating
transforms such as &lt;code>GroupByKey&lt;/code> and &lt;code>Combine&lt;/code>. The single global window with a
default trigger generally requires the entire data set to be available before
processing, which is not possible with continuously updating data. To perform
aggregations on an unbounded &lt;code>PCollection&lt;/code> that uses global windowing, you
should specify a non-default trigger for that &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;h3 id="setting-your-pcollections-windowing-function">8.3. Setting your PCollection&amp;rsquo;s windowing function&lt;/h3>
&lt;p>You can set the windowing function for a &lt;code>PCollection&lt;/code> by applying the &lt;code>Window&lt;/code>
transform. When you apply the &lt;code>Window&lt;/code> transform, you must provide a &lt;code>WindowFn&lt;/code>.
The &lt;code>WindowFn&lt;/code> determines the windowing function your &lt;code>PCollection&lt;/code> will use for
subsequent grouping transforms, such as a fixed or sliding time window.&lt;/p>
&lt;p>When you set a windowing function, you may also want to set a trigger for your
&lt;code>PCollection&lt;/code>. The trigger determines when each individual window is aggregated
and emitted, and helps refine how the windowing function performs with respect
to late data and computing early results. See the &lt;a href="#triggers">triggers&lt;/a> section
for more information.&lt;/p>
&lt;h4 id="using-fixed-time-windows">8.3.1. Fixed-time windows&lt;/h4>
&lt;p>The following example code shows how to apply &lt;code>Window&lt;/code> to divide a &lt;code>PCollection&lt;/code>
into fixed windows, each 60 seconds in length:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">fixedWindowedItems&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">items&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Window&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">FixedWindows&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardSeconds&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">60&lt;/span>&lt;span class="o">))));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">window&lt;/span>
&lt;span class="n">fixed_windowed_items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">items&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;window&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">window&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FixedWindows&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">60&lt;/span>&lt;span class="p">)))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="using-sliding-time-windows">8.3.2. Sliding time windows&lt;/h4>
&lt;p>The following example code shows how to apply &lt;code>Window&lt;/code> to divide a &lt;code>PCollection&lt;/code>
into sliding time windows. Each window is 30 seconds in length, and a new window
begins every five seconds:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">slidingWindowedItems&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">items&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Window&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">SlidingWindows&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardSeconds&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">30&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">every&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardSeconds&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">5&lt;/span>&lt;span class="o">))));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">window&lt;/span>
&lt;span class="n">sliding_windowed_items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">items&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;window&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">window&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SlidingWindows&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">)))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="using-session-windows">8.3.3. Session windows&lt;/h4>
&lt;p>The following example code shows how to apply &lt;code>Window&lt;/code> to divide a &lt;code>PCollection&lt;/code>
into session windows, where each session must be separated by a time gap of at
least 10 minutes (600 seconds):&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">sessionWindowedItems&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">items&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Window&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Sessions&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withGapDuration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardSeconds&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">600&lt;/span>&lt;span class="o">))));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">window&lt;/span>
&lt;span class="n">session_windowed_items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">items&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;window&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">window&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Sessions&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">60&lt;/span>&lt;span class="p">)))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Note that the sessions are per-key — each key in the collection will have its
own session groupings depending on the data distribution.&lt;/p>
&lt;h4 id="using-single-global-window">8.3.4. Single global window&lt;/h4>
&lt;p>If your &lt;code>PCollection&lt;/code> is bounded (the size is fixed), you can assign all the
elements to a single global window. The following example code shows how to set
a single global window for a &lt;code>PCollection&lt;/code>:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">batchItems&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">items&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Window&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">GlobalWindows&lt;/span>&lt;span class="o">()));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">window&lt;/span>
&lt;span class="n">session_windowed_items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">items&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;window&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">window&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GlobalWindows&lt;/span>&lt;span class="p">()))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="watermarks-and-late-data">8.4. Watermarks and late data&lt;/h3>
&lt;p>In any data processing system, there is a certain amount of lag between the time
a data event occurs (the &amp;ldquo;event time&amp;rdquo;, determined by the timestamp on the data
element itself) and the time the actual data element gets processed at any stage
in your pipeline (the &amp;ldquo;processing time&amp;rdquo;, determined by the clock on the system
processing the element). In addition, there are no guarantees that data events
will appear in your pipeline in the same order that they were generated.&lt;/p>
&lt;p>For example, let&amp;rsquo;s say we have a &lt;code>PCollection&lt;/code> that&amp;rsquo;s using fixed-time
windowing, with windows that are five minutes long. For each window, Beam must
collect all the data with an &lt;em>event time&lt;/em> timestamp in the given window range
(between 0:00 and 4:59 in the first window, for instance). Data with timestamps
outside that range (data from 5:00 or later) belong to a different window.&lt;/p>
&lt;p>However, data isn&amp;rsquo;t always guaranteed to arrive in a pipeline in time order, or
to always arrive at predictable intervals. Beam tracks a &lt;em>watermark&lt;/em>, which is
the system&amp;rsquo;s notion of when all data in a certain window can be expected to have
arrived in the pipeline. Once the watermark progresses past the end of a window,
any further element that arrives with a timestamp in that window is considered
&lt;strong>late data&lt;/strong>.&lt;/p>
&lt;p>From our example, suppose we have a simple watermark that assumes approximately
30s of lag time between the data timestamps (the event time) and the time the
data appears in the pipeline (the processing time), then Beam would close the
first window at 5:30. If a data record arrives at 5:34, but with a timestamp
that would put it in the 0:00-4:59 window (say, 3:38), then that record is late
data.&lt;/p>
&lt;p>Note: For simplicity, we&amp;rsquo;ve assumed that we&amp;rsquo;re using a very straightforward
watermark that estimates the lag time. In practice, your &lt;code>PCollection&lt;/code>'s data
source determines the watermark, and watermarks can be more precise or complex.&lt;/p>
&lt;p>Beam&amp;rsquo;s default windowing configuration tries to determine when all data has
arrived (based on the type of data source) and then advances the watermark past
the end of the window. This default configuration does &lt;em>not&lt;/em> allow late data.
&lt;a href="#triggers">Triggers&lt;/a> allow you to modify and refine the windowing strategy for
a &lt;code>PCollection&lt;/code>. You can use triggers to decide when each individual window
aggregates and reports its results, including how the window emits late
elements.&lt;/p>
&lt;h4 id="managing-late-data">8.4.1. Managing late data&lt;/h4>
&lt;p>You can allow late data by invoking the &lt;code>.withAllowedLateness&lt;/code> operation when
you set your &lt;code>PCollection&lt;/code>'s windowing strategy. The following code example
demonstrates a windowing strategy that will allow late data up to two days after
the end of a window.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">fixedWindowedItems&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">items&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Window&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">FixedWindows&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">)))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withAllowedLateness&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardDays&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">2&lt;/span>&lt;span class="o">)));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Initial&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">pc&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">FixedWindows&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">60&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">trigger&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">trigger_fn&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">accumulation_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">accumulation_mode&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">timestamp_combiner&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">timestamp_combiner&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">allowed_lateness&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">seconds&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="mi">24&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="mi">60&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="mi">60&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="c1"># 2 days&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>When you set &lt;code>.withAllowedLateness&lt;/code> on a &lt;code>PCollection&lt;/code>, that allowed lateness
propagates forward to any subsequent &lt;code>PCollection&lt;/code> derived from the first
&lt;code>PCollection&lt;/code> you applied allowed lateness to. If you want to change the allowed
lateness later in your pipeline, you must do so explicitly by applying
&lt;code>Window.configure().withAllowedLateness()&lt;/code>.&lt;/p>
&lt;h3 id="adding-timestamps-to-a-pcollections-elements">8.5. Adding timestamps to a PCollection&amp;rsquo;s elements&lt;/h3>
&lt;p>An unbounded source provides a timestamp for each element. Depending on your
unbounded source, you may need to configure how the timestamp is extracted from
the raw data stream.&lt;/p>
&lt;p>However, bounded sources (such as a file from &lt;code>TextIO&lt;/code>) do not provide
timestamps. If you need timestamps, you must add them to your &lt;code>PCollection&lt;/code>’s
elements.&lt;/p>
&lt;p>You can assign new timestamps to the elements of a &lt;code>PCollection&lt;/code> by applying a
&lt;a href="#pardo">ParDo&lt;/a> transform that outputs new elements with timestamps that you
set.&lt;/p>
&lt;p>An example might be if your pipeline reads log records from an input file, and
each log record includes a timestamp field; since your pipeline reads the
records in from a file, the file source doesn&amp;rsquo;t assign timestamps automatically.
You can parse the timestamp field from each record and use a &lt;code>ParDo&lt;/code> transform
with a &lt;code>DoFn&lt;/code> to attach the timestamps to each element in your &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">LogEntry&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">unstampedLogs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">LogEntry&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">stampedLogs&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">unstampedLogs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">LogEntry&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LogEntry&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">LogEntry&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">OutputReceiver&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">LogEntry&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Extract the timestamp from log entry we&amp;#39;re currently processing.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Instant&lt;/span> &lt;span class="n">logTimeStamp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">extractTimeStampFromLogEntry&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Use OutputReceiver.outputWithTimestamp (rather than
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// OutputReceiver.output) to emit the entry with timestamp attached.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">outputWithTimestamp&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">logTimeStamp&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">class&lt;/span> &lt;span class="nc">AddTimestampDoFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># Extract the numeric Unix seconds-since-epoch timestamp to be&lt;/span>
&lt;span class="c1"># associated with the current log entry.&lt;/span>
&lt;span class="n">unix_timestamp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">extract_timestamp_from_log_entry&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Wrap and emit the current entry and new timestamp in a&lt;/span>
&lt;span class="c1"># TimestampedValue.&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">window&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimestampedValue&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">unix_timestamp&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">timestamped_items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">items&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;timestamp&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">AddTimestampDoFn&lt;/span>&lt;span class="p">())&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="triggers">9. Triggers&lt;/h2>
&lt;p>When collecting and grouping data into windows, Beam uses &lt;strong>triggers&lt;/strong> to
determine when to emit the aggregated results of each window (referred to as a
&lt;em>pane&lt;/em>). If you use Beam&amp;rsquo;s default windowing configuration and &lt;a href="#default-trigger">default
trigger&lt;/a>, Beam outputs the aggregated result when it
&lt;a href="#watermarks-and-late-data">estimates all data has arrived&lt;/a>, and discards all
subsequent data for that window.&lt;/p>
&lt;p>You can set triggers for your &lt;code>PCollection&lt;/code>s to change this default behavior.
Beam provides a number of pre-built triggers that you can set:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Event time triggers&lt;/strong>. These triggers operate on the event time, as
indicated by the timestamp on each data element. Beam&amp;rsquo;s default trigger is
event time-based.&lt;/li>
&lt;li>&lt;strong>Processing time triggers&lt;/strong>. These triggers operate on the processing time
&amp;ndash; the time when the data element is processed at any given stage in the
pipeline.&lt;/li>
&lt;li>&lt;strong>Data-driven triggers&lt;/strong>. These triggers operate by examining the data as it
arrives in each window, and firing when that data meets a certain property.
Currently, data-driven triggers only support firing after a certain number
of data elements.&lt;/li>
&lt;li>&lt;strong>Composite triggers&lt;/strong>. These triggers combine multiple triggers in various
ways.&lt;/li>
&lt;/ul>
&lt;p>At a high level, triggers provide two additional capabilities compared to simply
outputting at the end of a window:&lt;/p>
&lt;ul>
&lt;li>Triggers allow Beam to emit early results, before all the data in a given
window has arrived. For example, emitting after a certain amount of time
elapses, or after a certain number of elements arrives.&lt;/li>
&lt;li>Triggers allow processing of late data by triggering after the event time
watermark passes the end of the window.&lt;/li>
&lt;/ul>
&lt;p>These capabilities allow you to control the flow of your data and balance
between different factors depending on your use case:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Completeness:&lt;/strong> How important is it to have all of your data before you
compute your result?&lt;/li>
&lt;li>&lt;strong>Latency:&lt;/strong> How long do you want to wait for data? For example, do you wait
until you think you have all data? Do you process data as it arrives?&lt;/li>
&lt;li>&lt;strong>Cost:&lt;/strong> How much compute power/money are you willing to spend to lower the
latency?&lt;/li>
&lt;/ul>
&lt;p>For example, a system that requires time-sensitive updates might use a strict
time-based trigger that emits a window every &lt;em>N&lt;/em> seconds, valuing promptness
over data completeness. A system that values data completeness more than the
exact timing of results might choose to use Beam&amp;rsquo;s default trigger, which fires
at the end of the window.&lt;/p>
&lt;p>You can also set a trigger for an unbounded &lt;code>PCollection&lt;/code> that uses a &lt;a href="#windowing">single
global window for its windowing function&lt;/a>. This can be useful when
you want your pipeline to provide periodic updates on an unbounded data set —
for example, a running average of all data provided to the present time, updated
every N seconds or every N elements.&lt;/p>
&lt;h3 id="event-time-triggers">9.1. Event time triggers&lt;/h3>
&lt;p>The &lt;code>AfterWatermark&lt;/code> trigger operates on &lt;em>event time&lt;/em>. The &lt;code>AfterWatermark&lt;/code>
trigger emits the contents of a window after the
&lt;a href="#watermarks-and-late-data">watermark&lt;/a> passes the end of the window, based on the
timestamps attached to the data elements. The watermark is a global progress
metric, and is Beam&amp;rsquo;s notion of input completeness within your pipeline at any
given point. &lt;span class="language-java">&lt;code>AfterWatermark.pastEndOfWindow()&lt;/code>&lt;/span>
&lt;span class="language-py">&lt;code>AfterWatermark&lt;/code>&lt;/span> &lt;em>only&lt;/em> fires when the
watermark passes the end of the window.&lt;/p>
&lt;p>In addition, you can configure triggers that fire if your pipeline receives data
before or after the end of the window.&lt;/p>
&lt;p>The following example shows a billing scenario, and uses both early and late
firings:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="c1">// Create a bill at the end of the month.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">AfterWatermark&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">pastEndOfWindow&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="c1">// During the month, get near real-time estimates.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withEarlyFirings&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">AfterProcessingTime&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">pastFirstElementInPane&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">plusDuration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="c1">// Fire on any late data so the bill can be corrected.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withLateFirings&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AfterPane&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">elementCountAtLeast&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">AfterWatermark&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">early&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">AfterProcessingTime&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">delay&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">60&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">late&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">AfterCount&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="default-trigger">9.1.1. Default trigger&lt;/h4>
&lt;p>The default trigger for a &lt;code>PCollection&lt;/code> is based on event time, and emits the
results of the window when the Beam&amp;rsquo;s watermark passes the end of the window,
and then fires each time late data arrives.&lt;/p>
&lt;p>However, if you are using both the default windowing configuration and the
default trigger, the default trigger emits exactly once, and late data is
discarded. This is because the default windowing configuration has an allowed
lateness value of 0. See the Handling Late Data section for information about
modifying this behavior.&lt;/p>
&lt;h3 id="processing-time-triggers">9.2. Processing time triggers&lt;/h3>
&lt;p>The &lt;code>AfterProcessingTime&lt;/code> trigger operates on &lt;em>processing time&lt;/em>. For example,
the &lt;span class="language-java">&lt;code>AfterProcessingTime.pastFirstElementInPane()&lt;/code>&lt;/span>
&lt;span class="language-py">&lt;code>AfterProcessingTime&lt;/code>&lt;/span> trigger emits a window
after a certain amount of processing time has passed since data was received.
The processing time is determined by the system clock, rather than the data
element&amp;rsquo;s timestamp.&lt;/p>
&lt;p>The &lt;code>AfterProcessingTime&lt;/code> trigger is useful for triggering early results from a
window, particularly a window with a large time frame such as a single global
window.&lt;/p>
&lt;h3 id="data-driven-triggers">9.3. Data-driven triggers&lt;/h3>
&lt;p>Beam provides one data-driven trigger,
&lt;span class="language-java">&lt;code>AfterPane.elementCountAtLeast()&lt;/code>&lt;/span>
&lt;span class="language-py">&lt;code>AfterCount&lt;/code>&lt;/span>. This trigger works on an element
count; it fires after the current pane has collected at least &lt;em>N&lt;/em> elements. This
allows a window to emit early results (before all the data has accumulated),
which can be particularly useful if you are using a single global window.&lt;/p>
&lt;p>It is important to note that if, for example, you specify
&lt;span class="language-java">&lt;code>.elementCountAtLeast(50)&lt;/code>&lt;/span>
&lt;span class="language-py">AfterCount(50)&lt;/span> and only 32 elements arrive,
those 32 elements sit around forever. If the 32 elements are important to you,
consider using &lt;a href="#composite-triggers">composite triggers&lt;/a> to combine multiple
conditions. This allows you to specify multiple firing conditions such as &amp;ldquo;fire
either when I receive 50 elements, or every 1 second&amp;rdquo;.&lt;/p>
&lt;h3 id="setting-a-trigger">9.4. Setting a trigger&lt;/h3>
&lt;p>When you set a windowing function for a &lt;code>PCollection&lt;/code> by using the
&lt;span class="language-java">&lt;code>Window&lt;/code>&lt;/span>&lt;span class="language-py">&lt;code>WindowInto&lt;/code>&lt;/span>
transform, you can also specify a trigger.&lt;/p>
&lt;p class="language-java">You set the trigger(s) for a &lt;code>PCollection&lt;/code> by invoking the method
&lt;code>.triggering()&lt;/code> on the result of your &lt;code>Window.into()&lt;/code> transform. This code
sample sets a time-based trigger for a &lt;code>PCollection&lt;/code>, which emits results one
minute after the first element in that window has been processed. The last line
in the code sample, &lt;code>.discardingFiredPanes()&lt;/code>, sets the window&amp;rsquo;s &lt;strong>accumulation
mode&lt;/strong>.&lt;/p>
&lt;p class="language-py">You set the trigger(s) for a &lt;code>PCollection&lt;/code> by setting the &lt;code>trigger&lt;/code> parameter
when you use the &lt;code>WindowInto&lt;/code> transform. This code sample sets a time-based
trigger for a &lt;code>PCollection&lt;/code>, which emits results one minute after the first
element in that window has been processed. The &lt;code>accumulation_mode&lt;/code> parameter
sets the window&amp;rsquo;s &lt;strong>accumulation mode&lt;/strong>.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">pc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Window&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">FixedWindows&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">TimeUnit&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">MINUTES&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">triggering&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AfterProcessingTime&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">pastFirstElementInPane&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">plusDelayOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">)))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">discardingFiredPanes&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">pcollection&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">FixedWindows&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">60&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">trigger&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">AfterProcessingTime&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">60&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">accumulation_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">AccumulationMode&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DISCARDING&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="window-accumulation-modes">9.4.1. Window accumulation modes&lt;/h4>
&lt;p>When you specify a trigger, you must also set the the window&amp;rsquo;s &lt;strong>accumulation
mode&lt;/strong>. When a trigger fires, it emits the current contents of the window as a
pane. Since a trigger can fire multiple times, the accumulation mode determines
whether the system &lt;em>accumulates&lt;/em> the window panes as the trigger fires, or
&lt;em>discards&lt;/em> them.&lt;/p>
&lt;p class="language-java">To set a window to accumulate the panes that are produced when the trigger
fires, invoke&lt;code>.accumulatingFiredPanes()&lt;/code> when you set the trigger. To set a
window to discard fired panes, invoke &lt;code>.discardingFiredPanes()&lt;/code>.&lt;/p>
&lt;p class="language-py">To set a window to accumulate the panes that are produced when the trigger
fires, set the &lt;code>accumulation_mode&lt;/code> parameter to &lt;code>ACCUMULATING&lt;/code> when you set the
trigger. To set a window to discard fired panes, set &lt;code>accumulation_mode&lt;/code> to
&lt;code>DISCARDING&lt;/code>.&lt;/p>
&lt;p>Let&amp;rsquo;s look an example that uses a &lt;code>PCollection&lt;/code> with fixed-time windowing and a
data-based trigger. This is something you might do if, for example, each window
represented a ten-minute running average, but you wanted to display the current
value of the average in a UI more frequently than every ten minutes. We&amp;rsquo;ll
assume the following conditions:&lt;/p>
&lt;ul>
&lt;li>The &lt;code>PCollection&lt;/code> uses 10-minute fixed-time windows.&lt;/li>
&lt;li>The &lt;code>PCollection&lt;/code> has a repeating trigger that fires every time 3 elements
arrive.&lt;/li>
&lt;/ul>
&lt;p>The following diagram shows data events for key X as they arrive in the
PCollection and are assigned to windows. To keep the diagram a bit simpler,
we&amp;rsquo;ll assume that the events all arrive in the pipeline in order.&lt;/p>
&lt;p>&lt;img src="/images/trigger-accumulation.png" alt="Diagram of data events for acculumating mode example">&lt;/p>
&lt;h5 id="accumulating-mode">9.4.1.1. Accumulating mode&lt;/h5>
&lt;p>If our trigger is set to accumulating mode, the trigger emits the following
values each time it fires. Keep in mind that the trigger fires every time three
elements arrive:&lt;/p>
&lt;pre>&lt;code> First trigger firing: [5, 8, 3]
Second trigger firing: [5, 8, 3, 15, 19, 23]
Third trigger firing: [5, 8, 3, 15, 19, 23, 9, 13, 10]
&lt;/code>&lt;/pre>&lt;h5 id="discarding-mode">9.4.1.2. Discarding mode&lt;/h5>
&lt;p>If our trigger is set to discarding mode, the trigger emits the following values
on each firing:&lt;/p>
&lt;pre>&lt;code> First trigger firing: [5, 8, 3]
Second trigger firing: [15, 19, 23]
Third trigger firing: [9, 13, 10]
&lt;/code>&lt;/pre>&lt;h4 id="handling-late-data">9.4.2. Handling late data&lt;/h4>
&lt;p>If you want your pipeline to process data that arrives after the watermark
passes the end of the window, you can apply an &lt;em>allowed lateness&lt;/em> when you set
your windowing configuration. This gives your trigger the opportunity to react
to the late data. If allowed lateness is set, the default trigger will emit new
results immediately whenever late data arrives.&lt;/p>
&lt;p>You set the allowed lateness by using &lt;code>.withAllowedLateness()&lt;/code> when you set your
windowing function:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">pc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Window&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">FixedWindows&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">TimeUnit&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">MINUTES&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">triggering&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AfterProcessingTime&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">pastFirstElementInPane&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">plusDelayOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">)))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withAllowedLateness&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">30&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">Initial&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">pc&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">FixedWindows&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">60&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">trigger&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">AfterProcessingTime&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">60&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">allowed_lateness&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1800&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 30 minutes&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="o">...&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>This allowed lateness propagates to all &lt;code>PCollection&lt;/code>s derived as a result of
applying transforms to the original &lt;code>PCollection&lt;/code>. If you want to change the
allowed lateness later in your pipeline, you can apply
&lt;code>Window.configure().withAllowedLateness()&lt;/code> again, explicitly.&lt;/p>
&lt;h3 id="composite-triggers">9.5. Composite triggers&lt;/h3>
&lt;p>You can combine multiple triggers to form &lt;strong>composite triggers&lt;/strong>, and can
specify a trigger to emit results repeatedly, at most once, or under other
custom conditions.&lt;/p>
&lt;h4 id="composite-trigger-types">9.5.1. Composite trigger types&lt;/h4>
&lt;p>Beam includes the following composite triggers:&lt;/p>
&lt;ul>
&lt;li>You can add additional early firings or late firings to
&lt;code>AfterWatermark.pastEndOfWindow&lt;/code> via &lt;code>.withEarlyFirings&lt;/code> and
&lt;code>.withLateFirings&lt;/code>.&lt;/li>
&lt;li>&lt;code>Repeatedly.forever&lt;/code> specifies a trigger that executes forever. Any time the
trigger&amp;rsquo;s conditions are met, it causes a window to emit results and then
resets and starts over. It can be useful to combine &lt;code>Repeatedly.forever&lt;/code>
with &lt;code>.orFinally&lt;/code> to specify a condition that causes the repeating trigger
to stop.&lt;/li>
&lt;li>&lt;code>AfterEach.inOrder&lt;/code> combines multiple triggers to fire in a specific
sequence. Each time a trigger in the sequence emits a window, the sequence
advances to the next trigger.&lt;/li>
&lt;li>&lt;code>AfterFirst&lt;/code> takes multiple triggers and emits the first time &lt;em>any&lt;/em> of its
argument triggers is satisfied. This is equivalent to a logical OR operation
for multiple triggers.&lt;/li>
&lt;li>&lt;code>AfterAll&lt;/code> takes multiple triggers and emits when &lt;em>all&lt;/em> of its argument
triggers are satisfied. This is equivalent to a logical AND operation for
multiple triggers.&lt;/li>
&lt;li>&lt;code>orFinally&lt;/code> can serve as a final condition to cause any trigger to fire one
final time and never fire again.&lt;/li>
&lt;/ul>
&lt;h4 id="composite-afterwatermark">9.5.2. Composition with AfterWatermark&lt;/h4>
&lt;p>Some of the most useful composite triggers fire a single time when Beam
estimates that all the data has arrived (i.e. when the watermark passes the end
of the window) combined with either, or both, of the following:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Speculative firings that precede the watermark passing the end of the window
to allow faster processing of partial results.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Late firings that happen after the watermark passes the end of the window,
to allow for handling late-arriving data&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>You can express this pattern using &lt;code>AfterWatermark&lt;/code>. For example, the following
example trigger code fires on the following conditions:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>On Beam&amp;rsquo;s estimate that all the data has arrived (the watermark passes the
end of the window)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Any time late data arrives, after a ten-minute delay&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p class="language-java">&lt;ul>
&lt;li>After two days, we assume no more data of interest will arrive, and the
trigger stops executing&lt;/li>
&lt;/ul>&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Window&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">configure&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">triggering&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AfterWatermark&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">pastEndOfWindow&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withLateFirings&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AfterProcessingTime&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">pastFirstElementInPane&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">plusDelayOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">10&lt;/span>&lt;span class="o">))))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withAllowedLateness&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardDays&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">2&lt;/span>&lt;span class="o">)));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">pcollection&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">FixedWindows&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">60&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">trigger&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">AfterWatermark&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">late&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">AfterProcessingTime&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">60&lt;/span>&lt;span class="p">)),&lt;/span>
&lt;span class="n">allowed_lateness&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">accumulation_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">AccumulationMode&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DISCARDING&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="other-composite-triggers">9.5.3. Other composite triggers&lt;/h4>
&lt;p>You can also build other sorts of composite triggers. The following example code
shows a simple composite trigger that fires whenever the pane has at least 100
elements, or after a minute.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">Repeatedly&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">forever&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AfterFirst&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">AfterPane&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">elementCountAtLeast&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">100&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">AfterProcessingTime&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">pastFirstElementInPane&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">plusDelayOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">))))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">pcollection&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">FixedWindows&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">60&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">trigger&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">Repeatedly&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">AfterAny&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">AfterCount&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">AfterProcessingTime&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">60&lt;/span>&lt;span class="p">))),&lt;/span>
&lt;span class="n">accumulation_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">AccumulationMode&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DISCARDING&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="metrics">10. Metrics&lt;/h2>
&lt;p>In the Beam model, metrics provide some insight into the current state of a user pipeline,
potentially while the pipeline is running. There could be different reasons for that, for instance:&lt;/p>
&lt;ul>
&lt;li>Check the number of errors encountered while running a specific step in the pipeline;&lt;/li>
&lt;li>Monitor the number of RPCs made to backend service;&lt;/li>
&lt;li>Retrieve an accurate count of the number of elements that have been processed;&lt;/li>
&lt;li>&amp;hellip;and so on.&lt;/li>
&lt;/ul>
&lt;h3 id="101-the-main-concepts-of-beam-metrics">10.1 The main concepts of Beam metrics&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Named&lt;/strong>. Each metric has a name which consists of a namespace and an actual name. The
namespace can be used to differentiate between multiple metrics with the same name and also
allows querying for all metrics within a specific namespace.&lt;/li>
&lt;li>&lt;strong>Scoped&lt;/strong>. Each metric is reported against a specific step in the pipeline, indicating what
code was running when the metric was incremented.&lt;/li>
&lt;li>&lt;strong>Dynamically Created&lt;/strong>. Metrics may be created during runtime without pre-declaring them, in
much the same way a logger could be created. This makes it easier to produce metrics in utility
code and have them usefully reported.&lt;/li>
&lt;li>&lt;strong>Degrade Gracefully&lt;/strong>. If a runner doesn’t support some part of reporting metrics, the
fallback behavior is to drop the metric updates rather than failing the pipeline. If a runner
doesn’t support some part of querying metrics, the runner will not return the associated data.&lt;/li>
&lt;/ul>
&lt;p>Reported metrics are implicitly scoped to the transform within the pipeline that reported them.
This allows reporting the same metric name in multiple places and identifying the value each
transform reported, as well as aggregating the metric across the entire pipeline.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> It is runner-dependent whether metrics are accessible during pipeline execution or only
after jobs have completed.&lt;/p>
&lt;/blockquote>
&lt;h3 id="types-of-metrics">10.2 Types of metrics&lt;/h3>
&lt;p>There are three types of metrics that are supported for the moment: &lt;code>Counter&lt;/code>, &lt;code>Distribution&lt;/code> and
&lt;code>Gauge&lt;/code>.&lt;/p>
&lt;p>&lt;strong>Counter&lt;/strong>: A metric that reports a single long value and can be incremented or decremented.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Counter&lt;/span> &lt;span class="n">counter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">counter&lt;/span>&lt;span class="o">(&lt;/span> &lt;span class="s">&amp;#34;namespace&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;counter1&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// count the elements
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">counter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">inc&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Distribution&lt;/strong>: A metric that reports information about the distribution of reported values.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Distribution&lt;/span> &lt;span class="n">distribution&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">distribution&lt;/span>&lt;span class="o">(&lt;/span> &lt;span class="s">&amp;#34;namespace&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;distribution1&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Integer&lt;/span> &lt;span class="n">element&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// create a distribution (histogram) of the values
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">distribution&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">update&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Gauge&lt;/strong>: A metric that reports the latest value out of reported values. Since metrics are
collected from many workers the value may not be the absolute last, but one of the latest values.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">Gauge&lt;/span> &lt;span class="n">gauge&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">gauge&lt;/span>&lt;span class="o">(&lt;/span> &lt;span class="s">&amp;#34;namespace&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;gauge1&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Integer&lt;/span> &lt;span class="n">element&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// create a gauge (latest value received) of the values
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">gauge&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="querying-metrics">10.3 Querying metrics&lt;/h3>
&lt;p>&lt;code>PipelineResult&lt;/code> has a method &lt;code>metrics()&lt;/code> which returns a &lt;code>MetricResults&lt;/code> object that allows
accessing metrics. The main method available in &lt;code>MetricResults&lt;/code> allows querying for all metrics
matching a given filter.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">interface&lt;/span> &lt;span class="nc">PipelineResult&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">MetricResults&lt;/span> &lt;span class="nf">metrics&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MetricResults&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="n">MetricQueryResults&lt;/span> &lt;span class="nf">queryMetrics&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Nullable&lt;/span> &lt;span class="n">MetricsFilter&lt;/span> &lt;span class="n">filter&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">interface&lt;/span> &lt;span class="nc">MetricQueryResults&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MetricResult&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="nf">getCounters&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MetricResult&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">DistributionResult&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="nf">getDistributions&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MetricResult&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">GaugeResult&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="nf">getGauges&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">interface&lt;/span> &lt;span class="nc">MetricResult&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">MetricName&lt;/span> &lt;span class="nf">getName&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="nf">getStep&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">T&lt;/span> &lt;span class="nf">getCommitted&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">T&lt;/span> &lt;span class="nf">getAttempted&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="using-metrics">10.4 Using metrics in pipeline&lt;/h3>
&lt;p>Below, there is a simple example of how to use a &lt;code>Counter&lt;/code> metric in a user pipeline.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// creating a pipeline with custom metrics DoFn
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(...)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">MyMetricsDoFn&lt;/span>&lt;span class="o">()));&lt;/span>
&lt;span class="n">pipelineResult&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">run&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">waitUntilFinish&lt;/span>&lt;span class="o">(...);&lt;/span>
&lt;span class="c1">// request the metric called &amp;#34;counter1&amp;#34; in namespace called &amp;#34;namespace&amp;#34;
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">MetricQueryResults&lt;/span> &lt;span class="n">metrics&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">pipelineResult&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">metrics&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">queryMetrics&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">MetricsFilter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">builder&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">addNameFilter&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MetricNameFilter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">named&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;namespace&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;counter1&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="c1">// print the metric value - there should be only one line because there is only one metric
&lt;/span>&lt;span class="c1">// called &amp;#34;counter1&amp;#34; in the namespace called &amp;#34;namespace&amp;#34;
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">MetricResult&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">counter&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getCounters&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">counter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getName&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;:&amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">counter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getAttempted&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MyMetricsDoFn&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">Counter&lt;/span> &lt;span class="n">counter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">counter&lt;/span>&lt;span class="o">(&lt;/span> &lt;span class="s">&amp;#34;namespace&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;counter1&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// count the elements
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">counter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">inc&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">context&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">context&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="export-metrics">10.5 Export metrics&lt;/h3>
&lt;p>Beam metrics can be exported to external sinks. If a metrics sink is set up in the configuration, the runner will push metrics to it at a default 5s period.
The configuration is held in the &lt;a href="https://beam.apache.org/releases/javadoc/2.19.0/org/apache/beam/sdk/metrics/MetricsOptions.html">MetricsOptions&lt;/a> class.
It contains push period configuration and also sink specific options such as type and URL. As for now only the REST HTTP and the Graphite sinks are supported and only
Flink and Spark runners support metrics export.&lt;/p>
&lt;p>Also Beam metrics are exported to inner Spark and Flink dashboards to be consulted in their respective UI.&lt;/p>
&lt;h2 id="state-and-timers">11. State and Timers&lt;/h2>
&lt;p>Beam&amp;rsquo;s windowing and triggering facilities provide a powerful abstraction for grouping and aggregating unbounded input
data based on timestamps. However there are aggregation use cases for which developers may require a higher degree of
control than provided by windows and triggers. Beam provides an API for manually managing per-key state, allowing for
fine-grained control over aggregations.&lt;/p>
&lt;p>Beam&amp;rsquo;s state API models state per key. To use the state API, you start out with a keyed &lt;code>PCollection&lt;/code>, which in Java
is modeled as a &lt;code>PCollection&amp;lt;KV&amp;lt;K, V&amp;gt;&amp;gt;&lt;/code>. A &lt;code>ParDo&lt;/code> processing this &lt;code>PCollection&lt;/code> can now declare state variables. Inside
the &lt;code>ParDo&lt;/code> these state variables can be used to write or update state for the current key or to read previous state
written for that key. State is always fully scoped only to the current processing key.&lt;/p>
&lt;p>Windowing can still be used together with stateful processing. All state for a key is scoped to the current window. This
means that the first time a key is seen for a given window any state reads will return empty, and that a runner can
garbage collect state when a window is completed. It&amp;rsquo;s also often useful to use Beam&amp;rsquo;s windowed aggregations prior to
the stateful operator. For example, using a combiner to preaggregate data, and then storing aggregated data inside of
state. Merging windows are not currently supported when using state and timers.&lt;/p>
&lt;p>Sometimes stateful processing is used to implement state-machine style processing inside a &lt;code>DoFn&lt;/code>. When doing this,
care must be taken to remember that the elements in input PCollection have no guaranteed order and to ensure that the
program logic is resilient to this. Unit tests written using the DirectRunner will shuffle the order of element
processing, and are recommended to test for correctness.&lt;/p>
&lt;p class="language-java">In Java DoFn declares states to be accessed by creating final &lt;code>StateSpec&lt;/code> member variables representing each state. Each
state must be named using the &lt;code>StateId&lt;/code> annotation; this name is unique to a ParDo in the graph and has no relation
to other nodes in the graph. A &lt;code>DoFn&lt;/code> can declare multiple state variables.&lt;/p>
&lt;p class="language-py">In Python DoFn declares states to be accessed by creating &lt;code>StateSpec&lt;/code> class member variables representing each state. Each
&lt;code>StateSpec&lt;/code> is initialized with a name, this name is unique to a ParDo in the graph and has no relation
to other nodes in the graph. A &lt;code>DoFn&lt;/code> can declare multiple state variables.&lt;/p>
&lt;h3 id="types-of-state">11.1 Types of state&lt;/h3>
&lt;p>Beam provides several types of state:&lt;/p>
&lt;h4 id="valuestate">ValueState&lt;/h4>
&lt;p>A ValueState is a scalar state value. For each key in the input, a ValueState will store a typed value that can be
read and modified inside the DoFn&amp;rsquo;s &lt;code>@ProcessElement&lt;/code> or &lt;code>@OnTimer&lt;/code> methods. If the type of the ValueState has a coder
registered, then Beam will automatically infer the coder for the state value. Otherwise, a coder can be explicitly
specified when creating the ValueState. For example, the following ParDo creates a single state variable that
accumulates the number of elements seen.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">numElements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Read the number element seen so far for this user key.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// state.read() returns null if it was never set. The below code allows us to have a default value of 0.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">currentValue&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">MoreObjects&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">firstNonNull&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Update the state.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">currentValue&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">1&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Beam also allows explicitly specifying a coder for &lt;code>ValueState&lt;/code> values. For example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MyType&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">numElements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">MyTypeCoder&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="combiningstate">CombiningState&lt;/h4>
&lt;p>&lt;code>CombiningState&lt;/code> allows you to create a state object that is updated using a Beam combiner. For example, the previous
&lt;code>ValueState&lt;/code> example could be rewritten to use &lt;code>CombiningState&lt;/code>&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">numElements&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">combining&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Sum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">ofIntegers&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-python>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">CombiningStateDoFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">SUM_TOTAL&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">CombiningValueStateSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;total&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">SoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">SUM_TOTAL&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Read per user&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">ReadPerUser&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Combine state pardo&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">CombiningStateDofn&lt;/span>&lt;span class="p">()))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="bagstate">BagState&lt;/h4>
&lt;p>A common use case for state is to accumulate multiple elements. &lt;code>BagState&lt;/code> allows for accumulating an unordered set
of elements. This allows for addition of elements to the collection without requiring the reading of the entire
collection first, which is an efficiency gain. In addition, runners that support paged reads can allow individual
bags larger than available memory.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">numElements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">bag&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@Element&lt;/span> &lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Add the current element to the bag for this key.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">shouldFetch&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Occasionally we fetch and process the values.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">values&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">processValues&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="c1">// Clear the state for this key.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-python>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">BagStateDoFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">ALL_ELEMENTS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">BagStateSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;buffer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">coders&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">VarIntCoder&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element_pair&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ALL_ELEMENTS&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element_pair&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">should_fetch&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="n">all_elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="n">process_values&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">all_elements&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">clear&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Read per user&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">ReadPerUser&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Bag state pardo&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">BagStateDoFn&lt;/span>&lt;span class="p">()))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="deferred-state-reads">11.2 Deferred state reads&lt;/h3>
&lt;p>When a &lt;code>DoFn&lt;/code> contains multiple state specifications, reading each one in order can be slow. Calling the &lt;code>read()&lt;/code> function
on a state can cause the runner to perform a blocking read. Performing multiple blocking reads in sequence adds latency
to element processing. If you know that a state will always be read, you can annotate it as @AlwaysFetched, and then the
runner can prefetch all of the states necessary. For example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state1&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">state1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state2&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">state2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state3&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">state3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">bag&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@AlwaysFetched&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state1&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state1&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@AlwaysFetched&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state2&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state2&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@AlwaysFetched&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state3&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state3&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">state1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">state2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">state3&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>If however there are code paths in which the states are not fetched, then annotating with @AlwaysFetched will add
unnecessary fetching for those paths. In this case, the readLater method allows the runner to know that the state will
be read in the future, allowing multiple state reads to be batched together.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state1&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">state1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state2&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">state2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state3&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">state3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">bag&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state1&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state1&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state2&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state2&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state3&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state3&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="cm">/* should read state */&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">state1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">readLater&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">state2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">readLater&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">state3&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">readLater&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// The runner can now batch all three states into a single read, reducing latency.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">processState1&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">state1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">processState2&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">state2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">processState3&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">state3&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="timers">11.3 Timers&lt;/h3>
&lt;p>Beam provides a per-key timer callback API. This allows for delayed processing of data stored using the state API.
Timers can be set to callback at either an event-time or a processing-time timestamp. Every timer is identified with a
TimerId. A given timer for a key can only be set for a single timestamp. Calling set on a timer overwrites the previous
firing time for that key&amp;rsquo;s timer.&lt;/p>
&lt;h4 id="event-time-timers">11.3.1 Event-time timers&lt;/h4>
&lt;p>Event-time timers fire when the input watermark for the DoFn passes the time at which the timer is set, meaning that
the runner believes that there are no more elements to be processed with timestamps before the timer timestamp. This
allows for event-time aggregations.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TimerSpec&lt;/span> &lt;span class="n">timer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">EVENT_TIME&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@Element&lt;/span> &lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@Timestamp&lt;/span> &lt;span class="n">Instant&lt;/span> &lt;span class="n">elementTs&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">Timer&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="c1">// Set an event-time timer to the element timestamp.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">elementTs&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@OnTimer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">onTimer&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">//Process timer.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-python>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">EventTimerDoFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">ALL_ELEMENTS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">BagStateSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;buffer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">coders&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">VarIntCoder&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="n">TIMER&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;timer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WATERMARK&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">element_pair&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">t&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimestampParam&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nb">buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ALL_ELEMENTS&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">timer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimerParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">TIMER&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="nb">buffer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element_pair&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="c1"># Set an event-time timer to the element timestamp.&lt;/span>
&lt;span class="n">timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">t&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nd">@on_timer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">TIMER&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">expiry_callback&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ALL_ELEMENTS&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">clear&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Read per user&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">ReadPerUser&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;EventTime timer pardo&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">EventTimerDoFn&lt;/span>&lt;span class="p">()))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="processing-time-timers">11.3.2 Processing-time timers&lt;/h4>
&lt;p>Processing-time timers fire when the real wall-clock time passes. This is often used to create larger batches of data
before processing. It can also be used to schedule events that should occur at a specific time. Just like with
event-time timers, processing-time timers are per key - each key has a separate copy of the timer.&lt;/p>
&lt;p>While processing-time timers can be set to an absolute timestamp, it is very common to set them to an offset relative
to the current time. In Java, the &lt;code>Timer.offset&lt;/code> and &lt;code>Timer.setRelative&lt;/code> methods can be used to accomplish this.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TimerSpec&lt;/span> &lt;span class="n">timer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">PROCESSING_TIME&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">Timer&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="c1">// Set a timer to go off 30 seconds in the future.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">offset&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardSeconds&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">30&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">setRelative&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@OnTimer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">onTimer&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">//Process timer.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-python>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">ProcessingTimerDoFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">ALL_ELEMENTS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">BagStateSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;buffer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">coders&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">VarIntCoder&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="n">TIMER&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;timer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">REAL_TIME&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">element_pair&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nb">buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ALL_ELEMENTS&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">timer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimerParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">TIMER&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="nb">buffer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">element_pair&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="c1"># Set a timer to go off 30 seconds in the future.&lt;/span>
&lt;span class="n">timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Timestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">now&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">Duration&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">seconds&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">30&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="nd">@on_timer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">TIMER&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">expiry_callback&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ALL_ELEMENTS&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="c1"># Process timer.&lt;/span>
&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">clear&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Read per user&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">ReadPerUser&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;ProcessingTime timer pardo&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ProcessingTimerDoFn&lt;/span>&lt;span class="p">()))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="dynamic-timer-tags">11.3.3 Dynamic timer tags&lt;/h4>
&lt;p>Beam also supports dynamically setting a timer tag using &lt;code>TimerMap&lt;/code>. This allows for setting multiple different timers
in a &lt;code>DoFn&lt;/code> and allowing for the timer tags to be dynamically chosen - e.g. based on data in the input elements. A
timer with a specific tag can only be set to a single timestamp, so setting the timer again has the effect of
overwriting the previous expiration time for the timer with that tag. Each &lt;code>TimerMap&lt;/code> is identified with a timer family
id, and timers in different timer families are independent.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@TimerFamily&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;actionTimers&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TimerSpec&lt;/span> &lt;span class="n">timer&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">TimerSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timerMap&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">EVENT_TIME&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@Element&lt;/span> &lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@Timestamp&lt;/span> &lt;span class="n">Instant&lt;/span> &lt;span class="n">elementTs&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@TimerFamily&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;actionTimers&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">TimerMap&lt;/span> &lt;span class="n">timers&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">timers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getActionType&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">elementTs&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@OnTimerFamily&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;actionTimers&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">onTimer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@TimerId&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">timerId&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">LOG&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">info&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Timer fired with id &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">timerId&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-python>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="n">To&lt;/span> &lt;span class="n">be&lt;/span> &lt;span class="n">supported&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">See&lt;/span> &lt;span class="n">BEAM&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">9602&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="timer-output-timestamps">11.3.4 Timer output timestamps&lt;/h4>
&lt;p>By default, event-time timers will hold the output watermark of the &lt;code>ParDo&lt;/code> to the timestamp of the timer. This means
that if a timer is set to 12pm, any windowed aggregations or event-time timers later in the pipeline graph that finish
after 12pm will not expire. The timestamp of the timer is also the default output timestamp for the timer callback. This
means that any elements output from the onTimer method will have a timestamp equal to the timestamp of the timer firing.
For processing-time timers, the default output timestamp and watermark hold is the value of the input watermark at the
time the timer was set.&lt;/p>
&lt;p>In some cases, a DoFn needs to output timestamps earlier than the timer expiration time, and therefore also needs to
hold its output watermark to those timestamps. For example, consider the following pipeline that temporarily batches
records into state, and sets a timer to drain the state. This code may appear correct, but will not work properly.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;elementBag&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">elementBag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">bag&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timerSet&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Boolean&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">timerSet&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;outputState&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TimerSpec&lt;/span> &lt;span class="n">timer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">PROCESSING_TIME&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@Element&lt;/span> &lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;elementBag&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">elementBag&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timerSet&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Boolean&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">timerSet&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;outputState&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">Timer&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Add the current element to the bag for this key.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">elementBag&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(!&lt;/span>&lt;span class="n">MoreObjects&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">firstNonNull&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">timerSet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// If the timer is not current set, then set it to go off in a minute.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">offset&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">setRelative&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">timerSet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@OnTimer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;outputState&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">onTimer&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;elementBag&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">elementBag&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timerSet&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Boolean&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">timerSet&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">OutputReceiver&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">ValueT&lt;/span> &lt;span class="n">bufferedElement&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">elementBag&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Output each element.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">outputWithTimestamp&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">bufferedElement&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">bufferedElement&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timestamp&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">elementBag&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// Note that the timer has now fired.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">timerSet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The problem with this code is that the ParDo is buffering elements, however nothing is preventing the watermark
from advancing past the timestamp of those elements, so all those elements might be dropped as late data. In order
to prevent this from happening, an output timestamp needs to be set on the timer to prevent the watermark from advancing
past the timestamp of the minimum element. The following code demonstrates this.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// The bag of elements accumulated.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;elementBag&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">elementBag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">bag&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// The timestamp of the timer set.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timerTimestamp&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">timerTimestamp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// The minimum timestamp stored in the bag.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;minTimestampInBag&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">minTimestampInBag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">combining&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Min&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">ofLongs&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;outputState&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TimerSpec&lt;/span> &lt;span class="n">timer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">PROCESSING_TIME&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@Element&lt;/span> &lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;elementBag&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">elementBag&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@AlwaysFetched&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timerTimestamp&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">timerTimestamp&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@AlwaysFetched&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;minTimestampInBag&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">minTimestamp&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;outputState&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">Timer&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Add the current element to the bag for this key.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">elementBag&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="c1">// Keep track of the minimum element timestamp currently stored in the bag.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">minTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">timestamp&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="c1">// If the timer is already set, then reset it at the same time but with an updated output timestamp (otherwise
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// we would keep resetting the timer to the future). If there is no timer set, then set one to expire in a minute.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Long&lt;/span> &lt;span class="n">timerTimestampMs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">timerTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">Instant&lt;/span> &lt;span class="n">timerToSet&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">timerTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">isEmpty&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">?&lt;/span> &lt;span class="n">Instant&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">now&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">plus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Instant&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">timerTimestampMs&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Setting the outputTimestamp to the minimum timestamp in the bag holds the watermark to that timestamp until the
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// timer fires. This allows outputting all the elements with their timestamp.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withOutputTimestamp&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">minTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">timerToSet&lt;/span>&lt;span class="o">).&lt;/span>
&lt;span class="n">timerTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">timerToSet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMillis&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@OnTimer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;outputState&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">onTimer&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;elementBag&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">elementBag&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timerTimestamp&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">timerTimestamp&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">OutputReceiver&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">ValueT&lt;/span> &lt;span class="n">bufferedElement&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">elementBag&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Output each element.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">outputWithTimestamp&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">bufferedElement&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">bufferedElement&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timestamp&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// Note that the timer has now fired.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">timerTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="garbage-collecting-state">11.4 Garbage collecting state&lt;/h3>
&lt;p>Per-key state needs to be garbage collected, or eventually the increasing size of state may negatively impact
performance. There are two common strategies for garbage collecting state.&lt;/p>
&lt;h5 id="using-windows-for-garbage-collection">11.4.1 &lt;strong>Using windows for garbage collection&lt;/strong>&lt;/h5>
&lt;p>All state and timers for a key is scoped to the window it is in. This means that depending on the timestamp of the
input element the ParDo will see different values for the state depending on the window that element falls into. In
addition, once the input watermark passes the end of the window, the runner should garbage collect all state for that
window. (note: if allowed lateness is set to a positive value for the window, the runner must wait for the watermark to
pass the end of the window plus the allowed lateness before garbage collecting state). This can be used as a
garbage-collection strategy.&lt;/p>
&lt;p>For example, given the following:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Window&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CalendarWindows&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">days&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withTimeZone&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">DateTimeZone&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">forID&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;America/Los_Angeles&amp;#34;&lt;/span>&lt;span class="o">))));&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Timestamp&lt;/span> &lt;span class="n">Instant&lt;/span> &lt;span class="n">ts&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// The state is scoped to a calendar day window. That means that if the input timestamp ts is after
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// midnight PST, then a new copy of the state will be seen for the next day.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-python>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">StateDoFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">ALL_ELEMENTS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">BagStateSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;buffer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">coders&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">VarIntCoder&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">element_pair&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nb">buffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ALL_ELEMENTS&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Read per user&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">ReadPerUser&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Windowing&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WindowInto&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">FixedWindows&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">60&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">60&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;DoFn&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">StateDoFn&lt;/span>&lt;span class="p">()))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>This &lt;code>ParDo&lt;/code> stores state per day. Once the pipeline is done processing data for a given day, all the state for that
day is garbage collected.&lt;/p>
&lt;h5 id="using-timers-for-garbage-collection">11.4.1 &lt;strong>Using timers For garbage collection&lt;/strong>&lt;/h5>
&lt;p>In some cases, it is difficult to find a windowing strategy that models the desired garbage-collection strategy. For
example, a common desire is to garbage collect state for a key once no activity has been seen on the key for some time.
This can be done by updating a timer that garbage collects state. For example&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// The state for the key.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// The maximum element timestamp seen so far.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTimestampSeen&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">maxTimestamp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">combining&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Max&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">ofLongs&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gcTimer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TimerSpec&lt;/span> &lt;span class="n">gcTimer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">EVENT_TIME&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@Element&lt;/span> &lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@Timestamp&lt;/span> &lt;span class="n">Instant&lt;/span> &lt;span class="n">ts&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTimestampSeen&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">maxTimestamp&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gcTimer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">gcTimer&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">updateState&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">state&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">maxTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMillis&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="c1">// Set the timer to be one hour after the maximum timestamp seen. This will keep overwriting the same timer, so
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// as long as there is activity on this key the state will stay active. Once the key goes inactive for one hour&amp;#39;s
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// worth of event time (as measured by the watermark), then the gc timer will fire.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Instant&lt;/span> &lt;span class="n">expirationTime&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Instant&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">maxTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">plus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardHours&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">expirationTime&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@OnTimer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gcTimer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">onTimer&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTimestampSeen&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">maxTimestamp&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Clear all state for the key.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">maxTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-python>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">UserDoFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DoFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">ALL_ELEMENTS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">BagStateSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;state&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">coders&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">VarIntCoder&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="n">MAX_TIMESTAMP&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">CombiningValueStateSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;max_timestamp_seen&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">max&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">TIMER&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpec&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;gc-timer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WATERMARK&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">element&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">t&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimestampParam&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">state&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ALL_ELEMENTS&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">max_timestamp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">MAX_TIMESTAMP&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">timer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TimerParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">TIMER&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="n">update_state&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">state&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">max_timestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">t&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">micros&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Set the timer to be one hour after the maximum timestamp seen. This will keep overwriting the same timer, so&lt;/span>
&lt;span class="c1"># as long as there is activity on this key the state will stay active. Once the key goes inactive for one hour&amp;#39;s&lt;/span>
&lt;span class="c1"># worth of event time (as measured by the watermark), then the gc timer will fire.&lt;/span>
&lt;span class="n">expiration_time&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Timestamp&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">micros&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">max_timestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">Duration&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">seconds&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">60&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="mi">60&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">expiration_time&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nd">@on_timer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">TIMER&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">expiry_callback&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">state&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ALL_ELEMENTS&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">max_timestamp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StateParam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">MAX_TIMESTAMP&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">clear&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">max_timestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">clear&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Read per user&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">ReadPerUser&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;User DoFn&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">UserDoFn&lt;/span>&lt;span class="p">()))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="state-timers-examples">11.5 State and timers examples&lt;/h3>
&lt;p>Following are some example uses of state and timers&lt;/p>
&lt;h4 id="joining-clicks-and-views">11.5.1. Joining clicks and views&lt;/h4>
&lt;p>In this example, the pipeline is processing data from an e-commerce site&amp;rsquo;s home page. There are two input streams:
a stream of views, representing suggested product links displayed to the user on the home page, and a stream of
clicks, representing actual user clicks on these links. The goal of the pipeline is to join click events with view
events, outputting a new joined event that contains information from both events. Each link has a unique identifier
that is present in both the view event and the join event.&lt;/p>
&lt;p>Many view events will never be followed up with clicks. This pipeline will wait one hour for a click, after which it
will give up on this join. While every click event should have a view event, some small number of view events may be
lost and never make it to the Beam pipeline; the pipeline will similarly wait one hour after seeing a click event, and
give up if the view event does not arrive in that time. Input events are not ordered - it is possible to see the click
event before the view event. The one hour join timeout should be based on event time, not on processing time.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Read the event stream and key it by the link id.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">eventsPerLinkId&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">readEvents&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">WithKeys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">getLinkId&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">withKeyType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">strings&lt;/span>&lt;span class="o">()));&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">JoinedEvent&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Store the view event.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;view&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">viewState&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// Store the click event.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;click&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">clickState&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// The maximum element timestamp seen so far.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTimestampSeen&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">maxTimestamp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">combining&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Max&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">ofLongs&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="c1">// Timer that fires when an hour goes by with an incomplete join.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gcTimer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TimerSpec&lt;/span> &lt;span class="n">gcTimer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">EVENT_TIME&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@Element&lt;/span> &lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@Timestamp&lt;/span> &lt;span class="n">Instant&lt;/span> &lt;span class="n">ts&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@AlwaysFetched&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;view&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">viewState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@AlwaysFetched&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;click&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">clickState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@AlwaysFetched&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTimestampSeen&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">maxTimestampState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gcTimer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">gcTimer&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">OutputReceiver&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">JoinedEvent&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Store the event into the correct state variable.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Event&lt;/span> &lt;span class="n">event&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">valueState&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">event&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getType&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">equals&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">VIEW&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">?&lt;/span> &lt;span class="n">viewState&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">clickState&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="n">valueState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">event&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">Event&lt;/span> &lt;span class="n">view&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">viewState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">Event&lt;/span> &lt;span class="n">click&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">clickState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="k">if&lt;/span> &lt;span class="n">view&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">click&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// We&amp;#39;ve seen both a view and a click. Output a joined event and clear state.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JoinedEvent&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">click&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">clearState&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">viewState&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">clickState&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">maxTimestampState&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// We&amp;#39;ve only seen on half of the join.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// Set the timer to be one hour after the maximum timestamp seen. This will keep overwriting the same timer, so
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// as long as there is activity on this key the state will stay active. Once the key goes inactive for one hour&amp;#39;s
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// worth of event time (as measured by the watermark), then the gc timer will fire.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">maxTimestampState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ts&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMillis&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">Instant&lt;/span> &lt;span class="n">expirationTime&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Instant&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">maxTimestampState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">plus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardHours&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">gcTimer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">expirationTime&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@OnTimer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gcTimer&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">onTimer&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;view&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">viewState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;click&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">clickState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTimestampSeen&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">maxTimestampState&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// An hour has gone by with an incomplete join. Give up and clear the state.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">clearState&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">viewState&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">clickState&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">maxTimestampState&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">clearState&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;view&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">viewState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;click&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Event&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">clickState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTimestampSeen&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">CombiningState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">long&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">maxTimestampState&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">viewState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">clickState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">maxTimestampState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="batching-rpcs">11.5.2 Batching RPCs&lt;/h4>
&lt;p>In this example, input elements are being forwarded to an external RPC service. The RPC accepts batch requests -
multiple events for the same user can be batched in a single RPC call. Since this RPC service also imposes rate limits,
we want to batch ten seconds worth of events together in order to reduce the number of calls.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">perUser&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">readPerUser&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">perUser&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">OutputT&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Store the elements buffered so far.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">bag&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// Keep track of whether a timer is currently set or not.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;isTimerSet&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">StateSpec&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Boolean&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">isTimerSet&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">StateSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">value&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// The processing-time timer user to publish the RPC.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;outputState&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TimerSpec&lt;/span> &lt;span class="n">timer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TimerSpecs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TimeDomain&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">PROCESSING_TIME&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@Element&lt;/span> &lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">element&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">elementsState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;isTimerSet&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Boolean&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">isTimerSetState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@TimerId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;outputState&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">Timer&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Add the current element to the bag for this key.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">state&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">element&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(!&lt;/span>&lt;span class="n">MoreObjects&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">firstNonNull&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">isTimerSetState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// If there is no timer currently set, then set one to go off in 10 seconds.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">timer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">offset&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardSeconds&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">10&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">setRelative&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">isTimerSetState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@OnTimer&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;outputState&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">onTimer&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;state&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">BagState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ValueT&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">elementsState&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="nd">@StateId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;isTimerSet&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">ValueState&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Boolean&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">isTimerSetState&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Send an RPC containing the batched elements and clear state.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">sendRPC&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">elementsState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">elementsState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">isTimerSetState&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div></description></item><item><title>Documentation: BigQuery patterns</title><link>/documentation/patterns/bigqueryio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/patterns/bigqueryio/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="google-bigquery-patterns">Google BigQuery patterns&lt;/h1>
&lt;p>The samples on this page show you common patterns for use with BigQueryIO.&lt;/p>
&lt;nav class="language-switcher">
&lt;strong>Adapt for:&lt;/strong>
&lt;ul>
&lt;li data-type="language-java" class="active">Java SDK&lt;/li>
&lt;li data-type="language-py">Python SDK&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;h2 id="bigqueryio-deadletter-pattern">BigQueryIO deadletter pattern&lt;/h2>
&lt;p>In production systems, it is useful to implement the deadletter pattern with BigQueryIO outputting any elements which had errors during processing by BigQueryIO into another PCollection for further processing.
The samples below print the errors, but in a production system they can be sent to a deadletter table for later correction.&lt;/p>
&lt;p class="language-java">When using &lt;code>STREAMING_INSERTS&lt;/code> you can use the &lt;code>WriteResult&lt;/code> object to access a &lt;code>PCollection&lt;/code> with the &lt;code>TableRows&lt;/code> that failed to be inserted into BigQuery.
If you also set the &lt;code>withExtendedErrorInfo&lt;/code> property , you will be able to access a &lt;code>PCollection&amp;lt;BigQueryInsertError&amp;gt;&lt;/code> from the &lt;code>WriteResult&lt;/code>. The &lt;code>PCollection&lt;/code> will then include a reference to the table, the data row and the &lt;code>InsertErrors&lt;/code>. Which errors are added to the deadletter queue is determined via the &lt;code>InsertRetryPolicy&lt;/code>.&lt;/p>
&lt;p class="language-py">In the result tuple you can access &lt;code>FailedRows&lt;/code> to access the failed inserts.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PipelineOptions&lt;/span> &lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">PipelineOptionsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">fromArgs&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">withValidation&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">as&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">BigQueryOptions&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">Pipeline&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Create a bug by writing the 2nd value as null. The API will correctly
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// throw an error when trying to insert a null value into a REQUIRED field.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">WriteResult&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">2&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withSchema&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setFields&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">ImmutableList&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;num&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;INTEGER&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setMode&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;REQUIRED&amp;#34;&lt;/span>&lt;span class="o">))))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Test.dummyTable&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withFormatFunction&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TableRow&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;num&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">2&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">?&lt;/span> &lt;span class="kc">null&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withFailedInsertRetryPolicy&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">InsertRetryPolicy&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">retryTransientErrors&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="c1">// Forcing the bounded pipeline to use streaming inserts
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withMethod&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Write&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Method&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">STREAMING_INSERTS&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="c1">// set the withExtendedErrorInfo property.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withExtendedErrorInfo&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withCreateDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Write&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CreateDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CREATE_IF_NEEDED&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withWriteDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Write&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">WriteDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">WRITE_APPEND&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">result&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">getFailedInsertsWithErr&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">strings&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34; The table was &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getTable&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34; The row was &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getRow&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34; The error was &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getError&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="s">&amp;#34;&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}));&lt;/span>
&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">run&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="cm">/* Sample Output From the pipeline:
&lt;/span>&lt;span class="cm"> &amp;lt;p&amp;gt;The table was GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=Test,projectId=&amp;lt;&amp;gt;, tableId=dummyTable}}
&lt;/span>&lt;span class="cm"> &amp;lt;p&amp;gt;The row was GenericData{classInfo=[f], {num=null}}
&lt;/span>&lt;span class="cm"> &amp;lt;p&amp;gt;The error was GenericData{classInfo=[errors, index],{errors=[GenericData{classInfo=[debugInfo, location, message, reason], {debugInfo=,location=, message=Missing required field: Msg_0_CLOUD_QUERY_TABLE.num., reason=invalid}}],index=0}}
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py"> &lt;span class="c1"># Create pipeline.&lt;/span>
&lt;span class="n">schema&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">({&lt;/span>&lt;span class="s1">&amp;#39;fields&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[{&lt;/span>&lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;a&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;type&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;STRING&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;mode&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;REQUIRED&amp;#39;&lt;/span>&lt;span class="p">}]})&lt;/span>
&lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">errors&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Data&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;CreateBrokenData&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">src&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;a&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">src&lt;/span>&lt;span class="p">}&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">src&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;a&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="bp">None&lt;/span>&lt;span class="p">})&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;WriteToBigQuery&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WriteToBigQuery&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="s2">&amp;#34;&amp;lt;Your Project:Test.dummy_a_table&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">schema&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">schema&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">insert_retry_strategy&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;RETRY_ON_TRANSIENT_ERROR&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">create_disposition&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;CREATE_IF_NEEDED&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">write_disposition&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;WRITE_APPEND&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">errors&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;FailedRows&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;PrintErrors&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">err&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="k">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Error Found {}&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">format&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">err&lt;/span>&lt;span class="p">))))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div></description></item><item><title>Documentation: Built-in I/O Transforms</title><link>/documentation/io/built-in/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/io/built-in/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="built-in-io-transforms">Built-in I/O Transforms&lt;/h1>
&lt;p>This table contains the currently available I/O transforms.&lt;/p>
&lt;p>Consult the &lt;a href="/documentation/programming-guide#pipeline-io">Programming Guide I/O section&lt;/a> for general usage instructions.&lt;/p>
&lt;nav class="language-switcher">
&lt;strong>Adapt for:&lt;/strong>
&lt;ul>
&lt;li data-type="language-java" class="active">Java SDK&lt;/li>
&lt;li data-type="language-py">Python SDK&lt;/li>
&lt;li data-type="language-go">Go SDK&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;h3>File-based&lt;/h3>
&lt;p>These I/O connectors involve working with files.&lt;/p>
&lt;table class="table table-bordered">
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>
&lt;span class="language-java">Javadoc&lt;/span>
&lt;span class="language-py">pydoc&lt;/span>
&lt;span class="language-go">Godoc&lt;/span>
&lt;/th>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
FileIO
&lt;/td>
&lt;td>General-purpose transforms for working with files: listing files (matching), reading and writing.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/FileIO.html">org.apache.beam.sdk.io.FileIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
FileIO
&lt;/td>
&lt;td>General-purpose transforms for working with files: listing files (matching), reading and writing.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.fileio.html">apache_beam.io.FileIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
AvroIO
&lt;/td>
&lt;td>PTransforms for reading from and writing to &lt;a href="https://avro.apache.org/">Avro&lt;/a> files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/AvroIO.html">org.apache.beam.sdk.io.AvroIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
AvroIO
&lt;/td>
&lt;td>PTransforms for reading from and writing to &lt;a href="https://avro.apache.org/">Avro&lt;/a> files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.avroio.html">apache_beam.io.avroio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-go">
&lt;td>
AvroIO
&lt;/td>
&lt;td>PTransforms for reading from and writing to &lt;a href="https://avro.apache.org/">Avro&lt;/a> files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam/io/avroio">github.com/apache/beam/sdks/go/pkg/beam/io/avroio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
TextIO
&lt;/td>
&lt;td>PTransforms for reading and writing text files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/TextIO.html">org.apache.beam.sdk.io.TextIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
TextIO
&lt;/td>
&lt;td>PTransforms for reading and writing text files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.textio.html">apache_beam.io.textio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-go">
&lt;td>
TextIO
&lt;/td>
&lt;td>PTransforms for reading and writing text files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam/io/textio">github.com/apache/beam/sdks/go/pkg/beam/io/textio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
TFRecordIO
&lt;/td>
&lt;td>PTransforms for reading and writing &lt;a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">TensorFlow TFRecord&lt;/a> files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/TFRecordIO.html">org.apache.beam.sdk.io.TFRecordIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
TFRecordIO
&lt;/td>
&lt;td>PTransforms for reading and writing &lt;a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">TensorFlow TFRecord&lt;/a> files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.tfrecordio.html">apache_beam.io.tfrecordio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
XmlIO
&lt;/td>
&lt;td>Transforms for reading and writing XML files using &lt;a href="https://www.oracle.com/technical-resources/articles/javase/jaxb.html">JAXB&lt;/a> mappers.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/xml/XmlIO.html">org.apache.beam.sdk.io.xml.XmlIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
TikaIO
&lt;/td>
&lt;td>Transforms for parsing arbitrary files using &lt;a href="https://tika.apache.org/">Apache Tika&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/tika/TikaIO.html">org.apache.beam.sdk.io.tika.TikaIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
ParquetIO
&lt;a href="/documentation/io/built-in/parquet/"> (guide)&lt;/a>
&lt;/td>
&lt;td>IO for reading from and writing to &lt;a href="https://parquet.apache.org/">Parquet&lt;/a> files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/parquet/ParquetIO.html">org.apache.beam.sdk.io.parquet.ParquetIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
ParquetIO
&lt;a href="/documentation/io/built-in/parquet/"> (guide)&lt;/a>
&lt;/td>
&lt;td>IO for reading from and writing to &lt;a href="https://parquet.apache.org/">Parquet&lt;/a> files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.parquetio.html">apache_beam.io.parquetio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
ThriftIO
&lt;/td>
&lt;td>PTransforms for reading and writing files containing &lt;a href="https://thrift.apache.org/">Thrift&lt;/a>-encoded data.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/thrift/ThriftIO.html">org.apache.beam.sdk.io.thrift.ThriftIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
VcfIO
&lt;/td>
&lt;td>A source for reading from &lt;a href="https://samtools.github.io/hts-specs/VCFv4.2.pdf">VCF files&lt;/a> (version 4.x).&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.vcfio.html">apache_beam.io.vcfio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
S3IO
&lt;/td>
&lt;td>A source for reading from and writing to &lt;a href="https://aws.amazon.com/s3/">Amazon S3&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.aws.s3io.html">apache_beam.io.aws.s3io&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
GcsIO
&lt;/td>
&lt;td>A source for reading from and writing to &lt;a href="https://cloud.google.com/storage">Google Cloud Storage&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.gcp.gcsio.html">apache_beam.io.gcp.gcsio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;h3>FileSystem&lt;/h3>
&lt;p>Beam provides a File system interface that defines APIs for writing file systems agnostic code. Several I/O connectors are implemented as a FileSystem implementation.&lt;/p>
&lt;table class="table table-bordered">
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>
&lt;span class="language-java">Javadoc&lt;/span>
&lt;span class="language-py">pydoc&lt;/span>
&lt;span class="language-go">Godoc&lt;/span>
&lt;/th>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
HadoopFileSystem
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation for accessing &lt;a href="https://hadoop.apache.org/">Hadoop&lt;/a> Distributed File System files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/hdfs/HadoopFileSystemRegistrar.html">org.apache.beam.sdk.io.hdfs.HadoopFileSystemRegistrar&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
HadoopFileSystem
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation for accessing &lt;a href="https://hadoop.apache.org/">Hadoop&lt;/a> Distributed File System files.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.hadoopfilesystem.html">apache_beam.io.hadoopfilesystem&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
GcsFileSystem
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation for &lt;a href="https://cloud.google.com/storage">Google Cloud Storage&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/extensions/gcp/storage/GcsFileSystemRegistrar.html">org.apache.beam.sdk.extensions.gcp.storage.GcsFileSystemRegistrar&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
GcsFileSystem
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation for &lt;a href="https://cloud.google.com/storage">Google Cloud Storage&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.gcp.gcsfilesystem.html">apache_beam.io.gcp.gcsfilesystem&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-go">
&lt;td>
GcsFileSystem
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation for &lt;a href="https://cloud.google.com/storage">Google Cloud Storage&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam/io/filesystem/gcs">github.com/apache/beam/sdks/go/pkg/beam/io/filesystem/gcs&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
LocalFileSystem
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation for accessing files on disk.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/LocalFileSystemRegistrar.html">org.apache.beam.sdk.io.LocalFileSystemRegistrar&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
LocalFileSystem
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation for accessing files on disk.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.localfilesystem.html">apache_beam.io.localfilesystem&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-go">
&lt;td>
LocalFileSystem
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation for accessing files on disk.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam/io/filesystem/local">github.com/apache/beam/sdks/go/pkg/beam/io/filesystem/local&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
S3FileSystem
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation for &lt;a href="https://aws.amazon.com/s3/">Amazon S3&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/aws/s3/S3FileSystemRegistrar.html">org.apache.beam.sdk.io.aws.s3.S3FileSystemRegistrar&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-go">
&lt;td>
In-memory
&lt;/td>
&lt;td>&lt;code>FileSystem&lt;/code> implementation in memory; useful for testing.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam/io/filesystem/memfs">github.com/apache/beam/sdks/go/pkg/beam/io/filesystem/memfs&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;h3>Messaging&lt;/h3>
&lt;p>These I/O connectors typically involve working with unbounded sources that come from messaging sources.&lt;/p>
&lt;table class="table table-bordered">
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>
&lt;span class="language-java">Javadoc&lt;/span>
&lt;span class="language-py">pydoc&lt;/span>
&lt;span class="language-go">Godoc&lt;/span>
&lt;/th>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
KinesisIO
&lt;/td>
&lt;td>PTransforms for reading from and writing to &lt;a href="https://aws.amazon.com/kinesis/">Kinesis&lt;/a> streams.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/kinesis/KinesisIO.html">org.apache.beam.sdk.io.kinesis.KinesisIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
AmqpIO
&lt;/td>
&lt;td>AMQP 1.0 protocol using the Apache QPid Proton-J library&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/amqp/AmqpIO.html">org.apache.beam.sdk.io.amqp.AmqpIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
KafkaIO
&lt;/td>
&lt;td>Read and Write PTransforms for &lt;a href="https://kafka.apache.org/">Apache Kafka&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/kafka/KafkaIO.html">org.apache.beam.sdk.io.kafka.KafkaIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
KafkaIO
&lt;/td>
&lt;td>Read and Write PTransforms for &lt;a href="https://kafka.apache.org/">Apache Kafka&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.external.kafka.html">apache_beam.io.external.kafka&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
PubSubIO
&lt;/td>
&lt;td>Read and Write PTransforms for &lt;a href="https://cloud.google.com/pubsub">Google Cloud Pub/Sub&lt;/a> streams.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/gcp/pubsub/PubsubIO.html">org.apache.beam.sdk.io.gcp.pubsub.PubsubIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
PubSubIO
&lt;/td>
&lt;td>Read and Write PTransforms for &lt;a href="https://cloud.google.com/pubsub">Google Cloud Pub/Sub&lt;/a> streams.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.gcp.pubsub.html">apache_beam.io.gcp.pubsub&lt;/a>&lt;/div>
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.external.gcp.pubsub.html">apache_beam.io.external.gcp.pubsub&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-go">
&lt;td>
PubSubIO
&lt;/td>
&lt;td>Read and Write PTransforms for &lt;a href="https://cloud.google.com/pubsub">Google Cloud Pub/Sub&lt;/a> streams.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam/io/pubsubio">github.com/apache/beam/sdks/go/pkg/beam/io/pubsubio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
JmsIO
&lt;/td>
&lt;td>An unbounded source for &lt;a href="https://www.oracle.com/java/technologies/java-message-service.html">JMS&lt;/a> destinations (queues or topics).&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/jms/JmsIO.html">org.apache.beam.sdk.io.jms.JmsIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
MqttIO
&lt;/td>
&lt;td>An unbounded source for &lt;a href="https://mqtt.org/">MQTT&lt;/a> broker.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/mqtt/MqttIO.html">org.apache.beam.sdk.io.mqtt.MqttIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
RabbitMqIO
&lt;/td>
&lt;td>A IO to publish or consume messages with a RabbitMQ broker.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/rabbitmq/RabbitMqIO.html">org.apache.beam.sdk.io.rabbitmq.RabbitMqIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
SqsIO
&lt;/td>
&lt;td>An unbounded source for &lt;a href="https://aws.amazon.com/sqs/">Amazon Simple Queue Service (SQS)&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/aws/sqs/SqsIO.html">org.apache.beam.sdk.io.aws.sqs.SqsIO&lt;/a>&lt;/div>
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/aws2/sqs/SqsIO.html">org.apache.beam.sdk.io.aws2.sqs.SqsIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
SnsIO
&lt;/td>
&lt;td>PTransforms for writing to &lt;a href="https://aws.amazon.com/sns/">Amazon Simple Notification Service (SNS)&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/aws/sns/SnsIO.html">org.apache.beam.sdk.io.aws.sns.SnsIO&lt;/a>&lt;/div>
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/aws2/sns/SnsIO.html">org.apache.beam.sdk.io.aws2.sns.SnsIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;h3>Database&lt;/h3>
&lt;p>These I/O connectors are used to connect to database systems.&lt;/p>
&lt;table class="table table-bordered">
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>
&lt;span class="language-java">Javadoc&lt;/span>
&lt;span class="language-py">pydoc&lt;/span>
&lt;span class="language-go">Godoc&lt;/span>
&lt;/th>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
CassandraIO
&lt;/td>
&lt;td>An IO to read from &lt;a href="https://cassandra.apache.org/">Apache Cassandra&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/cassandra/CassandraIO.html">org.apache.beam.sdk.io.cassandra.CassandraIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
HadoopFormatIO
&lt;a href="/documentation/io/built-in/hadoop/"> (guide)&lt;/a>
&lt;/td>
&lt;td>Allows for reading data from any source or writing data to any sink which implements &lt;a href="https://hadoop.apache.org/">Hadoop&lt;/a> InputFormat or OutputFormat.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/hadoop/format/HadoopFormatIO.html">org.apache.beam.sdk.io.hadoop.format.HadoopFormatIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
HBaseIO
&lt;/td>
&lt;td>A bounded source and sink for &lt;a href="https://hbase.apache.org/">HBase&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/hbase/HBaseIO.html">org.apache.beam.sdk.io.hbase.HBaseIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
HCatalogIO
&lt;a href="/documentation/io/built-in/hcatalog/"> (guide)&lt;/a>
&lt;/td>
&lt;td>HCatalog source supports reading of HCatRecord from a &lt;a href="https://cwiki.apache.org/confluence/display/Hive/HCatalog">HCatalog&lt;/a>-managed source, for example &lt;a href="https://hive.apache.org/">Hive&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/hcatalog/HCatalogIO.html">org.apache.beam.sdk.io.hcatalog.HCatalogIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
KuduIO
&lt;/td>
&lt;td>A bounded source and sink for &lt;a href="https://kudu.apache.org/">Kudu&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/kudu/KuduIO.html">org.apache.beam.sdk.io.kudu&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
SolrIO
&lt;/td>
&lt;td>Transforms for reading and writing data from/to &lt;a href="https://lucene.apache.org/solr/">Solr&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/solr/SolrIO.html">org.apache.beam.sdk.io.solr.SolrIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
ElasticsearchIO
&lt;/td>
&lt;td>Transforms for reading and writing data from/to &lt;a href="https://www.elastic.co/elasticsearch/">Elasticsearch&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIO.html">org.apache.beam.sdk.io.elasticsearch.ElasticsearchIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
BigQueryIO
&lt;a href="/documentation/io/built-in/google-bigquery/"> (guide)&lt;/a>
&lt;/td>
&lt;td>Read from and write to &lt;a href="https://cloud.google.com/bigquery">Google Cloud BigQuery&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.html">org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
BigQueryIO
&lt;a href="/documentation/io/built-in/google-bigquery/"> (guide)&lt;/a>
&lt;/td>
&lt;td>Read from and write to &lt;a href="https://cloud.google.com/bigquery">Google Cloud BigQuery&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.gcp.bigquery.html">apache_beam.io.gcp.bigquery&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-go">
&lt;td>
BigQueryIO
&lt;a href="/documentation/io/built-in/google-bigquery/"> (guide)&lt;/a>
&lt;/td>
&lt;td>Read from and write to &lt;a href="https://cloud.google.com/bigquery">Google Cloud BigQuery&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam/io/bigqueryio">github.com/apache/beam/sdks/go/pkg/beam/io/bigqueryio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
BigTableIO
&lt;/td>
&lt;td>Read from and write to &lt;a href="https://cloud.google.com/bigtable/">Google Cloud Bigtable&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/gcp/bigtable/BigtableIO.html">org.apache.beam.sdk.io.gcp.bigtable.BigtableIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
BigTableIO
&lt;/td>
&lt;td>Read from and write to &lt;a href="https://cloud.google.com/bigtable/">Google Cloud Bigtable&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.gcp.bigtableio.html">apache_beam.io.gcp.bigtableio module&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
DatastoreIO
&lt;/td>
&lt;td>Read from and write to &lt;a href="https://cloud.google.com/datastore">Google Cloud Datastore&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/gcp/datastore/DatastoreIO.html">org.apache.beam.sdk.io.gcp.datastore.DatastoreIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
DatastoreIO
&lt;/td>
&lt;td>Read from and write to &lt;a href="https://cloud.google.com/datastore">Google Cloud Datastore&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.gcp.datastore.v1new.datastoreio.html">apache_beam.io.gcp.datastore.v1new.datastoreio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
SnowflakeIO
&lt;a href="/documentation/io/built-in/snowflake"> (guide)&lt;/a>
&lt;/td>
&lt;td>Experimental Transforms for reading from and writing to &lt;a href="https://www.snowflake.com/">Snowflake&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/snowflake/SnowflakeIO.html">org.apache.beam.sdk.io.snowflake.SnowflakeIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
SpannerIO
&lt;/td>
&lt;td>Experimental Transforms for reading from and writing to &lt;a href="https://cloud.google.com/spanner">Google Cloud Spanner&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/gcp/spanner/SpannerIO.html">org.apache.beam.sdk.io.gcp.spanner.SpannerIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
JdbcIO
&lt;/td>
&lt;td>IO to read and write data on &lt;a href="https://docs.oracle.com/javase/tutorial/jdbc/basics/index.html">JDBC&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/jdbc/JdbcIO.html">org.apache.beam.sdk.io.jdbc.JdbcIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
MongoDbIO
&lt;/td>
&lt;td>IO to read and write data on &lt;a href="https://www.mongodb.com/">MongoDB&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/mongodb/MongoDbIO.html">org.apache.beam.sdk.io.mongodb.MongoDbIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
MongoDbIO
&lt;/td>
&lt;td>IO to read and write data on &lt;a href="https://www.mongodb.com/">MongoDB&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.mongodbio.html">apache_beam.io.mongodbio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
MongoDbGridFSIO
&lt;/td>
&lt;td>IO to read and write data on &lt;a href="https://docs.mongodb.com/manual/core/gridfs/">MongoDB GridFS&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/mongodb/MongoDbGridFSIO.html">org.apache.beam.sdk.io.mongodb.MongoDbGridFSIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
RedisIO
&lt;/td>
&lt;td>An IO to manipulate a &lt;a href="https://redis.io/">Redis&lt;/a> key/value database.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/redis/RedisIO.html">org.apache.beam.sdk.io.redis.RedisIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
DynamoDBIO
&lt;/td>
&lt;td>Read from and write to &lt;a href="https://aws.amazon.com/dynamodb/">Amazon DynamoDB&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/aws/dynamodb/DynamoDBIO.html">org.apache.beam.sdk.io.aws.dynamodb.DynamoDBIO&lt;/a>&lt;/div>
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIO.html">org.apache.beam.sdk.io.aws2.dynamodb.DynamoDBIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
ClickHouseIO
&lt;/td>
&lt;td>Transform for writing to &lt;a href="https://clickhouse.tech/">ClickHouse&lt;/a>.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/clickhouse/ClickHouseIO.html">org.apache.beam.sdk.io.clickhouse.ClickHouseIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-go">
&lt;td>
DatabaseIO
&lt;/td>
&lt;td>Package databaseio provides transformations and utilities to interact with a generic database / SQL API.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://godoc.org/github.com/apache/beam/sdks/go/pkg/beam/io/databaseio">github.com/apache/beam/sdks/go/pkg/beam/io/databaseio&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;h3>Miscellaneous&lt;/h3>
&lt;p>Miscellaneous I/O sources.&lt;/p>
&lt;table class="table table-bordered">
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>
&lt;span class="language-java">Javadoc&lt;/span>
&lt;span class="language-py">pydoc&lt;/span>
&lt;span class="language-go">Godoc&lt;/span>
&lt;/th>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
FlinkStreamingImpulseSource
&lt;/td>
&lt;td>A PTransform that provides an unbounded, streaming source of empty byte arrays. This can only be used with the Flink runner.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.flink.flink_streaming_impulse_source.html">apache_beam.io.flink.flink_streaming_impulse_source&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
GenerateSequence
&lt;/td>
&lt;td>Generates a bounded or unbounded stream of integers.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/GenerateSequence.html">org.apache.beam.sdk.io.GenerateSequence&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-py">
&lt;td>
GenerateSequence
&lt;/td>
&lt;td>Generates a bounded or unbounded stream of integers.&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.external.generate_sequence.html">apache_beam.io.external.generate_sequence.GenerateSequence&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;tr class="language-java">
&lt;td>
SplunkIO
&lt;/td>
&lt;td>A PTransform that provides an unbounded, streaming sink for Splunk&amp;rsquo;s Http Event Collector (HEC).&lt;/td>
&lt;td style="word-break: break-all;">
&lt;div>&lt;a target="_blank" href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/splunk/SplunkIO.html">org.apache.beam.sdk.io.splunk.SplunkIO&lt;/a>&lt;/div>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;h1 id="in-progress-io-transforms">In-Progress I/O Transforms&lt;/h1>
&lt;p>This table contains I/O transforms that are currently planned or in-progress. Status information can be found on the JIRA issue, or on the GitHub PR linked to by the JIRA issue (if there is one).&lt;/p>
&lt;table class="table table-bordered">
&lt;tr>
&lt;th>Name&lt;/th>&lt;th>Language&lt;/th>&lt;th>JIRA&lt;/th>
&lt;/tr>
&lt;tr>
&lt;td>Apache DistributedLog&lt;/td>&lt;td>Java&lt;/td>
&lt;td>&lt;a href="https://issues.apache.org/jira/browse/BEAM-607">BEAM-607&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Apache Sqoop&lt;/td>&lt;td>Java&lt;/td>
&lt;td>&lt;a href="https://issues.apache.org/jira/browse/BEAM-67">BEAM-67&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Couchbase&lt;/td>&lt;td>Java&lt;/td>
&lt;td>&lt;a href="https://issues.apache.org/jira/browse/BEAM-1893">BEAM-1893&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>InfluxDB&lt;/td>&lt;td>Java&lt;/td>
&lt;td>&lt;a href="https://issues.apache.org/jira/browse/BEAM-2546">BEAM-2546&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Memcached&lt;/td>&lt;td>Java&lt;/td>
&lt;td>&lt;a href="https://issues.apache.org/jira/browse/BEAM-1678">BEAM-1678&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Neo4j&lt;/td>&lt;td>Java&lt;/td>
&lt;td>&lt;a href="https://issues.apache.org/jira/browse/BEAM-1857">BEAM-1857&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Pub/Sub Lite&lt;/td>&lt;td>Java&lt;/td>
&lt;td>&lt;a href="https://issues.apache.org/jira/browse/BEAM-10114">BEAM-10114&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>RestIO&lt;/td>&lt;td>Java&lt;/td>
&lt;td>&lt;a href="https://issues.apache.org/jira/browse/BEAM-1946">BEAM-1946&lt;/a>&lt;/td>
&lt;/tr>
&lt;/table></description></item><item><title>Documentation: CoGroupByKey</title><link>/documentation/transforms/java/aggregation/cogroupbykey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/cogroupbykey/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="cogroupbykey">CoGroupByKey&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/join/CoGroupByKey.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Aggregates all input elements by their key and allows downstream processing
to consume all values associated with the key. While &lt;code>GroupByKey&lt;/code> performs
this operation over a single input collection and thus a single type of
input values, &lt;code>CoGroupByKey&lt;/code> operates over multiple input collections. As
a result, the result for each key is a tuple of the values associated with
that key in each input collection.&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#cogroupbykey">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>&lt;strong>Example&lt;/strong>: Say you have two different files with user data; one file has
names and email addresses and the other file has names and phone numbers.&lt;/p>
&lt;p>You can join those two data sets, using the username as a common key and the
other data as the associated values. After the join, you have one data set
that contains all of the information (email addresses and phone numbers)
associated with each name.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">UID&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">pt1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="cm">/* ... */&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">UID&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">pt2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="cm">/* ... */&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">t1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;();&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">t2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;();&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">UID&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CoGBKResult&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">KeyedPCollectionTuple&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">t1&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">pt1&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">t2&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">pt2&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CoGroupByKey&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">result&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="cm">/* some result */&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">e&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">CoGbkResult&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// Retrieve all integers associated with this key from pt1
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Iterable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">allIntegers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">result&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getAll&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">t1&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Retrieve the string associated with this key from pt2.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// Note: This will fail if multiple values had the same key in pt2.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">string&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getOnly&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">t2&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/groupbykey">GroupByKey&lt;/a>
takes one input collection.&lt;/li>
&lt;/ul></description></item><item><title>Documentation: CoGroupByKey</title><link>/documentation/transforms/python/aggregation/cogroupbykey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/cogroupbykey/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="cogroupbykey">CoGroupByKey&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html#apache_beam.transforms.util.CoGroupByKey"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Aggregates all input elements by their key and allows downstream processing
to consume all values associated with the key. While &lt;code>GroupByKey&lt;/code> performs
this operation over a single input collection and thus a single type of input
values, &lt;code>CoGroupByKey&lt;/code> operates over multiple input collections. As a result,
the result for each key is a tuple of the values associated with that key in
each input collection.&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#cogroupbykey">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following example, we create a pipeline with two &lt;code>PCollection&lt;/code>s of produce, one with icons and one with durations, both with a common key of the produce name.
Then, we apply &lt;code>CoGroupByKey&lt;/code> to join both &lt;code>PCollection&lt;/code>s using their keys.&lt;/p>
&lt;p>&lt;code>CoGroupByKey&lt;/code> expects a dictionary of named keyed &lt;code>PCollection&lt;/code>s, and produces elements joined by their keys.
The values of each output element are dictionaries where the names correspond to the input dictionary, with lists of all the values found for that key.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">icon_pairs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create icons&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Apple&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍎&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Apple&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍏&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="n">duration_pairs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create durations&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Apple&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="n">plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(({&lt;/span>
&lt;span class="s1">&amp;#39;icons&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">icon_pairs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;durations&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">duration_pairs&lt;/span>
&lt;span class="p">})&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Merge&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CoGroupByKey&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;Apple&amp;#39;, {&amp;#39;icons&amp;#39;: [&amp;#39;🍎&amp;#39;, &amp;#39;🍏&amp;#39;], &amp;#39;durations&amp;#39;: [&amp;#39;perennial&amp;#39;]})
(&amp;#39;Carrot&amp;#39;, {&amp;#39;icons&amp;#39;: [], &amp;#39;durations&amp;#39;: [&amp;#39;biennial&amp;#39;]})
(&amp;#39;Tomato&amp;#39;, {&amp;#39;icons&amp;#39;: [&amp;#39;🍅&amp;#39;], &amp;#39;durations&amp;#39;: [&amp;#39;perennial&amp;#39;, &amp;#39;annual&amp;#39;]})
(&amp;#39;Eggplant&amp;#39;, {&amp;#39;icons&amp;#39;: [&amp;#39;🍆&amp;#39;], &amp;#39;durations&amp;#39;: []})&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/cogroupbykey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/combineglobally">CombineGlobally&lt;/a> to combine elements.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/groupbykey">GroupByKey&lt;/a> takes one input collection.&lt;/li>
&lt;/ul>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html#apache_beam.transforms.util.CoGroupByKey"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: Combine</title><link>/documentation/transforms/java/aggregation/combine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/combine/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="combine">Combine&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/Combine.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>A user-defined &lt;code>CombineFn&lt;/code> may be applied to combine all elements in a
&lt;code>PCollection&lt;/code> (global combine) or to combine all elements associated
with each key.&lt;/p>
&lt;p>While the result is similar to applying a &lt;code>GroupByKey&lt;/code> followed by
aggregating values in each &lt;code>Iterable&lt;/code>, there is an impact
on the code you must write as well as the performance of the pipeline.
Writing a &lt;code>ParDo&lt;/code> that counts the number of elements in each value
would be very straightforward. However, as described in the execution
model, it would also require all values associated with each key to be
processed by a single worker. This introduces a lot of communication overhead.
Using a &lt;code>CombineFn&lt;/code> requires the code be structured as an associative and
commumative operation. But, it allows the use of partial sums to be precomputed.&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#combine">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>&lt;strong>Example 1&lt;/strong>: Global combine
Use the global combine to combine all of the elements in a given &lt;code>PCollection&lt;/code>
into a single value, represented in your pipeline as a new &lt;code>PCollection&lt;/code> containing
one element. The following example code shows how to apply the Beam-provided
sum combine function to produce a single sum value for a &lt;code>PCollection&lt;/code> of integers.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Sum.SumIntegerFn() combines the elements in the input PCollection. The resulting PCollection, called sum,
&lt;/span>&lt;span class="c1">// contains one value: the sum of all the elements in the input PCollection.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Combine&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">globally&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">Sum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">SumIntegerFn&lt;/span>&lt;span class="o">()));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Example 2&lt;/strong>: Keyed combine
Use a keyed combine to combine all of the values associated with each key
into a single output value for each key. As with the global combine, the
function passed to a keyed combine must be associative and commutative.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// PCollection is grouped by key and the Double values associated with each key are combined into a Double.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">salesRecords&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">totalSalesPerPerson&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">salesRecords&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Combine&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">perKey&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">Sum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">SumDoubleFn&lt;/span>&lt;span class="o">()));&lt;/span>
&lt;span class="c1">// The combined value is of a different type than the original collection of values per key. PCollection has
&lt;/span>&lt;span class="c1">// keys of type String and values of type Integer, and the combined value is a Double.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">playerAccuracy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">avgAccuracyPerPlayer&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">playerAccuracy&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Combine&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">perKey&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">MeanInts&lt;/span>&lt;span class="o">())));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/combinewithcontext">CombineWithContext&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/groupbykey">GroupByKey&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Documentation: CombineGlobally</title><link>/documentation/transforms/python/aggregation/combineglobally/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/combineglobally/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="combineglobally">CombineGlobally&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineGlobally"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Combines all elements in a collection.&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#combine">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following examples, we create a pipeline with a &lt;code>PCollection&lt;/code> of produce.
Then, we apply &lt;code>CombineGlobally&lt;/code> in multiple ways to combine all the elements in the &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>&lt;code>CombineGlobally&lt;/code> accepts a function that takes an &lt;code>iterable&lt;/code> of elements as an input, and combines them to return a single element.&lt;/p>
&lt;h3 id="example-1-combining-with-a-function">Example 1: Combining with a function&lt;/h3>
&lt;p>We define a function &lt;code>get_common_items&lt;/code> which takes an &lt;code>iterable&lt;/code> of sets as an input, and calculates the intersection (common items) of those sets.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">get_common_items&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sets&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># set.intersection() takes multiple sets as separete arguments.&lt;/span>
&lt;span class="c1"># We unpack the `sets` list into multiple arguments with the * operator.&lt;/span>
&lt;span class="c1"># The combine transform might give us an empty list of `sets`,&lt;/span>
&lt;span class="c1"># so we use a list with an empty set as a default value.&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">set&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">intersection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sets&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">set&lt;/span>&lt;span class="p">()]))&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">common_items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍌&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌶️&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍇&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥝&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍉&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍍&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🥑&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥥&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Get common items&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">get_common_items&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;🍅&amp;#39;, &amp;#39;🥕&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineglobally.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-2-combining-with-a-lambda-function">Example 2: Combining with a lambda function&lt;/h3>
&lt;p>We can also use lambda functions to simplify &lt;strong>Example 1&lt;/strong>.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">common_items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍌&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌶️&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍇&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥝&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍉&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍍&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🥑&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥥&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Get common items&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">sets&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">set&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">intersection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sets&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">set&lt;/span>&lt;span class="p">()])))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;🍅&amp;#39;, &amp;#39;🥕&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineglobally.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-3-combining-with-multiple-arguments">Example 3: Combining with multiple arguments&lt;/h3>
&lt;p>You can pass functions with multiple arguments to &lt;code>CombineGlobally&lt;/code>.
They are passed as additional positional arguments or keyword arguments to the function.&lt;/p>
&lt;p>In this example, the lambda function takes &lt;code>sets&lt;/code> and &lt;code>exclude&lt;/code> as arguments.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">common_items_with_exceptions&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍌&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌶️&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍇&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥝&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍉&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍍&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🥑&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥥&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Get common items with exceptions&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">sets&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">exclude&lt;/span>&lt;span class="p">:&lt;/span> \
&lt;span class="nb">set&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">intersection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sets&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">set&lt;/span>&lt;span class="p">()]))&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">exclude&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">exclude&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">})&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;🍅&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineglobally.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-4-combining-with-side-inputs-as-singletons">Example 4: Combining with side inputs as singletons&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has a single value, such as the average from another computation,
passing the &lt;code>PCollection&lt;/code> as a &lt;em>singleton&lt;/em> accesses that value.&lt;/p>
&lt;p>In this example, we pass a &lt;code>PCollection&lt;/code> the value &lt;code>'🥕'&lt;/code> as a singleton.
We then use that value to exclude specific items.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">single_exclude&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create single_exclude&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">common_items_with_exceptions&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍌&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌶️&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍇&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥝&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍉&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍍&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🥑&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥥&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Get common items with exceptions&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">sets&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">single_exclude&lt;/span>&lt;span class="p">:&lt;/span> \
&lt;span class="nb">set&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">intersection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sets&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">set&lt;/span>&lt;span class="p">()]))&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="n">single_exclude&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="n">single_exclude&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsSingleton&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">single_exclude&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;🍅&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineglobally.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-5-combining-with-side-inputs-as-iterators">Example 5: Combining with side inputs as iterators&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has multiple values, pass the &lt;code>PCollection&lt;/code> as an &lt;em>iterator&lt;/em>.
This accesses elements lazily as they are needed,
so it is possible to iterate over large &lt;code>PCollection&lt;/code>s that won&amp;rsquo;t fit into memory.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">exclude&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create exclude&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">common_items_with_exceptions&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍌&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌶️&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍇&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥝&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍉&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍍&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🥑&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥥&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Get common items with exceptions&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">sets&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">exclude&lt;/span>&lt;span class="p">:&lt;/span> \
&lt;span class="nb">set&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">intersection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sets&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">set&lt;/span>&lt;span class="p">()]))&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="nb">set&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">exclude&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">exclude&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsIter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">exclude&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;🍅&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineglobally.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: You can pass the &lt;code>PCollection&lt;/code> as a &lt;em>list&lt;/em> with &lt;code>beam.pvalue.AsList(pcollection)&lt;/code>,
but this requires that all the elements fit into memory.&lt;/p>
&lt;/blockquote>
&lt;h3 id="example-6-combining-with-side-inputs-as-dictionaries">Example 6: Combining with side inputs as dictionaries&lt;/h3>
&lt;p>If a &lt;code>PCollection&lt;/code> is small enough to fit into memory, then that &lt;code>PCollection&lt;/code> can be passed as a &lt;em>dictionary&lt;/em>.
Each element must be a &lt;code>(key, value)&lt;/code> pair.
Note that all the elements of the &lt;code>PCollection&lt;/code> must fit into memory for this.
If the &lt;code>PCollection&lt;/code> won&amp;rsquo;t fit into memory, use &lt;code>beam.pvalue.AsIter(pcollection)&lt;/code> instead.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">get_custom_common_items&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sets&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">options&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">sets&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sets&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">set&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;span class="n">common_items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">set&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">intersection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">sets&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">common_items&lt;/span> &lt;span class="o">|=&lt;/span> &lt;span class="n">options&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;include&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1"># union&lt;/span>
&lt;span class="n">common_items&lt;/span> &lt;span class="o">&amp;amp;=&lt;/span> &lt;span class="n">options&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;exclude&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1"># intersection&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">common_items&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create options&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;exclude&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">}),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;include&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍇&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">}),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="n">custom_common_items&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍌&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌶️&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍇&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥝&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🍉&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍍&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;🥑&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥥&amp;#39;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Get common items&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">get_custom_common_items&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">options&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsDict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;🍅&amp;#39;, &amp;#39;🍇&amp;#39;, &amp;#39;🌽&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineglobally.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-7-combining-with-a-combinefn">Example 7: Combining with a &lt;code>CombineFn&lt;/code>&lt;/h3>
&lt;p>The more general way to combine elements, and the most flexible, is with a class that inherits from &lt;code>CombineFn&lt;/code>.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.create_accumulator">&lt;code>CombineFn.create_accumulator()&lt;/code>&lt;/a>:
This creates an empty accumulator.
For example, an empty accumulator for a sum would be &lt;code>0&lt;/code>, while an empty accumulator for a product (multiplication) would be &lt;code>1&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.add_input">&lt;code>CombineFn.add_input()&lt;/code>&lt;/a>:
Called &lt;em>once per element&lt;/em>.
Takes an accumulator and an input element, combines them and returns the updated accumulator.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.merge_accumulators">&lt;code>CombineFn.merge_accumulators()&lt;/code>&lt;/a>:
Multiple accumulators could be processed in parallel, so this function helps merging them into a single accumulator.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.extract_output">&lt;code>CombineFn.extract_output()&lt;/code>&lt;/a>:
It allows to do additional calculations before extracting a result.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">PercentagesFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">create_accumulator&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">add_input&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># accumulator == {}&lt;/span>
&lt;span class="c1"># input == &amp;#39;🥕&amp;#39;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nb">input&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">accumulator&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="c1"># {&amp;#39;🥕&amp;#39;: 0}&lt;/span>
&lt;span class="n">accumulator&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="c1"># {&amp;#39;🥕&amp;#39;: 1}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">accumulator&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">merge_accumulators&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulators&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># accumulators == [&lt;/span>
&lt;span class="c1"># {&amp;#39;🥕&amp;#39;: 1, &amp;#39;🍅&amp;#39;: 2},&lt;/span>
&lt;span class="c1"># {&amp;#39;🥕&amp;#39;: 1, &amp;#39;🍅&amp;#39;: 1, &amp;#39;🍆&amp;#39;: 1},&lt;/span>
&lt;span class="c1"># {&amp;#39;🥕&amp;#39;: 1, &amp;#39;🍅&amp;#39;: 3},&lt;/span>
&lt;span class="c1"># ]&lt;/span>
&lt;span class="n">merged&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">accum&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">accumulators&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">item&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">accum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">item&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">merged&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">merged&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="n">merged&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">count&lt;/span>
&lt;span class="c1"># merged == {&amp;#39;🥕&amp;#39;: 3, &amp;#39;🍅&amp;#39;: 6, &amp;#39;🍆&amp;#39;: 1}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">merged&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">extract_output&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># accumulator == {&amp;#39;🥕&amp;#39;: 3, &amp;#39;🍅&amp;#39;: 6, &amp;#39;🍆&amp;#39;: 1}&lt;/span>
&lt;span class="n">total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">accumulator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="c1"># 10&lt;/span>
&lt;span class="n">percentages&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">total&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">item&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">()}&lt;/span>
&lt;span class="c1"># percentages == {&amp;#39;🥕&amp;#39;: 0.3, &amp;#39;🍅&amp;#39;: 0.6, &amp;#39;🍆&amp;#39;: 0.1}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">percentages&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">percentages&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Get percentages&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineGlobally&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">PercentagesFn&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;🥕&amp;#39;: 0.3, &amp;#39;🍅&amp;#39;: 0.6, &amp;#39;🍆&amp;#39;: 0.1}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineglobally.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;p>You can use the following combiner transforms:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/combineperkey">CombinePerKey&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/combinevalues">CombineValues&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/mean">Mean&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/count">Count&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/top">Top&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/sample">Sample&lt;/a>&lt;/li>
&lt;/ul>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineGlobally"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: CombinePerKey</title><link>/documentation/transforms/python/aggregation/combineperkey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/combineperkey/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="combineperkey">CombinePerKey&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombinePerKey"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Combines all elements for each key in a collection.&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#combine">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following examples, we create a pipeline with a &lt;code>PCollection&lt;/code> of produce.
Then, we apply &lt;code>CombinePerKey&lt;/code> in multiple ways to combine all the elements in the &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>&lt;code>CombinePerKey&lt;/code> accepts a function that takes a list of values as an input, and combines them for each key.&lt;/p>
&lt;h3 id="example-1-combining-with-a-predefined-function">Example 1: Combining with a predefined function&lt;/h3>
&lt;p>We use the function
&lt;a href="https://docs.python.org/3/library/functions.html#sum">&lt;code>sum&lt;/code>&lt;/a>
which takes an &lt;code>iterable&lt;/code> of numbers and adds them together.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombinePerKey&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 12)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineperkey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-2-combining-with-a-function">Example 2: Combining with a function&lt;/h3>
&lt;p>We define a function &lt;code>saturated_sum&lt;/code> which takes an &lt;code>iterable&lt;/code> of numbers and adds them together, up to a predefined maximum number.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">saturated_sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">max_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">8&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">saturated_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Saturated sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombinePerKey&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">saturated_sum&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineperkey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-3-combining-with-a-lambda-function">Example 3: Combining with a lambda function&lt;/h3>
&lt;p>We can also use lambda functions to simplify &lt;strong>Example 2&lt;/strong>.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">saturated_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Saturated sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombinePerKey&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineperkey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-4-combining-with-multiple-arguments">Example 4: Combining with multiple arguments&lt;/h3>
&lt;p>You can pass functions with multiple arguments to &lt;code>CombinePerKey&lt;/code>.
They are passed as additional positional arguments or keyword arguments to the function.&lt;/p>
&lt;p>In this example, the lambda function takes &lt;code>values&lt;/code> and &lt;code>max_value&lt;/code> as arguments.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">saturated_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Saturated sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombinePerKey&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineperkey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-5-combining-with-side-inputs-as-singletons">Example 5: Combining with side inputs as singletons&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has a single value, such as the average from another computation,
passing the &lt;code>PCollection&lt;/code> as a &lt;em>singleton&lt;/em> accesses that value.&lt;/p>
&lt;p>In this example, we pass a &lt;code>PCollection&lt;/code> the value &lt;code>8&lt;/code> as a singleton.
We then use that value as the &lt;code>max_value&lt;/code> for our saturated sum.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">max_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create max_value&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">saturated_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Saturated sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombinePerKey&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">max_value&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">max_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsSingleton&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">max_value&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineperkey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-6-combining-with-side-inputs-as-iterators">Example 6: Combining with side inputs as iterators&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has multiple values, pass the &lt;code>PCollection&lt;/code> as an &lt;em>iterator&lt;/em>.
This accesses elements lazily as they are needed,
so it is possible to iterate over large &lt;code>PCollection&lt;/code>s that won&amp;rsquo;t fit into memory.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">bounded_sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">min_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_range&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">min_value&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">min_value&lt;/span>
&lt;span class="n">max_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_range&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">max_value&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">result&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">data_range&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create data_range&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">bounded_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Bounded sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombinePerKey&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">bounded_sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsIter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_range&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 2)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineperkey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: You can pass the &lt;code>PCollection&lt;/code> as a &lt;em>list&lt;/em> with &lt;code>beam.pvalue.AsList(pcollection)&lt;/code>,
but this requires that all the elements fit into memory.&lt;/p>
&lt;/blockquote>
&lt;h3 id="example-7-combining-with-side-inputs-as-dictionaries">Example 7: Combining with side inputs as dictionaries&lt;/h3>
&lt;p>If a &lt;code>PCollection&lt;/code> is small enough to fit into memory, then that &lt;code>PCollection&lt;/code> can be passed as a &lt;em>dictionary&lt;/em>.
Each element must be a &lt;code>(key, value)&lt;/code> pair.
Note that all the elements of the &lt;code>PCollection&lt;/code> must fit into memory for this.
If the &lt;code>PCollection&lt;/code> won&amp;rsquo;t fit into memory, use &lt;code>beam.pvalue.AsIter(pcollection)&lt;/code> instead.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">bounded_sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">min_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;min&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">min_value&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">min_value&lt;/span>
&lt;span class="n">max_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;max&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">max_value&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">result&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">data_range&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create data_range&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;min&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;max&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="n">bounded_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Bounded sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombinePerKey&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">bounded_sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsDict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_range&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 2)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineperkey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-8-combining-with-a-combinefn">Example 8: Combining with a &lt;code>CombineFn&lt;/code>&lt;/h3>
&lt;p>The more general way to combine elements, and the most flexible, is with a class that inherits from &lt;code>CombineFn&lt;/code>.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.create_accumulator">&lt;code>CombineFn.create_accumulator()&lt;/code>&lt;/a>:
This creates an empty accumulator.
For example, an empty accumulator for a sum would be &lt;code>0&lt;/code>, while an empty accumulator for a product (multiplication) would be &lt;code>1&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.add_input">&lt;code>CombineFn.add_input()&lt;/code>&lt;/a>:
Called &lt;em>once per element&lt;/em>.
Takes an accumulator and an input element, combines them and returns the updated accumulator.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.merge_accumulators">&lt;code>CombineFn.merge_accumulators()&lt;/code>&lt;/a>:
Multiple accumulators could be processed in parallel, so this function helps merging them into a single accumulator.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.extract_output">&lt;code>CombineFn.extract_output()&lt;/code>&lt;/a>:
It allows to do additional calculations before extracting a result.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">AverageFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">create_accumulator&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="nb">sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;span class="n">count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="n">accumulator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">accumulator&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">add_input&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="nb">sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">accumulator&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">sum&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">merge_accumulators&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulators&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># accumulators = [(sum1, count1), (sum2, count2), (sum3, count3), ...]&lt;/span>
&lt;span class="n">sums&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">counts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">accumulators&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># sums = [sum1, sum2, sum3, ...]&lt;/span>
&lt;span class="c1"># counts = [count1, count2, count3, ...]&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sums&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">counts&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">extract_output&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="nb">sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">accumulator&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">float&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;NaN&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">sum&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">count&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">average&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Average&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombinePerKey&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">AverageFn&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 2.5)
(&amp;#39;🍆&amp;#39;, 1.0)
(&amp;#39;🍅&amp;#39;, 4.0)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combineperkey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;p>You can use the following combiner transforms:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/combineglobally">CombineGlobally&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/combinevalues">CombineValues&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/mean">Mean&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/count">Count&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/top">Top&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/sample">Sample&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>See also &lt;a href="/documentation/transforms/python/aggregation/groupby">GroupBy&lt;/a> which allows you to combine more than one field at once.&lt;/p>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombinePerKey"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: CombineValues</title><link>/documentation/transforms/python/aggregation/combinevalues/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/combinevalues/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="combinevalues">CombineValues&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineValues"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Combines an iterable of values in a keyed collection of elements.&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#combine">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following examples, we create a pipeline with a &lt;code>PCollection&lt;/code> of produce.
Then, we apply &lt;code>CombineValues&lt;/code> in multiple ways to combine the keyed values in the &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>&lt;code>CombineValues&lt;/code> accepts a function that takes an &lt;code>iterable&lt;/code> of elements as an input, and combines them to return a single element.
&lt;code>CombineValues&lt;/code> expects a keyed &lt;code>PCollection&lt;/code> of elements, where the value is an iterable of elements to be combined.&lt;/p>
&lt;h3 id="example-1-combining-with-a-predefined-function">Example 1: Combining with a predefined function&lt;/h3>
&lt;p>We use the function
&lt;a href="https://docs.python.org/3/library/functions.html#sum">&lt;code>sum&lt;/code>&lt;/a>
which takes an &lt;code>iterable&lt;/code> of numbers and adds them together.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 12)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combinevalues.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-2-combining-with-a-function">Example 2: Combining with a function&lt;/h3>
&lt;p>We want the sum to be bounded up to a maximum value, so we use
&lt;a href="https://en.wikipedia.org/wiki/Saturation_arithmetic">saturated arithmetic&lt;/a>.&lt;/p>
&lt;p>We define a function &lt;code>saturated_sum&lt;/code> which takes an &lt;code>iterable&lt;/code> of numbers and adds them together, up to a predefined maximum number.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">saturated_sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">max_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">8&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">saturated_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Saturated sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">saturated_sum&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combinevalues.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-3-combining-with-a-lambda-function">Example 3: Combining with a lambda function&lt;/h3>
&lt;p>We can also use lambda functions to simplify &lt;strong>Example 2&lt;/strong>.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">saturated_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Saturated sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combinevalues.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-4-combining-with-multiple-arguments">Example 4: Combining with multiple arguments&lt;/h3>
&lt;p>You can pass functions with multiple arguments to &lt;code>CombineValues&lt;/code>.
They are passed as additional positional arguments or keyword arguments to the function.&lt;/p>
&lt;p>In this example, the lambda function takes &lt;code>values&lt;/code> and &lt;code>max_value&lt;/code> as arguments.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">saturated_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Saturated sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineValues&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combinevalues.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-5-combining-with-side-inputs-as-singletons">Example 5: Combining with side inputs as singletons&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has a single value, such as the average from another computation,
passing the &lt;code>PCollection&lt;/code> as a &lt;em>singleton&lt;/em> accesses that value.&lt;/p>
&lt;p>In this example, we pass a &lt;code>PCollection&lt;/code> the value &lt;code>8&lt;/code> as a singleton.
We then use that value as the &lt;code>max_value&lt;/code> for our saturated sum.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">max_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create max_value&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">saturated_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Saturated sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineValues&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">values&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">max_value&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">max_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsSingleton&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">max_value&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 1)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combinevalues.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-6-combining-with-side-inputs-as-iterators">Example 6: Combining with side inputs as iterators&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has multiple values, pass the &lt;code>PCollection&lt;/code> as an &lt;em>iterator&lt;/em>.
This accesses elements lazily as they are needed,
so it is possible to iterate over large &lt;code>PCollection&lt;/code>s that won&amp;rsquo;t fit into memory.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">bounded_sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">min_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_range&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">min_value&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">min_value&lt;/span>
&lt;span class="n">max_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_range&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">max_value&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">result&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">data_range&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create data_range&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">bounded_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Bounded sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineValues&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">bounded_sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsIter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_range&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 2)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combinevalues.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: You can pass the &lt;code>PCollection&lt;/code> as a &lt;em>list&lt;/em> with &lt;code>beam.pvalue.AsList(pcollection)&lt;/code>,
but this requires that all the elements fit into memory.&lt;/p>
&lt;/blockquote>
&lt;h3 id="example-7-combining-with-side-inputs-as-dictionaries">Example 7: Combining with side inputs as dictionaries&lt;/h3>
&lt;p>If a &lt;code>PCollection&lt;/code> is small enough to fit into memory, then that &lt;code>PCollection&lt;/code> can be passed as a &lt;em>dictionary&lt;/em>.
Each element must be a &lt;code>(key, value)&lt;/code> pair.
Note that all the elements of the &lt;code>PCollection&lt;/code> must fit into memory for this.
If the &lt;code>PCollection&lt;/code> won&amp;rsquo;t fit into memory, use &lt;code>beam.pvalue.AsIter(pcollection)&lt;/code> instead.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">bounded_sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">min_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;min&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">min_value&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">min_value&lt;/span>
&lt;span class="n">max_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;max&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">max_value&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">max_value&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">result&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">data_range&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create data_range&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;min&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;max&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="n">bounded_total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plant counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Bounded sum&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineValues&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">bounded_sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data_range&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsDict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data_range&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🥕&amp;#39;, 5)
(&amp;#39;🍆&amp;#39;, 2)
(&amp;#39;🍅&amp;#39;, 8)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combinevalues.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-8-combining-with-a-combinefn">Example 8: Combining with a &lt;code>CombineFn&lt;/code>&lt;/h3>
&lt;p>The more general way to combine elements, and the most flexible, is with a class that inherits from &lt;code>CombineFn&lt;/code>.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.create_accumulator">&lt;code>CombineFn.create_accumulator()&lt;/code>&lt;/a>:
This creates an empty accumulator.
For example, an empty accumulator for a sum would be &lt;code>0&lt;/code>, while an empty accumulator for a product (multiplication) would be &lt;code>1&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.add_input">&lt;code>CombineFn.add_input()&lt;/code>&lt;/a>:
Called &lt;em>once per element&lt;/em>.
Takes an accumulator and an input element, combines them and returns the updated accumulator.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.merge_accumulators">&lt;code>CombineFn.merge_accumulators()&lt;/code>&lt;/a>:
Multiple accumulators could be processed in parallel, so this function helps merging them into a single accumulator.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineFn.extract_output">&lt;code>CombineFn.extract_output()&lt;/code>&lt;/a>:
It allows to do additional calculations before extracting a result.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">class&lt;/span> &lt;span class="nc">AverageFn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineFn&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">create_accumulator&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">add_input&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># accumulator == {}&lt;/span>
&lt;span class="c1"># input == &amp;#39;🥕&amp;#39;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nb">input&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">accumulator&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="c1"># {&amp;#39;🥕&amp;#39;: 0}&lt;/span>
&lt;span class="n">accumulator&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="c1"># {&amp;#39;🥕&amp;#39;: 1}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">accumulator&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">merge_accumulators&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulators&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># accumulators == [&lt;/span>
&lt;span class="c1"># {&amp;#39;🥕&amp;#39;: 1, &amp;#39;🍅&amp;#39;: 1},&lt;/span>
&lt;span class="c1"># {&amp;#39;🥕&amp;#39;: 1, &amp;#39;🍅&amp;#39;: 1, &amp;#39;🍆&amp;#39;: 1},&lt;/span>
&lt;span class="c1"># ]&lt;/span>
&lt;span class="n">merged&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">accum&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">accumulators&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">item&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">accum&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">item&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">merged&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">merged&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="n">merged&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">count&lt;/span>
&lt;span class="c1"># merged == {&amp;#39;🥕&amp;#39;: 2, &amp;#39;🍅&amp;#39;: 2, &amp;#39;🍆&amp;#39;: 1}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">merged&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">extract_output&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># accumulator == {&amp;#39;🥕&amp;#39;: 2, &amp;#39;🍅&amp;#39;: 2, &amp;#39;🍆&amp;#39;: 1}&lt;/span>
&lt;span class="n">total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">accumulator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="c1"># 5&lt;/span>
&lt;span class="n">percentages&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">total&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">item&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">accumulator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">()}&lt;/span>
&lt;span class="c1"># percentages == {&amp;#39;🥕&amp;#39;: 0.4, &amp;#39;🍅&amp;#39;: 0.4, &amp;#39;🍆&amp;#39;: 0.2}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">percentages&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">percentages_per_season&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;fall&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;winter&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Average&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CombineValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">AverageFn&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;spring&amp;#39;, {&amp;#39;🥕&amp;#39;: 0.4, &amp;#39;🍅&amp;#39;: 0.4, &amp;#39;🍆&amp;#39;: 0.2})
(&amp;#39;summer&amp;#39;, {&amp;#39;🥕&amp;#39;: 0.2, &amp;#39;🍅&amp;#39;: 0.6, &amp;#39;🌽&amp;#39;: 0.2})
(&amp;#39;fall&amp;#39;, {&amp;#39;🥕&amp;#39;: 0.5, &amp;#39;🍅&amp;#39;: 0.5})
(&amp;#39;winter&amp;#39;, {&amp;#39;🍆&amp;#39;: 1.0})&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/combinevalues.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;p>You can use the following combiner transforms:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/combineglobally">CombineGlobally&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/combineperkey">CombinePerKey&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/mean">Mean&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/count">Count&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/top">Top&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/sample">Sample&lt;/a>&lt;/li>
&lt;/ul>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.CombineValues"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: CombineWithContext</title><link>/documentation/transforms/java/aggregation/combinewithcontext/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/combinewithcontext/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="combinewithcontext">CombineWithContext&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/CombineWithContext.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>A class of transforms that contains combine functions that have access to &lt;code>PipelineOptions&lt;/code> and side inputs through &lt;code>CombineWithContext.Context&lt;/code>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7703">BEAM-7703&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/combine">Combine&lt;/a>
for combining all values associated with a key to a single result&lt;/li>
&lt;/ul></description></item><item><title>Documentation: CombineWithContext</title><link>/documentation/transforms/python/aggregation/combinewithcontext/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/combinewithcontext/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="combinewithcontext">CombineWithContext&lt;/h1>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7390">BEAM-7390&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2></description></item><item><title>Documentation: Container environments</title><link>/documentation/runtime/environments/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/runtime/environments/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="container-environments">Container environments&lt;/h1>
&lt;p>The Beam SDK runtime environment is isolated from other runtime systems because the SDK runtime environment is &lt;a href="https://s.apache.org/beam-fn-api-container-contract">containerized&lt;/a> with &lt;a href="https://www.docker.com/">Docker&lt;/a>. This means that any execution engine can run the Beam SDK.&lt;/p>
&lt;p>This page describes how to customize, build, and push Beam SDK container images.&lt;/p>
&lt;p>Before you begin, install &lt;a href="https://www.docker.com/">Docker&lt;/a> on your workstation.&lt;/p>
&lt;h2 id="customizing-container-images">Customizing container images&lt;/h2>
&lt;p>You can add extra dependencies to container images so that you don&amp;rsquo;t have to supply the dependencies to execution engines.&lt;/p>
&lt;p>To customize a container image, either:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#writing-new-dockerfiles">Write a new&lt;/a> &lt;a href="https://docs.docker.com/engine/reference/builder/">Dockerfile&lt;/a> on top of the original.&lt;/li>
&lt;li>&lt;a href="#modifying-dockerfiles">Modify&lt;/a> the &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/container/Dockerfile">original Dockerfile&lt;/a> and reimage the container.&lt;/li>
&lt;/ul>
&lt;p>It&amp;rsquo;s often easier to write a new Dockerfile. However, by modifying the original Dockerfile, you can customize anything (including the base OS).&lt;/p>
&lt;h3 id="writing-new-dockerfiles">Writing new Dockerfiles on top of the original&lt;/h3>
&lt;ol>
&lt;li>Pull a &lt;a href="https://hub.docker.com/search?q=apache%2Fbeam&amp;amp;type=image">prebuilt SDK container image&lt;/a> for your &lt;a href="https://docs.docker.com/docker-hub/repos/#searching-for-repositories">target&lt;/a> language and version. The following example pulls the latest Python SDK:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>docker pull apache/beam_python3.7_sdk
&lt;/code>&lt;/pre>&lt;ol start="2">
&lt;li>&lt;a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/">Write a new Dockerfile&lt;/a> that &lt;a href="https://docs.docker.com/engine/reference/builder/#from">designates&lt;/a> the original as its &lt;a href="https://docs.docker.com/glossary/?term=parent%20image">parent&lt;/a>.&lt;/li>
&lt;li>&lt;a href="#building-container-images">Build&lt;/a> a child image.&lt;/li>
&lt;/ol>
&lt;h3 id="modifying-dockerfiles">Modifying the original Dockerfile&lt;/h3>
&lt;ol>
&lt;li>Clone the &lt;code>beam&lt;/code> repository:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>git clone https://github.com/apache/beam.git
&lt;/code>&lt;/pre>&lt;ol start="2">
&lt;li>Customize the &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/container/Dockerfile">Dockerfile&lt;/a>. If you&amp;rsquo;re adding dependencies from &lt;a href="https://pypi.org/">PyPI&lt;/a>, use &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/container/base_image_requirements.txt">&lt;code>base_image_requirements.txt&lt;/code>&lt;/a> instead.&lt;/li>
&lt;li>&lt;a href="#building-container-images">Reimage&lt;/a> the container.&lt;/li>
&lt;/ol>
&lt;h3 id="testing-customized-images">Testing customized images&lt;/h3>
&lt;p>To test a customized image locally, run a pipeline with PortableRunner and set the &lt;code>--environment_config&lt;/code> flag to the image path:&lt;/p>
&lt;div class=runner-direct>
&lt;pre>&lt;code>python -m apache_beam.examples.wordcount \
--input=/path/to/inputfile \
--output /path/to/write/counts \
--runner=PortableRunner \
--job_endpoint=embed \
--environment_config=path/to/container/image&lt;/code>&lt;/pre>
&lt;/div>
&lt;div class=runner-flink-local>
&lt;pre>&lt;code># Start a Flink job server on localhost:8099
./gradlew :runners:flink:1.8:job-server:runShadow
# Run a pipeline on the Flink job server
python -m apache_beam.examples.wordcount \
--input=/path/to/inputfile \
--output=/path/to/write/counts \
--runner=PortableRunner \
--job_endpoint=localhost:8099 \
--environment_config=path/to/container/image&lt;/code>&lt;/pre>
&lt;/div>
&lt;div class=runner-spark-local>
&lt;pre>&lt;code># Start a Spark job server on localhost:8099
./gradlew :runners:spark:job-server:runShadow
# Run a pipeline on the Spark job server
python -m apache_beam.examples.wordcount \
--input=/path/to/inputfile \
--output=path/to/write/counts \
--runner=PortableRunner \
--job_endpoint=localhost:8099 \
--environment_config=path/to/container/image&lt;/code>&lt;/pre>
&lt;/div>
&lt;h2 id="building-container-images">Building container images&lt;/h2>
&lt;p>To build Beam SDK container images:&lt;/p>
&lt;ol>
&lt;li>Navigate to the root directory of the local copy of your Apache Beam.&lt;/li>
&lt;li>Run Gradle with the &lt;code>docker&lt;/code> target. If you&amp;rsquo;re &lt;a href="#writing-new-dockerfiles">building a child image&lt;/a>, set the optional &lt;code>--file&lt;/code> flag to the new Dockerfile. If you&amp;rsquo;re &lt;a href="#modifying-dockerfiles">building an image from an original Dockerfile&lt;/a>, ignore the &lt;code>--file&lt;/code> flag:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code># The default repository of each SDK
./gradlew [--file=path/to/new/Dockerfile] :sdks:java:container:docker
./gradlew [--file=path/to/new/Dockerfile] :sdks:go:container:docker
./gradlew [--file=path/to/new/Dockerfile] :sdks:python:container:py2:docker
./gradlew [--file=path/to/new/Dockerfile] :sdks:python:container:py35:docker
./gradlew [--file=path/to/new/Dockerfile] :sdks:python:container:py36:docker
./gradlew [--file=path/to/new/Dockerfile] :sdks:python:container:py37:docker
# Shortcut for building all four Python SDKs
./gradlew [--file=path/to/new/Dockerfile] :sdks:python:container buildAll
&lt;/code>&lt;/pre>&lt;p>From 2.21.0, &lt;code>docker-pull-licenses&lt;/code> tag was introduced. Licenses/notices of third party dependencies will be added to the docker images when &lt;code>docker-pull-licenses&lt;/code> was set.
For example, &lt;code>./gradlew :sdks:java:container:docker -Pdocker-pull-licenses&lt;/code>. The files are added to &lt;code>/opt/apache/beam/third_party_licenses/&lt;/code>.
By default, no licenses/notices are added to the docker images.&lt;/p>
&lt;p>To examine the containers that you built, run &lt;code>docker images&lt;/code> from anywhere in the command line. If you successfully built all of the container images, the command prints a table like the following:&lt;/p>
&lt;pre>&lt;code>REPOSITORY TAG IMAGE ID CREATED SIZE
apache/beam_java_sdk latest 16ca619d489e 2 weeks ago 550MB
apache/beam_python2.7_sdk latest b6fb40539c29 2 weeks ago 1.78GB
apache/beam_python3.5_sdk latest bae309000d09 2 weeks ago 1.85GB
apache/beam_python3.6_sdk latest 42faad307d1a 2 weeks ago 1.86GB
apache/beam_python3.7_sdk latest 18267df54139 2 weeks ago 1.86GB
apache/beam_go_sdk latest 30cf602e9763 2 weeks ago 124MB
&lt;/code>&lt;/pre>&lt;h3 id="overriding-default-docker-targets">Overriding default Docker targets&lt;/h3>
&lt;p>The default &lt;a href="https://docs.docker.com/engine/reference/commandline/tag/">tag&lt;/a> is sdk_version defined at &lt;a href="https://github.com/apache/beam/blob/master/gradle.properties">gradle.properties&lt;/a> and the default repositories are in the Docker Hub &lt;code>apache&lt;/code> namespace.
The &lt;code>docker&lt;/code> command-line tool implicitly &lt;a href="#pushing-container-images">pushes container images&lt;/a> to this location.&lt;/p>
&lt;p>To tag a local image, set the &lt;code>docker-tag&lt;/code> option when building the container. The following command tags a Python SDK image with a date.&lt;/p>
&lt;pre>&lt;code>./gradlew :sdks:python:container:py36:docker -Pdocker-tag=2019-10-04
&lt;/code>&lt;/pre>&lt;p>To change the repository, set the &lt;code>docker-repository-root&lt;/code> option to a new location. The following command sets the &lt;code>docker-repository-root&lt;/code>
to a repository named &lt;code>example-repo&lt;/code> on Docker Hub.&lt;/p>
&lt;pre>&lt;code>./gradlew :sdks:python:container:py36:docker -Pdocker-repository-root=example-repo
&lt;/code>&lt;/pre>&lt;h2 id="pushing-container-images">Pushing container images&lt;/h2>
&lt;p>After &lt;a href="#building-container-images">building a container image&lt;/a>, you can store it in a remote Docker repository.&lt;/p>
&lt;p>The following steps push a Python3.6 SDK image to the &lt;a href="#overriding-default-docker-targets">&lt;code>docker-root-repository&lt;/code> value&lt;/a>.
Please log in to the destination repository as needed.&lt;/p>
&lt;p>Upload it to the remote repository:&lt;/p>
&lt;pre>&lt;code>docker push example-repo/beam_python3.6_sdk
&lt;/code>&lt;/pre>&lt;p>To download the image again, run &lt;code>docker pull&lt;/code>:&lt;/p>
&lt;pre>&lt;code>docker pull example-repo/beam_python3.6_sdk
&lt;/code>&lt;/pre>&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: After pushing a container image, the remote image ID and digest match the local image ID and digest.&lt;/p>
&lt;/blockquote></description></item><item><title>Documentation: Count</title><link>/documentation/transforms/java/aggregation/count/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/count/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="count">Count&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/Count.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Counts the number of elements within each aggregation. The &lt;code>Count&lt;/code>
transform has three varieties:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Count.globally()&lt;/code> counts the number of elements in the entire
&lt;code>PCollection&lt;/code>. The result is a collection with a single element.&lt;/li>
&lt;li>&lt;code>Count.perKey()&lt;/code> counts how many elements are associated with each
key. It ignores the values. The resulting collection has one
output for every key in the input collection.&lt;/li>
&lt;li>&lt;code>Count.perElement()&lt;/code> counts how many times each element appears
in the input collection. The output collection is a key-value
pair, containing each unique element and the number of times it
appeared in the original collection.&lt;/li>
&lt;/ul>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7703">BEAM-7703&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/approximateunique">ApproximateUnique&lt;/a>
estimates the number of distinct elements or distinct values in key-value pairs&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/sum">Sum&lt;/a> computes
the sum of elements in a collection&lt;/li>
&lt;/ul></description></item><item><title>Documentation: Count</title><link>/documentation/transforms/python/aggregation/count/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/count/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="count">Count&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.combiners.html#apache_beam.transforms.combiners.Count"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Counts the number of elements within each aggregation.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following example, we create a pipeline with two &lt;code>PCollection&lt;/code>s of produce.
Then, we apply &lt;code>Count&lt;/code> to get the total number of elements in different ways.&lt;/p>
&lt;h3 id="example-1-counting-all-elements-in-a-pcollection">Example 1: Counting all elements in a PCollection&lt;/h3>
&lt;p>We use &lt;code>Count.Globally()&lt;/code> to count &lt;em>all&lt;/em> elements in a &lt;code>PCollection&lt;/code>, even if there are duplicate elements.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">total_elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Count all elements&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">combiners&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Count&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Globally&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>10&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/count.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-2-counting-elements-for-each-key">Example 2: Counting elements for each key&lt;/h3>
&lt;p>We use &lt;code>Count.PerKey()&lt;/code> to count the elements for each unique key in a &lt;code>PCollection&lt;/code> of key-values.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">total_elements_per_keys&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;fall&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;winter&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;fall&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Count elements per key&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">combiners&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Count&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PerKey&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;spring&amp;#39;, 4)
(&amp;#39;summer&amp;#39;, 3)
(&amp;#39;fall&amp;#39;, 2)
(&amp;#39;winter&amp;#39;, 1)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/count.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-3-counting-all-unique-elements">Example 3: Counting all unique elements&lt;/h3>
&lt;p>We use &lt;code>Count.PerElement()&lt;/code> to count the only the unique elements in a &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">total_unique_elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Count unique elements&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">combiners&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Count&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PerElement&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;🍓&amp;#39;, 1)
(&amp;#39;🥕&amp;#39;, 3)
(&amp;#39;🍆&amp;#39;, 2)
(&amp;#39;🍅&amp;#39;, 3)
(&amp;#39;🌽&amp;#39;, 1)&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/count.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;p>N/A&lt;/p>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.combiners.html#apache_beam.transforms.combiners.Count"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: Create</title><link>/documentation/transforms/java/other/create/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/other/create/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="create">Create&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/Create.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Creates a collection containing a specified set of elements. This is useful
for testing, as well as creating an initial input to process in parallel.
For example, a single element to execute a one-time &lt;code>ParDo&lt;/code> or a list of filenames to be read.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7704">BEAM-7704&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;p>N/A&lt;/p></description></item><item><title>Documentation: Create</title><link>/documentation/transforms/python/other/create/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/other/create/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="create">Create&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.Create">
&lt;img src="https://beam.apache.org/images/logos/sdks/python.png" width="20px" height="20px"
alt="Pydoc" />
Pydoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Creates a collection containing a specified set of elements. This is
useful for testing, as well as creating an initial input to process
in parallel. For example, a single element to execute a one-time
&lt;code>ParDo&lt;/code> or a list of filenames to be read.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7391">BEAM-7391&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2></description></item><item><title>Documentation: Create Your Pipeline</title><link>/documentation/pipelines/create-your-pipeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/pipelines/create-your-pipeline/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="create-your-pipeline">Create Your Pipeline&lt;/h1>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#creating-your-pipeline-object">Creating Your Pipeline Object&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reading-data-into-your-pipeline">Reading Data Into Your Pipeline&lt;/a>&lt;/li>
&lt;li>&lt;a href="#applying-transforms-to-process-pipeline-data">Applying Transforms to Process Pipeline Data&lt;/a>&lt;/li>
&lt;li>&lt;a href="#writing-or-outputting-your-final-pipeline-data">Writing or Outputting Your Final Pipeline Data&lt;/a>&lt;/li>
&lt;li>&lt;a href="#running-your-pipeline">Running Your Pipeline&lt;/a>&lt;/li>
&lt;li>&lt;a href="#whats-next">What&amp;rsquo;s next&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;p>Your Beam program expresses a data processing pipeline, from start to finish. This section explains the mechanics of using the classes in the Beam SDKs to build a pipeline. To construct a pipeline using the classes in the Beam SDKs, your program will need to perform the following general steps:&lt;/p>
&lt;ul>
&lt;li>Create a &lt;code>Pipeline&lt;/code> object.&lt;/li>
&lt;li>Use a &lt;strong>Read&lt;/strong> or &lt;strong>Create&lt;/strong> transform to create one or more &lt;code>PCollection&lt;/code>s for your pipeline data.&lt;/li>
&lt;li>Apply &lt;strong>transforms&lt;/strong> to each &lt;code>PCollection&lt;/code>. Transforms can change, filter, group, analyze, or otherwise process the elements in a &lt;code>PCollection&lt;/code>. Each transform creates a new output &lt;code>PCollection&lt;/code>, to which you can apply additional transforms until processing is complete.&lt;/li>
&lt;li>&lt;strong>Write&lt;/strong> or otherwise output the final, transformed &lt;code>PCollection&lt;/code>s.&lt;/li>
&lt;li>&lt;strong>Run&lt;/strong> the pipeline.&lt;/li>
&lt;/ul>
&lt;h2 id="creating-your-pipeline-object">Creating Your Pipeline Object&lt;/h2>
&lt;p>A Beam program often starts by creating a &lt;code>Pipeline&lt;/code> object.&lt;/p>
&lt;p>In the Beam SDKs, each pipeline is represented by an explicit object of type &lt;code>Pipeline&lt;/code>. Each &lt;code>Pipeline&lt;/code> object is an independent entity that encapsulates both the data the pipeline operates over and the transforms that get applied to that data.&lt;/p>
&lt;p>To create a pipeline, declare a &lt;code>Pipeline&lt;/code> object, and pass it some &lt;a href="/documentation/programming-guide#configuring-pipeline-options">configuration options&lt;/a>.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Start by defining the options for the pipeline.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PipelineOptions&lt;/span> &lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PipelineOptionsFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// Then create the pipeline.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">Pipeline&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">options&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="reading-data-into-your-pipeline">Reading Data Into Your Pipeline&lt;/h2>
&lt;p>To create your pipeline&amp;rsquo;s initial &lt;code>PCollection&lt;/code>, you apply a root transform to your pipeline object. A root transform creates a &lt;code>PCollection&lt;/code> from either an external data source or some local data you specify.&lt;/p>
&lt;p>There are two kinds of root transforms in the Beam SDKs: &lt;code>Read&lt;/code> and &lt;code>Create&lt;/code>. &lt;code>Read&lt;/code> transforms read data from an external source, such as a text file or a database table. &lt;code>Create&lt;/code> transforms create a &lt;code>PCollection&lt;/code> from an in-memory &lt;code>java.util.Collection&lt;/code>.&lt;/p>
&lt;p>The following example code shows how to &lt;code>apply&lt;/code> a &lt;code>TextIO.Read&lt;/code> root transform to read data from a text file. The transform is applied to a &lt;code>Pipeline&lt;/code> object &lt;code>p&lt;/code>, and returns a pipeline data set in the form of a &lt;code>PCollection&amp;lt;String&amp;gt;&lt;/code>:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">lines&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;ReadLines&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">from&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gs://some/inputData.txt&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="applying-transforms-to-process-pipeline-data">Applying Transforms to Process Pipeline Data&lt;/h2>
&lt;p>You can manipulate your data using the various &lt;a href="/documentation/programming-guide/#transforms">transforms&lt;/a> provided in the Beam SDKs. To do this, you &lt;strong>apply&lt;/strong> the transforms to your pipeline&amp;rsquo;s &lt;code>PCollection&lt;/code> by calling the &lt;code>apply&lt;/code> method on each &lt;code>PCollection&lt;/code> that you want to process and passing the desired transform object as an argument.&lt;/p>
&lt;p>The following code shows how to &lt;code>apply&lt;/code> a transform to a &lt;code>PCollection&lt;/code> of strings. The transform is a user-defined custom transform that reverses the contents of each string and outputs a new &lt;code>PCollection&lt;/code> containing the reversed strings.&lt;/p>
&lt;p>The input is a &lt;code>PCollection&amp;lt;String&amp;gt;&lt;/code> called &lt;code>words&lt;/code>; the code passes an instance of a &lt;code>PTransform&lt;/code> object called &lt;code>ReverseWords&lt;/code> to &lt;code>apply&lt;/code>, and saves the return value as the &lt;code>PCollection&amp;lt;String&amp;gt;&lt;/code> called &lt;code>reversedWords&lt;/code>.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">reversedWords&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">words&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">ReverseWords&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="writing-or-outputting-your-final-pipeline-data">Writing or Outputting Your Final Pipeline Data&lt;/h2>
&lt;p>Once your pipeline has applied all of its transforms, you&amp;rsquo;ll usually need to output the results. To output your pipeline&amp;rsquo;s final &lt;code>PCollection&lt;/code>s, you apply a &lt;code>Write&lt;/code> transform to that &lt;code>PCollection&lt;/code>. &lt;code>Write&lt;/code> transforms can output the elements of a &lt;code>PCollection&lt;/code> to an external data sink, such as a database table. You can use &lt;code>Write&lt;/code> to output a &lt;code>PCollection&lt;/code> at any time in your pipeline, although you&amp;rsquo;ll typically write out data at the end of your pipeline.&lt;/p>
&lt;p>The following example code shows how to &lt;code>apply&lt;/code> a &lt;code>TextIO.Write&lt;/code> transform to write a &lt;code>PCollection&lt;/code> of &lt;code>String&lt;/code> to a text file:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">filteredWords&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">filteredWords&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;WriteMyFile&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gs://some/outputData.txt&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="running-your-pipeline">Running Your Pipeline&lt;/h2>
&lt;p>Once you have constructed your pipeline, use the &lt;code>run&lt;/code> method to execute the pipeline. Pipelines are executed asynchronously: the program you create sends a specification for your pipeline to a &lt;strong>pipeline runner&lt;/strong>, which then constructs and runs the actual series of pipeline operations.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">run&lt;/span>&lt;span class="o">();&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The &lt;code>run&lt;/code> method is asynchronous. If you&amp;rsquo;d like a blocking execution instead, run your pipeline appending the &lt;code>waitUntilFinish&lt;/code> method:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">run&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">waitUntilFinish&lt;/span>&lt;span class="o">();&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="whats-next">What&amp;rsquo;s next&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/programming-guide">Programming Guide&lt;/a> - Learn the details of creating your pipeline, configuring pipeline options, and applying transforms.&lt;/li>
&lt;li>&lt;a href="/documentation/pipelines/test-your-pipeline">Test your pipeline&lt;/a>.&lt;/li>
&lt;/ul></description></item><item><title>Documentation: Custom I/O patterns</title><link>/documentation/patterns/custom-io/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/patterns/custom-io/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="custom-io-patterns">Custom I/O patterns&lt;/h1>
&lt;p>This page describes common patterns in pipelines with &lt;a href="/documentation/io/developing-io-overview/">custom I/O connectors&lt;/a>. Custom I/O connectors connect pipelines to databases that aren&amp;rsquo;t supported by Beam&amp;rsquo;s &lt;a href="/documentation/io/built-in/">built-in I/O transforms&lt;/a>.&lt;/p>
&lt;nav class="language-switcher">
&lt;strong>Adapt for:&lt;/strong>
&lt;ul>
&lt;li data-type="language-java" class="active">Java SDK&lt;/li>
&lt;li data-type="language-py">Python SDK&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;h2 id="choosing-between-built-in-and-custom-connectors">Choosing between built-in and custom connectors&lt;/h2>
&lt;p>&lt;a href="/documentation/io/built-in/">Built-in I/O connectors&lt;/a> are tested and hardened, so use them whenever possible. Only use custom I/O connectors when:&lt;/p>
&lt;ul>
&lt;li>No built-in options exist&lt;/li>
&lt;li>Your pipeline pulls in a small subset of source data&lt;/li>
&lt;/ul>
&lt;p>For instance, use a custom I/O connector to enrich pipeline elements with a small subset of source data. If you’re processing a sales order and adding information to each purchase, you can use a custom I/O connector to pull the small subset of data into your pipeline (instead of processing the entire source).&lt;/p>
&lt;p>Beam distributes work across many threads, so custom I/O connectors can increase your data source’s load average. You can reduce the load with the &lt;span class="language-java">&lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/transforms/DoFn.StartBundle.html">start&lt;/a>&lt;/span>&lt;span class="language-py">&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html?highlight=bundle#apache_beam.transforms.core.DoFn.start_bundle">start&lt;/a>&lt;/span> and &lt;span class="language-java">&lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/transforms/DoFn.FinishBundle.html">finish&lt;/a>&lt;/span>&lt;span class="language-py">&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html?highlight=bundle#apache_beam.transforms.core.DoFn.finish_bundle">finish&lt;/a>&lt;/span> bundle annotations.&lt;/p></description></item><item><title>Documentation: Custom window patterns</title><link>/documentation/patterns/custom-windows/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/patterns/custom-windows/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="custom-window-patterns">Custom window patterns&lt;/h1>
&lt;p>The samples on this page demonstrate common custom window patterns. You can create custom windows with &lt;a href="/documentation/programming-guide/#provided-windowing-functions">&lt;code>WindowFn&lt;/code> functions&lt;/a>. For more information, see the &lt;a href="/documentation/programming-guide/#windowing">programming guide section on windowing&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Note&lt;/strong>: Custom merging windows isn&amp;rsquo;t supported in Python (with fnapi).&lt;/p>
&lt;h2 id="using-data-to-dynamically-set-session-window-gaps">Using data to dynamically set session window gaps&lt;/h2>
&lt;p>You can modify the &lt;a href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/windowing/SlidingWindows.html">&lt;code>assignWindows&lt;/code>&lt;/a> function to use data-driven gaps, then window incoming data into sessions.&lt;/p>
&lt;p>Access the &lt;code>assignWindows&lt;/code> function through &lt;code>WindowFn.AssignContext.element()&lt;/code>. The original, fixed-duration &lt;code>assignWindows&lt;/code> function is:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="kd">public&lt;/span> &lt;span class="n">Collection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">IntervalWindow&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">assignWindows&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">WindowFn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">AssignContext&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Assign each element into a window from its timestamp until gapDuration in the
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// future. Overlapping windows (representing elements within gapDuration of
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// each other) will be merged.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">IntervalWindow&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timestamp&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">gapDuration&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="creating-data-driven-gaps">Creating data-driven gaps&lt;/h3>
&lt;p>To create data-driven gaps, add the following snippets to the &lt;code>assignWindows&lt;/code> function:&lt;/p>
&lt;ul>
&lt;li>A default value for when the custom gap is not present in the data&lt;/li>
&lt;li>A way to set the attribute from the main pipeline as a method of the custom windows&lt;/li>
&lt;/ul>
&lt;p>For example, the following function assigns each element to a window between the timestamp and &lt;code>gapDuration&lt;/code>:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Collection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">IntervalWindow&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">assignWindows&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AssignContext&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Assign each element into a window from its timestamp until gapDuration in the
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// future. Overlapping windows (representing elements within gapDuration of
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// each other) will be merged.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Duration&lt;/span> &lt;span class="n">dataDrivenGap&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="n">TableRow&lt;/span> &lt;span class="n">message&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">dataDrivenGap&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardSeconds&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">parseLong&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">message&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;gap&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">()));&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">catch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Exception&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">dataDrivenGap&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">gapDuration&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">IntervalWindow&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">timestamp&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">dataDrivenGap&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Then, set the &lt;code>gapDuration&lt;/code> field in a windowing function:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">DynamicSessions&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">WindowFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">TableRow&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">IntervalWindow&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="cm">/** Duration of the gaps between sessions. */&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">Duration&lt;/span> &lt;span class="n">gapDuration&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="cm">/** Creates a {@code DynamicSessions} {@link WindowFn} with the specified gap duration. */&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="nf">DynamicSessions&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span> &lt;span class="n">gapDuration&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">gapDuration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">gapDuration&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="windowing-messages-into-sessions">Windowing messages into sessions&lt;/h3>
&lt;p>After creating data-driven gaps, you can window incoming data into the new, custom sessions.&lt;/p>
&lt;p>First, set the session length to the gap duration:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="cm">/** Creates a {@code DynamicSessions} {@link WindowFn} with the specified gap duration. */&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">DynamicSessions&lt;/span> &lt;span class="nf">withDefaultGapDuration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span> &lt;span class="n">gapDuration&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">DynamicSessions&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">gapDuration&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Lastly, window data into sessions in your pipeline:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;Window into sessions&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">Window&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">TableRow&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">into&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">DynamicSessions&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withDefaultGapDuration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardSeconds&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">10&lt;/span>&lt;span class="o">))));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="example-data-and-windows">Example data and windows&lt;/h3>
&lt;p>The following test data tallies two users&amp;rsquo; scores with and without the &lt;code>gap&lt;/code> attribute:&lt;/p>
&lt;pre>&lt;code>.apply(&amp;quot;Create data&amp;quot;, Create.timestamped(
TimestampedValue.of(&amp;quot;{\&amp;quot;user\&amp;quot;:\&amp;quot;user-1\&amp;quot;,\&amp;quot;score\&amp;quot;:\&amp;quot;12\&amp;quot;,\&amp;quot;gap\&amp;quot;:\&amp;quot;5\&amp;quot;}&amp;quot;, new Instant()),
TimestampedValue.of(&amp;quot;{\&amp;quot;user\&amp;quot;:\&amp;quot;user-2\&amp;quot;,\&amp;quot;score\&amp;quot;:\&amp;quot;4\&amp;quot;}&amp;quot;, new Instant()),
TimestampedValue.of(&amp;quot;{\&amp;quot;user\&amp;quot;:\&amp;quot;user-1\&amp;quot;,\&amp;quot;score\&amp;quot;:\&amp;quot;-3\&amp;quot;,\&amp;quot;gap\&amp;quot;:\&amp;quot;5\&amp;quot;}&amp;quot;, new Instant().plus(2000)),
TimestampedValue.of(&amp;quot;{\&amp;quot;user\&amp;quot;:\&amp;quot;user-1\&amp;quot;,\&amp;quot;score\&amp;quot;:\&amp;quot;2\&amp;quot;,\&amp;quot;gap\&amp;quot;:\&amp;quot;5\&amp;quot;}&amp;quot;, new Instant().plus(9000)),
TimestampedValue.of(&amp;quot;{\&amp;quot;user\&amp;quot;:\&amp;quot;user-1\&amp;quot;,\&amp;quot;score\&amp;quot;:\&amp;quot;7\&amp;quot;,\&amp;quot;gap\&amp;quot;:\&amp;quot;5\&amp;quot;}&amp;quot;, new Instant().plus(12000)),
TimestampedValue.of(&amp;quot;{\&amp;quot;user\&amp;quot;:\&amp;quot;user-2\&amp;quot;,\&amp;quot;score\&amp;quot;:\&amp;quot;10\&amp;quot;}&amp;quot;, new Instant().plus(12000)))
.withCoder(StringUtf8Coder.of()))
&lt;/code>&lt;/pre>&lt;p>The diagram below visualizes the test data:&lt;/p>
&lt;p>&lt;img src="/images/standard-vs-dynamic-sessions.png" alt="Two sets of data and the standard and dynamic sessions with which the data is windowed.">&lt;/p>
&lt;h4 id="standard-sessions">Standard sessions&lt;/h4>
&lt;p>Standard sessions use the following windows and scores:&lt;/p>
&lt;pre>&lt;code>user=user-2, score=4, window=[2019-05-26T13:28:49.122Z..2019-05-26T13:28:59.122Z)
user=user-1, score=18, window=[2019-05-26T13:28:48.582Z..2019-05-26T13:29:12.774Z)
user=user-2, score=10, window=[2019-05-26T13:29:03.367Z..2019-05-26T13:29:13.367Z)
&lt;/code>&lt;/pre>&lt;p>User #1 sees two events separated by 12 seconds. With standard sessions, the gap defaults to 10 seconds; both scores are in different sessions, so the scores aren&amp;rsquo;t added.&lt;/p>
&lt;p>User #2 sees four events, seperated by two, seven, and three seconds, respectively. Since none of the gaps are greater than the default, the four events are in the same standard session and added together (18 points).&lt;/p>
&lt;h4 id="dynamic-sessions">Dynamic sessions&lt;/h4>
&lt;p>The dynamic sessions specify a five-second gap, so they use the following windows and scores:&lt;/p>
&lt;pre>&lt;code>user=user-2, score=4, window=[2019-05-26T14:30:22.969Z..2019-05-26T14:30:32.969Z)
user=user-1, score=9, window=[2019-05-26T14:30:22.429Z..2019-05-26T14:30:30.553Z)
user=user-1, score=9, window=[2019-05-26T14:30:33.276Z..2019-05-26T14:30:41.849Z)
user=user-2, score=10, window=[2019-05-26T14:30:37.357Z..2019-05-26T14:30:47.357Z)
&lt;/code>&lt;/pre>&lt;p>With dynamic sessions, User #2 gets different scores. The third messages arrives seven seconds after the second message, so it&amp;rsquo;s grouped into a different session. The large, 18-point session is split into two 9-point sessions.&lt;/p></description></item><item><title>Documentation: Design Your Pipeline</title><link>/documentation/pipelines/design-your-pipeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/pipelines/design-your-pipeline/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="design-your-pipeline">Design Your Pipeline&lt;/h1>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#what-to-consider-when-designing-your-pipeline">What to consider when designing your pipeline&lt;/a>&lt;/li>
&lt;li>&lt;a href="#a-basic-pipeline">A basic pipeline&lt;/a>&lt;/li>
&lt;li>&lt;a href="#branching-pcollections">Branching PCollections&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#multiple-transforms-process-the-same-pcollection">Multiple transforms process the same PCollection&lt;/a>&lt;/li>
&lt;li>&lt;a href="#a-single-transform-that-produces-multiple-outputs">A single transform that produces multiple outputs&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#merging-pcollections">Merging PCollections&lt;/a>&lt;/li>
&lt;li>&lt;a href="#multiple-sources">Multiple sources&lt;/a>&lt;/li>
&lt;li>&lt;a href="#whats-next">What&amp;rsquo;s next&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;p>This page helps you design your Apache Beam pipeline. It includes information about how to determine your pipeline&amp;rsquo;s structure, how to choose which transforms to apply to your data, and how to determine your input and output methods.&lt;/p>
&lt;p>Before reading this section, it is recommended that you become familiar with the information in the &lt;a href="/documentation/programming-guide">Beam programming guide&lt;/a>.&lt;/p>
&lt;h2 id="what-to-consider-when-designing-your-pipeline">What to consider when designing your pipeline&lt;/h2>
&lt;p>When designing your Beam pipeline, consider a few basic questions:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Where is your input data stored?&lt;/strong> How many sets of input data do you have? This will determine what kinds of &lt;code>Read&lt;/code> transforms you&amp;rsquo;ll need to apply at the start of your pipeline.&lt;/li>
&lt;li>&lt;strong>What does your data look like?&lt;/strong> It might be plaintext, formatted log files, or rows in a database table. Some Beam transforms work exclusively on &lt;code>PCollection&lt;/code>s of key/value pairs; you&amp;rsquo;ll need to determine if and how your data is keyed and how to best represent that in your pipeline&amp;rsquo;s &lt;code>PCollection&lt;/code>(s).&lt;/li>
&lt;li>&lt;strong>What do you want to do with your data?&lt;/strong> The core transforms in the Beam SDKs are general purpose. Knowing how you need to change or manipulate your data will determine how you build core transforms like &lt;a href="/documentation/programming-guide/#pardo">ParDo&lt;/a>, or when you use pre-written transforms included with the Beam SDKs.&lt;/li>
&lt;li>&lt;strong>What does your output data look like, and where should it go?&lt;/strong> This will determine what kinds of &lt;code>Write&lt;/code> transforms you&amp;rsquo;ll need to apply at the end of your pipeline.&lt;/li>
&lt;/ul>
&lt;h2 id="a-basic-pipeline">A basic pipeline&lt;/h2>
&lt;p>The simplest pipelines represent a linear flow of operations, as shown in figure 1.&lt;/p>
&lt;p>&lt;img src="/images/design-your-pipeline-linear.svg" alt="A linear pipeline starts with one input collection, sequentially appliesthree transforms, and ends with one output collection.">&lt;/p>
&lt;p>&lt;em>Figure 1: A linear pipeline.&lt;/em>&lt;/p>
&lt;p>However, your pipeline can be significantly more complex. A pipeline represents a &lt;a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">Directed Acyclic Graph&lt;/a> of steps. It can have multiple input sources, multiple output sinks, and its operations (&lt;code>PTransform&lt;/code>s) can both read and output multiple &lt;code>PCollection&lt;/code>s. The following examples show some of the different shapes your pipeline can take.&lt;/p>
&lt;h2 id="branching-pcollections">Branching PCollections&lt;/h2>
&lt;p>It&amp;rsquo;s important to understand that transforms do not consume &lt;code>PCollection&lt;/code>s; instead, they consider each individual element of a &lt;code>PCollection&lt;/code> and create a new &lt;code>PCollection&lt;/code> as output. This way, you can do different things to different elements in the same &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;h3 id="multiple-transforms-process-the-same-pcollection">Multiple transforms process the same PCollection&lt;/h3>
&lt;p>You can use the same &lt;code>PCollection&lt;/code> as input for multiple transforms without consuming the input or altering it.&lt;/p>
&lt;p>The pipeline in figure 2 is a branching pipeline. The pipeline reads its input (first names represented as strings) from a database table and creates a &lt;code>PCollection&lt;/code> of table rows. Then, the pipeline applies multiple transforms to the &lt;strong>same&lt;/strong> &lt;code>PCollection&lt;/code>. Transform A extracts all the names in that &lt;code>PCollection&lt;/code> that start with the letter &amp;lsquo;A&amp;rsquo;, and Transform B extracts all the names in that &lt;code>PCollection&lt;/code> that start with the letter &amp;lsquo;B&amp;rsquo;. Both transforms A and B have the same input &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>&lt;img src="/images/design-your-pipeline-multiple-pcollections.svg" alt="The pipeline applies two transforms to a single input collection. Eachtransform produces an output collection.">&lt;/p>
&lt;p>&lt;em>Figure 2: A branching pipeline. Two transforms are applied to a single
PCollection of database table rows.&lt;/em>&lt;/p>
&lt;p>The following example code applies two transforms to a single input collection.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">dbRowCollection&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">aCollection&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dbRowCollection&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;aTrans&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;(){&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">if&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">startsWith&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;A&amp;#34;&lt;/span>&lt;span class="o">)){&lt;/span>
&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">bCollection&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dbRowCollection&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;bTrans&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;(){&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">if&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">startsWith&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;B&amp;#34;&lt;/span>&lt;span class="o">)){&lt;/span>
&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="a-single-transform-that-produces-multiple-outputs">A single transform that produces multiple outputs&lt;/h3>
&lt;p>Another way to branch a pipeline is to have a &lt;strong>single&lt;/strong> transform output to multiple &lt;code>PCollection&lt;/code>s by using &lt;a href="/documentation/programming-guide/#additional-outputs">tagged outputs&lt;/a>. Transforms that produce more than one output process each element of the input once, and output to zero or more &lt;code>PCollection&lt;/code>s.&lt;/p>
&lt;p>Figure 3 illustrates the same example described above, but with one transform that produces multiple outputs. Names that start with &amp;lsquo;A&amp;rsquo; are added to the main output &lt;code>PCollection&lt;/code>, and names that start with &amp;lsquo;B&amp;rsquo; are added to an additional output &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>&lt;img src="/images/design-your-pipeline-additional-outputs.svg" alt="The pipeline applies one transform that produces multiple output collections.">&lt;/p>
&lt;p>&lt;em>Figure 3: A pipeline with a transform that outputs multiple PCollections.&lt;/em>&lt;/p>
&lt;p>If we compare the pipelines in figure 2 and figure 3, you can see they perform
the same operation in different ways. The pipeline in figure 2 contains two
transforms that process the elements in the same input &lt;code>PCollection&lt;/code>. One
transform uses the following logic:&lt;/p>
&lt;pre>if (starts with 'A') { outputToPCollectionA }&lt;/pre>
&lt;p>while the other transform uses:&lt;/p>
&lt;pre>if (starts with 'B') { outputToPCollectionB }&lt;/pre>
&lt;p>Because each transform reads the entire input &lt;code>PCollection&lt;/code>, each element in the input &lt;code>PCollection&lt;/code> is processed twice.&lt;/p>
&lt;p>The pipeline in figure 3 performs the same operation in a different way - with only one transform that uses the following logic:&lt;/p>
&lt;pre>if (starts with 'A') { outputToPCollectionA } else if (starts with 'B') { outputToPCollectionB }&lt;/pre>
&lt;p>where each element in the input &lt;code>PCollection&lt;/code> is processed once.&lt;/p>
&lt;p>The following example code applies one transform that processes each element
once and outputs two collections.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Define two TupleTags, one for each output.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">startsWithATag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;(){};&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">startsWithBTag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;(){};&lt;/span>
&lt;span class="n">PCollectionTuple&lt;/span> &lt;span class="n">mixedCollection&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">dbRowCollection&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ParDo&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">processElement&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ProcessContext&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">startsWith&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;A&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Emit to main output, which is the output with tag startsWithATag.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="k">if&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">startsWith&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;B&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Emit to output with tag startsWithBTag.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">startsWithBTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">element&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">})&lt;/span>
&lt;span class="c1">// Specify main output. In this example, it is the output
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// with tag startsWithATag.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withOutputTags&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">startsWithATag&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="c1">// Specify the output with tag startsWithBTag, as a TupleTagList.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">TupleTagList&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">startsWithBTag&lt;/span>&lt;span class="o">)));&lt;/span>
&lt;span class="c1">// Get subset of the output with tag startsWithATag.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">mixedCollection&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">startsWithATag&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(...);&lt;/span>
&lt;span class="c1">// Get subset of the output with tag startsWithBTag.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">mixedCollection&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">startsWithBTag&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(...);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>You can use either mechanism to produce multiple output &lt;code>PCollection&lt;/code>s. However, using additional outputs makes more sense if the transform&amp;rsquo;s computation per element is time-consuming.&lt;/p>
&lt;h2 id="merging-pcollections">Merging PCollections&lt;/h2>
&lt;p>Often, after you&amp;rsquo;ve branched your &lt;code>PCollection&lt;/code> into multiple &lt;code>PCollection&lt;/code>s via multiple transforms, you&amp;rsquo;ll want to merge some or all of those resulting &lt;code>PCollection&lt;/code>s back together. You can do so by using one of the following:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Flatten&lt;/strong> - You can use the &lt;code>Flatten&lt;/code> transform in the Beam SDKs to merge multiple &lt;code>PCollection&lt;/code>s of the &lt;strong>same type&lt;/strong>.&lt;/li>
&lt;li>&lt;strong>Join&lt;/strong> - You can use the &lt;code>CoGroupByKey&lt;/code> transform in the Beam SDK to perform a relational join between two &lt;code>PCollection&lt;/code>s. The &lt;code>PCollection&lt;/code>s must be keyed (i.e. they must be collections of key/value pairs) and they must use the same key type.&lt;/li>
&lt;/ul>
&lt;p>The example in figure 4 is a continuation of the example in figure 2 in &lt;a href="#multiple-transforms-process-the-same-pcollection">the
section above&lt;/a>. After
branching into two &lt;code>PCollection&lt;/code>s, one with names that begin with &amp;lsquo;A&amp;rsquo; and one
with names that begin with &amp;lsquo;B&amp;rsquo;, the pipeline merges the two together into a
single &lt;code>PCollection&lt;/code> that now contains all names that begin with either &amp;lsquo;A&amp;rsquo; or
&amp;lsquo;B&amp;rsquo;. Here, it makes sense to use &lt;code>Flatten&lt;/code> because the &lt;code>PCollection&lt;/code>s being
merged both contain the same type.&lt;/p>
&lt;p>&lt;img src="/images/design-your-pipeline-flatten.svg" alt="The pipeline merges two collections into one collection with the Flatten transform.">&lt;/p>
&lt;p>&lt;em>Figure 4: A pipeline that merges two collections into one collection with the Flatten transform.&lt;/em>&lt;/p>
&lt;p>The following example code applies &lt;code>Flatten&lt;/code> to merge two collections.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">//merge the two PCollections with Flatten
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollectionList&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">collectionList&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PCollectionList&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">aCollection&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">bCollection&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">mergedCollectionWithFlatten&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">collectionList&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Flatten&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">pCollections&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="c1">// continue with the new merged PCollection
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">mergedCollectionWithFlatten&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(...);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="multiple-sources">Multiple sources&lt;/h2>
&lt;p>Your pipeline can read its input from one or more sources. If your pipeline reads from multiple sources and the data from those sources is related, it can be useful to join the inputs together. In the example illustrated in figure 5 below, the pipeline reads names and addresses from a database table, and names and order numbers from a Kafka topic. The pipeline then uses &lt;code>CoGroupByKey&lt;/code> to join this information, where the key is the name; the resulting &lt;code>PCollection&lt;/code> contains all the combinations of names, addresses, and orders.&lt;/p>
&lt;p>&lt;img src="/images/design-your-pipeline-join.svg" alt="The pipeline joins two input collections into one collection with the Join transform.">&lt;/p>
&lt;p>&lt;em>Figure 5: A pipeline that does a relational join of two input collections.&lt;/em>&lt;/p>
&lt;p>The following example code applies &lt;code>Join&lt;/code> to join two input collections.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">userAddress&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JdbcIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()...);&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">userOrder&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">KafkaIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="o">()...);&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">addressTag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;();&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">orderTag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;();&lt;/span>
&lt;span class="c1">// Merge collection values into a CoGbkResult collection.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CoGbkResult&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">joinedCollection&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">KeyedPCollectionTuple&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">addressTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">userAddress&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">orderTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">userOrder&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CoGroupByKey&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">create&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">joinedCollection&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(...);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="whats-next">What&amp;rsquo;s next&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/pipelines/create-your-pipeline">Create your own pipeline&lt;/a>.&lt;/li>
&lt;li>&lt;a href="/documentation/pipelines/test-your-pipeline">Test your pipeline&lt;/a>.&lt;/li>
&lt;/ul></description></item><item><title>Documentation: Distinct</title><link>/documentation/transforms/java/aggregation/distinct/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/distinct/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="distinct">Distinct&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/Distinct.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Produces a collection containing distinct elements of the input collection.&lt;/p>
&lt;p>On some data sets, it might be more efficient to compute an approximate
answer using &lt;code>ApproximateUnique&lt;/code>, which also allows for determining distinct
values for each key.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7703">BEAM-7703&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/count">Count&lt;/a>
counts the number of elements within each aggregation.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/approximateunique">ApproximateUnique&lt;/a>
estimates the number of distinct elements in a collection.&lt;/li>
&lt;/ul></description></item><item><title>Documentation: Distinct</title><link>/documentation/transforms/python/aggregation/distinct/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/distinct/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="distinct">Distinct&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html#apache_beam.transforms.util.Distinct"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Produces a collection containing distinct elements of the input collection.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following example, we create a pipeline with two &lt;code>PCollection&lt;/code>s of produce.&lt;/p>
&lt;p>We use &lt;code>Distinct&lt;/code> to get rid of duplicate elements, which outputs a &lt;code>PCollection&lt;/code> of all the unique elements.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">unique_elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Deduplicate elements&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Distinct&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>🥕
🍆
🍅&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/distinct.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/count">Count&lt;/a> counts the number of elements within each aggregation.&lt;/li>
&lt;/ul>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html#apache_beam.transforms.util.Distinct"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: Execution model</title><link>/documentation/runtime/model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/runtime/model/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="execution-model">Execution model&lt;/h1>
&lt;p>The Beam model allows runners to execute your pipeline in different ways. You
may observe various effects as a result of the runner’s choices. This page
describes these effects so you can better understand how Beam pipelines execute.&lt;/p>
&lt;h2 id="processing-of-elements">Processing of elements&lt;/h2>
&lt;p>The serialization and communication of elements between machines is one of the
most expensive operations in a distributed execution of your pipeline. Avoiding
this serialization may require re-processing elements after failures or may
limit the distribution of output to other machines.&lt;/p>
&lt;h3 id="serialization-and-communication">Serialization and communication&lt;/h3>
&lt;p>The runner might serialize elements between machines for communication purposes
and for other reasons such as persistence.&lt;/p>
&lt;p>A runner may decide to transfer elements between transforms in a variety of
ways, such as:&lt;/p>
&lt;ul>
&lt;li>Routing elements to a worker for processing as part of a grouping operation.
This may involve serializing elements and grouping or sorting them by their
key.&lt;/li>
&lt;li>Redistributing elements between workers to adjust parallelism. This may
involve serializing elements and communicating them to other workers.&lt;/li>
&lt;li>Using the elements in a side input to a &lt;code>ParDo&lt;/code>. This may require
serializing the elements and broadcasting them to all the workers executing
the &lt;code>ParDo&lt;/code>.&lt;/li>
&lt;li>Passing elements between transforms that are running on the same worker.
This may allow the runner to avoid serializing elements; instead, the runner
can just pass the elements in memory.&lt;/li>
&lt;/ul>
&lt;p>Some situations where the runner may serialize and persist elements are:&lt;/p>
&lt;ol>
&lt;li>When used as part of a stateful &lt;code>DoFn&lt;/code>, the runner may persist values to some
state mechanism.&lt;/li>
&lt;li>When committing the results of processing, the runner may persist the outputs
as a checkpoint.&lt;/li>
&lt;/ol>
&lt;h3 id="bundling-and-persistence">Bundling and persistence&lt;/h3>
&lt;p>Beam pipelines often focus on &amp;ldquo;&lt;a href="https://en.wikipedia.org/wiki/embarrassingly_parallel">embarassingly parallel&lt;/a>&amp;rdquo;
problems. Because of this, the APIs emphasize processing elements in parallel,
which makes it difficult to express actions like &amp;ldquo;assign a sequence number to
each element in a PCollection&amp;rdquo;. This is intentional as such algorithms are much
more likely to suffer from scalability problems.&lt;/p>
&lt;p>Processing all elements in parallel also has some drawbacks. Specifically, it
makes it impossible to batch any operations, such as writing elements to a sink
or checkpointing progress during processing.&lt;/p>
&lt;p>Instead of processing all elements simultaneously, the elements in a
&lt;code>PCollection&lt;/code> are processed in &lt;em>bundles&lt;/em>. The division of the collection into
bundles is arbitrary and selected by the runner. This allows the runner to
choose an appropriate middle-ground between persisting results after every
element, and having to retry everything if there is a failure. For example, a
streaming runner may prefer to process and commit small bundles, and a batch
runner may prefer to process larger bundles.&lt;/p>
&lt;h2 id="parallelism">Failures and parallelism within and between transforms&lt;/h2>
&lt;p>In this section, we discuss how elements in the input collection are processed
in parallel, and how transforms are retried when failures occur.&lt;/p>
&lt;h3 id="data-parallelism">Data-parallelism within one transform&lt;/h3>
&lt;p>When executing a single &lt;code>ParDo&lt;/code>, a runner might divide an example input
collection of nine elements into two bundles as shown in figure 1.&lt;/p>
&lt;p>&lt;img src="/images/execution_model_bundling.svg" alt="Bundle A contains five elements. Bundle B contains four elements.">&lt;/p>
&lt;p>&lt;em>Figure 1: A runner divides an input collection into two bundles.&lt;/em>&lt;/p>
&lt;p>When the &lt;code>ParDo&lt;/code> executes, workers may process the two bundles in parallel as
shown in figure 2.&lt;/p>
&lt;p>&lt;img src="/images/execution_model_bundling_gantt.svg" alt="Two workers process the two bundles in parallel. Worker one processes bundle A. Worker two processes bundle B.">&lt;/p>
&lt;p>&lt;em>Figure 2: Two workers process the two bundles in parallel.&lt;/em>&lt;/p>
&lt;p>Since elements cannot be split, the maximum parallelism for a transform depends
on the number of elements in the collection. In figure 3, the input collection
has nine elements, so the maximum parallelism is nine.&lt;/p>
&lt;p>&lt;img src="/images/execution_model_bundling_gantt_max.svg" alt="Nine workers process a nine element input collection in parallel.">&lt;/p>
&lt;p>&lt;em>Figure 3: Nine workers process a nine element input collection in parallel.&lt;/em>&lt;/p>
&lt;p>Note: Splittable ParDo allows splitting the processing of a single input across
multiple bundles. This feature is a work in progress.&lt;/p>
&lt;h3 id="dependent-parallellism">Dependent-parallelism between transforms&lt;/h3>
&lt;p>&lt;code>ParDo&lt;/code> transforms that are in sequence may be &lt;em>dependently parallel&lt;/em> if the
runner chooses to execute the consuming transform on the producing transform&amp;rsquo;s
output elements without altering the bundling. In figure 4, &lt;code>ParDo1&lt;/code> and
&lt;code>ParDo2&lt;/code> are &lt;em>dependently parallel&lt;/em> if the output of &lt;code>ParDo1&lt;/code> for a given
element must be processed on the same worker.&lt;/p>
&lt;p>&lt;img src="/images/execution_model_bundling_multi.svg" alt="ParDo1 processes an input collection that contains bundles A and B. ParDo2 then processes the output collection from ParDo1, which contains bundles C and D.">&lt;/p>
&lt;p>&lt;em>Figure 4: Two transforms in sequence and their corresponding input collections.&lt;/em>&lt;/p>
&lt;p>Figure 5 shows how these dependently parallel transforms might execute. The
first worker executes &lt;code>ParDo1&lt;/code> on the elements in bundle A (which results in
bundle C), and then executes &lt;code>ParDo2&lt;/code> on the elements in bundle C. Similarly,
the second worker executes &lt;code>ParDo1&lt;/code> on the elements in bundle B (which results
in bundle D), and then executes &lt;code>ParDo2&lt;/code> on the elements in bundle D.&lt;/p>
&lt;p>&lt;img src="/images/execution_model_bundling_multi_gantt.svg" alt="Worker one executes ParDo1 on bundle A and Pardo2 on bundle C. Worker two executes ParDo1 on bundle B and ParDo2 on bundle D.">&lt;/p>
&lt;p>&lt;em>Figure 5: Two workers execute dependently parallel ParDo transforms.&lt;/em>&lt;/p>
&lt;p>Executing transforms this way allows a runner to avoid redistributing elements
between workers, which saves on communication costs. However, the maximum parallelism
now depends on the maximum parallelism of the first of the dependently parallel
steps.&lt;/p>
&lt;h3 id="failures-within-one-transform">Failures within one transform&lt;/h3>
&lt;p>If processing of an element within a bundle fails, the entire bundle fails. The
elements in the bundle must be retried (otherwise the entire pipeline fails),
although they do not need to be retried with the same bundling.&lt;/p>
&lt;p>For this example, we will use the &lt;code>ParDo&lt;/code> from figure 1 that has an input
collection with nine elements and is divided into two bundles.&lt;/p>
&lt;p>In figure 6, the first worker successfully processes all five elements in bundle
A. The second worker processes the four elements in bundle B: the first two
elements were successfully processed, the third element’s processing failed, and
there is one element still awaiting processing.&lt;/p>
&lt;p>We see that the runner retries all elements in bundle B and the processing
completes successfully the second time. Note that the retry does not necessarily
happen on the same worker as the original processing attempt, as shown in the
figure.&lt;/p>
&lt;p>&lt;img src="/images/execution_model_failure_retry.svg" alt="Worker two fails to process an element in bundle B. Worker one finishes processing bundle A and then successfully retries to execute bundle B.">&lt;/p>
&lt;p>&lt;em>Figure 6: The processing of an element within bundle B fails, and another worker
retries the entire bundle.&lt;/em>&lt;/p>
&lt;p>Because we encountered a failure while processing an element in the input
bundle, we had to reprocess &lt;em>all&lt;/em> of the elements in the input bundle. This means
the runner must throw away the entire output of the bundle (including any state
mutations and set timers) since all of the results it contains will be recomputed.&lt;/p>
&lt;p>Note that if the failed transform is a &lt;code>ParDo&lt;/code>, then the &lt;code>DoFn&lt;/code> instance is torn
down and abandoned.&lt;/p>
&lt;h3 id="coupled-failure">Coupled failure: Failures between transforms&lt;/h3>
&lt;p>If a failure to process an element in &lt;code>ParDo2&lt;/code> causes &lt;code>ParDo1&lt;/code> to re-execute,
these two steps are said to be &lt;em>co-failing&lt;/em>.&lt;/p>
&lt;p>For this example, we will use the two &lt;code>ParDo&lt;/code>s from figure 4.&lt;/p>
&lt;p>In figure 7, worker two successfully executes &lt;code>ParDo1&lt;/code> on all elements in bundle
B. However, the worker fails to process an element in bundle D, so &lt;code>ParDo2&lt;/code>
fails (shown as the red X). As a result, the runner must discard and recompute
the output of &lt;code>ParDo2&lt;/code>. Because the runner was executing &lt;code>ParDo1&lt;/code> and &lt;code>ParDo2&lt;/code>
together, the output bundle from &lt;code>ParDo1&lt;/code> must also be thrown away, and all
elements in the input bundle must be retried. These two &lt;code>ParDo&lt;/code>s are co-failing.&lt;/p>
&lt;p>&lt;img src="/images/execution_model_bundling_coupled_failure.svg" alt="Worker two fails to process en element in bundle D, so all elements in both bundle B and bundle D must be retried.">&lt;/p>
&lt;p>&lt;em>Figure 7: Processing of an element within bundle D fails, so all elements in
the input bundle are retried.&lt;/em>&lt;/p>
&lt;p>Note that the retry does not necessarily have the same processing time as the
original attempt, as shown in the diagram.&lt;/p>
&lt;p>All &lt;code>DoFns&lt;/code> that experience coupled failures are terminated and must be torn
down since they aren’t following the normal &lt;code>DoFn&lt;/code> lifecycle .&lt;/p>
&lt;p>Executing transforms this way allows a runner to avoid persisting elements
between transforms, saving on persistence costs.&lt;/p></description></item><item><title>Documentation: File processing patterns</title><link>/documentation/patterns/file-processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/patterns/file-processing/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="file-processing-patterns">File processing patterns&lt;/h1>
&lt;p>This page describes common file processing tasks. For more information on file-based I/O, see &lt;a href="/documentation/programming-guide/#pipeline-io">Pipeline I/O&lt;/a> and &lt;a href="/documentation/programming-guide/#file-based-data">File-based input and output data&lt;/a>.&lt;/p>
&lt;nav class="language-switcher">
&lt;strong>Adapt for:&lt;/strong>
&lt;ul>
&lt;li data-type="language-java" class="active">Java SDK&lt;/li>
&lt;li data-type="language-py">Python SDK&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;h2 id="processing-files-as-they-arrive">Processing files as they arrive&lt;/h2>
&lt;p>This section shows you how to process files as they arrive in your file system or object store (like Google Cloud Storage). You can continuously read files or trigger stream and processing pipelines when a file arrives.&lt;/p>
&lt;h3 id="continuous-read-mode">Continuous read mode&lt;/h3>
&lt;p class="language-java">You can use &lt;code>FileIO&lt;/code> or &lt;code>TextIO&lt;/code> to continuously read the source for new files.&lt;/p>
&lt;p class="language-java">Use the &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/FileIO.html">&lt;code>FileIO&lt;/code>&lt;/a> class to continuously watch a single file pattern. The following example matches a file pattern repeatedly every 30 seconds, continuously returns new matched files as an unbounded &lt;code>PCollection&amp;lt;Metadata&amp;gt;&lt;/code>, and stops if no new files appear for one hour:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// This produces PCollection&amp;lt;MatchResult.Metadata&amp;gt;
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">FileIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">match&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">filepattern&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;...&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">continuously&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardSeconds&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">30&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="n">Watch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Growth&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">afterTimeSinceNewOutput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardHours&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">))));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">The &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/TextIO.html">&lt;code>TextIO&lt;/code>&lt;/a> class &lt;code>watchForNewFiles&lt;/code> property streams new file matches.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// This produces PCollection&amp;lt;String&amp;gt;
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">TextIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">from&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;&amp;lt;path-to-files&amp;gt;/*&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">watchForNewFiles&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="c1">// Check for new files every minute.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardMinutes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="c1">// Stop watching the file pattern if no new files appear for an hour.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Watch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Growth&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">afterTimeSinceNewOutput&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Duration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">standardHours&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">))));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">Some runners may retain file lists during updates, but file lists don’t persist when you restart a pipeline. You can save file lists by:&lt;/p>
&lt;p class="language-java">&lt;ul>
&lt;li>Storing processed filenames in an external file and deduplicating the lists at the next transform&lt;/li>
&lt;li>Adding timestamps to filenames, writing a glob pattern to pull in only new files, and matching the pattern when the pipeline restarts&lt;/li>
&lt;/ul>&lt;/p>
&lt;p class="language-py">The continuous-read option is not available for Python.&lt;/p>
&lt;h3 id="stream-processing-triggered-from-external-source">Stream processing triggered from external source&lt;/h3>
&lt;p>A streaming pipeline can process data from an unbounded source. For example, to trigger stream processing with Google Cloud Pub/Sub:&lt;/p>
&lt;ol>
&lt;li>Use an external process to detect when new files arrive.&lt;/li>
&lt;li>Send a Google Cloud Pub/Sub message with a URI to the file.&lt;/li>
&lt;li>Access the URI from a &lt;code>DoFn&lt;/code> that follows the Google Cloud Pub/Sub source.&lt;/li>
&lt;li>Process the file.&lt;/li>
&lt;/ol>
&lt;h3 id="batch-processing-triggered-from-external-source">Batch processing triggered from external source&lt;/h3>
&lt;p>To start or schedule a batch pipeline job when a file arrives, write the triggering event in the source file itself. This has the most latency because the pipeline must initialize before processing. It’s best suited for low-frequency, large, file-size updates.&lt;/p>
&lt;h2 id="accessing-filenames">Accessing filenames&lt;/h2>
&lt;p class="language-java">Use the &lt;code>FileIO&lt;/code> class to read filenames in a pipeline job. &lt;code>FileIO&lt;/code> returns a &lt;code>PCollection&amp;lt;ReadableFile&amp;gt;&lt;/code> object, and the &lt;code>ReadableFile&lt;/code> instance contains the filename.&lt;/p>
&lt;p class="language-java">To access filenames:&lt;/p>
&lt;p class="language-java">&lt;ol>
&lt;li>Create a &lt;code>ReadableFile&lt;/code> instance with &lt;code>FileIO&lt;/code>. &lt;code>FileIO&lt;/code> returns a &lt;code>PCollection&amp;lt;ReadableFile&amp;gt;&lt;/code> object. The &lt;code>ReadableFile&lt;/code> class contains the filename.&lt;/li>
&lt;li>Call the &lt;code>readFullyAsUTF8String()&lt;/code> method to read the file into memory and return the filename as a &lt;code>String&lt;/code> object. If memory is limited, you can use utility classes like &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/FileSystems.html">&lt;code>FileSystems&lt;/code>&lt;/a> to work directly with the file.&lt;/li>
&lt;/ol>&lt;/p>
&lt;p class="language-py">To read filenames in a pipeline job:&lt;/p>
&lt;p class="language-py">&lt;ol>
&lt;li>Collect the list of file URIs. You can use the &lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.filesystems.html?highlight=filesystems#module-apache_beam.io.filesystems">&lt;code>FileSystems&lt;/code>&lt;/a> module to get a list of files that match a glob pattern.&lt;/li>
&lt;li>Pass the file URIs to a &lt;code>PCollection&lt;/code>.&lt;/li>
&lt;/ol>&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">FileIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">match&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">filepattern&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hdfs://path/to/*.gz&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="c1">// The withCompression method is optional. By default, the Beam SDK detects compression from
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// the filename.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">FileIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">readMatches&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">withCompression&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Compression&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">GZIP&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">ParDo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">DoFn&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">FileIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">ReadableFile&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@ProcessElement&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">process&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Element&lt;/span> &lt;span class="n">FileIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">ReadableFile&lt;/span> &lt;span class="n">file&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// We can now access the file and its metadata.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">LOG&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">info&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;File Metadata resourceId is {} &amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMetadata&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">resourceId&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">readable_files&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">fileio&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MatchFiles&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;hdfs://path/to/*.txt&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">fileio&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ReadMatches&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Reshuffle&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="n">files_and_contents&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">readable_files&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metadata&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read_utf8&lt;/span>&lt;span class="p">())))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div></description></item><item><title>Documentation: Filter</title><link>/documentation/transforms/java/elementwise/filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/elementwise/filter/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="filter">Filter&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/Filter.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Given a predicate, filter out all elements that don&amp;rsquo;t satisfy that predicate.
May also be used to filter based on an inequality with a given value based
on the natural ordering of the element.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>&lt;strong>Example 1&lt;/strong>: Filtering with a predicate&lt;/p>
&lt;p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">allStrings&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Hello&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;world&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;hi&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">longStrings&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">allStrings&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Filter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">by&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">SerializableFunction&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Boolean&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Boolean&lt;/span> &lt;span class="nf">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">length&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">3&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
The result is a &lt;code>PCollection&lt;/code> containing &amp;ldquo;Hello&amp;rdquo; and &amp;ldquo;world&amp;rdquo;.&lt;/p>
&lt;p>&lt;strong>Example 2&lt;/strong>: Filtering with an inequality&lt;/p>
&lt;p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">numbers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1L&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">2L&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">3L&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">4L&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">5L&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">bigNumbers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">numbers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Filter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">greaterThan&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">3&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">smallNumbers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">numbers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Filter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">lessThanEq&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">3&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
Other variants include &lt;code>Filter.greaterThanEq&lt;/code>, &lt;code>Filter.lessThan&lt;/code> and &lt;code>Filter.equal&lt;/code>.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/elementwise/flatmapelements">FlatMapElements&lt;/a> behaves the same as &lt;code>Map&lt;/code>, but for
each input it might produce zero or more outputs.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/elementwise/pardo">ParDo&lt;/a> is the most general element-wise mapping
operation, and includes other abilities such as multiple output collections and side-inputs.&lt;/li>
&lt;/ul></description></item><item><title>Documentation: Filter</title><link>/documentation/transforms/python/elementwise/filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/elementwise/filter/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="filter">Filter&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.Filter"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Given a predicate, filter out all elements that don&amp;rsquo;t satisfy that predicate.
May also be used to filter based on an inequality with a given value based
on the comparison ordering of the element.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following examples, we create a pipeline with a &lt;code>PCollection&lt;/code> of produce with their icon, name, and duration.
Then, we apply &lt;code>Filter&lt;/code> in multiple ways to filter out produce by their duration value.&lt;/p>
&lt;p>&lt;code>Filter&lt;/code> accepts a function that keeps elements that return &lt;code>True&lt;/code>, and filters out the remaining elements.&lt;/p>
&lt;h3 id="example-1-filtering-with-a-function">Example 1: Filtering with a function&lt;/h3>
&lt;p>We define a function &lt;code>is_perennial&lt;/code> which returns &lt;code>True&lt;/code> if the element&amp;rsquo;s duration equals &lt;code>'perennial'&lt;/code>, and &lt;code>False&lt;/code> otherwise.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">is_perennial&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">plant&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">perennials&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Filter perennials&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Filter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">is_perennial&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;icon&amp;#39;: &amp;#39;🍓&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Strawberry&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍆&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Eggplant&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🥔&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Potato&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/filter-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/filter.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-2-filtering-with-a-lambda-function">Example 2: Filtering with a lambda function&lt;/h3>
&lt;p>We can also use lambda functions to simplify &lt;strong>Example 1&lt;/strong>.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">perennials&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Filter perennials&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Filter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;icon&amp;#39;: &amp;#39;🍓&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Strawberry&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍆&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Eggplant&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🥔&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Potato&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/filter-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/filter.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-3-filtering-with-multiple-arguments">Example 3: Filtering with multiple arguments&lt;/h3>
&lt;p>You can pass functions with multiple arguments to &lt;code>Filter&lt;/code>.
They are passed as additional positional arguments or keyword arguments to the function.&lt;/p>
&lt;p>In this example, &lt;code>has_duration&lt;/code> takes &lt;code>plant&lt;/code> and &lt;code>duration&lt;/code> as arguments.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">has_duration&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">plant&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">duration&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">duration&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">perennials&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Filter perennials&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Filter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">has_duration&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;icon&amp;#39;: &amp;#39;🍓&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Strawberry&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍆&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Eggplant&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🥔&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Potato&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/filter-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/filter.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-4-filtering-with-side-inputs-as-singletons">Example 4: Filtering with side inputs as singletons&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has a single value, such as the average from another computation,
passing the &lt;code>PCollection&lt;/code> as a &lt;em>singleton&lt;/em> accesses that value.&lt;/p>
&lt;p>In this example, we pass a &lt;code>PCollection&lt;/code> the value &lt;code>'perennial'&lt;/code> as a singleton.
We then use that value to filter out perennials.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">perennial&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Perennial&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">perennials&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Filter perennials&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Filter&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">duration&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">duration&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">duration&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsSingleton&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">perennial&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;icon&amp;#39;: &amp;#39;🍓&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Strawberry&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍆&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Eggplant&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🥔&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Potato&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/filter-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/filter.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-5-filtering-with-side-inputs-as-iterators">Example 5: Filtering with side inputs as iterators&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has multiple values, pass the &lt;code>PCollection&lt;/code> as an &lt;em>iterator&lt;/em>.
This accesses elements lazily as they are needed,
so it is possible to iterate over large &lt;code>PCollection&lt;/code>s that won&amp;rsquo;t fit into memory.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">valid_durations&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Valid durations&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="n">valid_plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;PERENNIAL&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Filter valid plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Filter&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">valid_durations&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">valid_durations&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">valid_durations&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsIter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">valid_durations&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;icon&amp;#39;: &amp;#39;🍓&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Strawberry&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🥕&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Carrot&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;biennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍆&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Eggplant&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍅&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Tomato&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;annual&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/filter-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/filter.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: You can pass the &lt;code>PCollection&lt;/code> as a &lt;em>list&lt;/em> with &lt;code>beam.pvalue.AsList(pcollection)&lt;/code>,
but this requires that all the elements fit into memory.&lt;/p>
&lt;/blockquote>
&lt;h3 id="example-6-filtering-with-side-inputs-as-dictionaries">Example 6: Filtering with side inputs as dictionaries&lt;/h3>
&lt;p>If a &lt;code>PCollection&lt;/code> is small enough to fit into memory, then that &lt;code>PCollection&lt;/code> can be passed as a &lt;em>dictionary&lt;/em>.
Each element must be a &lt;code>(key, value)&lt;/code> pair.
Note that all the elements of the &lt;code>PCollection&lt;/code> must fit into memory for this.
If the &lt;code>PCollection&lt;/code> won&amp;rsquo;t fit into memory, use &lt;code>beam.pvalue.AsIter(pcollection)&lt;/code> instead.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">keep_duration&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Duration filters&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">False&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">False&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">True&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="n">perennials&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Filter plants by duration&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Filter&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">keep_duration&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">keep_duration&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]],&lt;/span>
&lt;span class="n">keep_duration&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsDict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">keep_duration&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;icon&amp;#39;: &amp;#39;🍓&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Strawberry&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍆&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Eggplant&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🥔&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Potato&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/filter-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/filter.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/elementwise/flatmap">FlatMap&lt;/a> behaves the same as &lt;code>Map&lt;/code>, but for
each input it might produce zero or more outputs.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/elementwise/pardo">ParDo&lt;/a> is the most general elementwise mapping
operation, and includes other abilities such as multiple output collections and side-inputs.&lt;/li>
&lt;/ul>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.Filter"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: FlatMap</title><link>/documentation/transforms/python/elementwise/flatmap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/elementwise/flatmap/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="flatmap">FlatMap&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.FlatMap"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Applies a simple 1-to-many mapping function over each element in the collection.
The many elements are flattened into the resulting collection.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following examples, we create a pipeline with a &lt;code>PCollection&lt;/code> of produce with their icon, name, and duration.
Then, we apply &lt;code>FlatMap&lt;/code> in multiple ways to yield zero or more elements per each input element into the resulting &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>&lt;code>FlatMap&lt;/code> accepts a function that returns an &lt;code>iterable&lt;/code>,
where each of the output &lt;code>iterable&lt;/code>'s elements is an element of the resulting &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;h3 id="example-1-flatmap-with-a-predefined-function">Example 1: FlatMap with a predefined function&lt;/h3>
&lt;p>We use the function &lt;code>str.split&lt;/code> which takes a single &lt;code>str&lt;/code> element and outputs a &lt;code>list&lt;/code> of &lt;code>str&lt;/code>s.
This pipeline splits the input element using whitespaces, creating a list of zero or more elements.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="s1">&amp;#39;🍓Strawberry 🥕Carrot 🍆Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;🍅Tomato 🥔Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Split words&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>🍓Strawberry
🥕Carrot
🍆Eggplant
🍅Tomato
🥔Potato&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/flatmap-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/flatmap.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-2-flatmap-with-a-function">Example 2: FlatMap with a function&lt;/h3>
&lt;p>We define a function &lt;code>split_words&lt;/code> which splits an input &lt;code>str&lt;/code> element using the delimiter &lt;code>','&lt;/code> and outputs a &lt;code>list&lt;/code> of &lt;code>str&lt;/code>s.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">split_words&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;,&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="s1">&amp;#39;🍓Strawberry,🥕Carrot,🍆Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;🍅Tomato,🥔Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Split words&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">split_words&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>🍓Strawberry
🥕Carrot
🍆Eggplant
🍅Tomato
🥔Potato&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/flatmap-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/flatmap.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-3-flatmap-with-a-lambda-function">Example 3: FlatMap with a lambda function&lt;/h3>
&lt;p>For this example, we want to flatten a &lt;code>PCollection&lt;/code> of lists of &lt;code>str&lt;/code>s into a &lt;code>PCollection&lt;/code> of &lt;code>str&lt;/code>s.
Each input element is already an &lt;code>iterable&lt;/code>, where each element is what we want in the resulting &lt;code>PCollection&lt;/code>.
We use a lambda function that returns the same input element it received.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🍓Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆Eggplant&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🍅Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥔Potato&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Flatten lists&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">elements&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">elements&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>🍓Strawberry
🥕Carrot
🍆Eggplant
🍅Tomato
🥔Potato&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/flatmap-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/flatmap.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-4-flatmap-with-a-generator">Example 4: FlatMap with a generator&lt;/h3>
&lt;p>For this example, we want to flatten a &lt;code>PCollection&lt;/code> of lists of &lt;code>str&lt;/code>s into a &lt;code>PCollection&lt;/code> of &lt;code>str&lt;/code>s.
We use a generator to iterate over the input list and yield each of the elements.
Each yielded result in the generator is an element in the resulting &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">generate_elements&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">elements&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">element&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">elements&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">element&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🍓Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆Eggplant&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;🍅Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥔Potato&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Flatten lists&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">generate_elements&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>🍓Strawberry
🥕Carrot
🍆Eggplant
🍅Tomato
🥔Potato&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/flatmap-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/flatmap.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-5-flatmaptuple-for-key-value-pairs">Example 5: FlatMapTuple for key-value pairs&lt;/h3>
&lt;p>If your &lt;code>PCollection&lt;/code> consists of &lt;code>(key, value)&lt;/code> pairs,
you can use &lt;code>FlatMapTuple&lt;/code> to unpack them into different function arguments.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">format_plant&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">icon&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">icon&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="s1">&amp;#39;{}{}&amp;#39;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">format&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">icon&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Strawberry&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Potato&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="bp">None&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Invalid&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Format&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMapTuple&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">format_plant&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>🍓Strawberry
🥕Carrot
🍆Eggplant
🍅Tomato
🥔Potato&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/flatmap-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/flatmap.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-6-flatmap-with-multiple-arguments">Example 6: FlatMap with multiple arguments&lt;/h3>
&lt;p>You can pass functions with multiple arguments to &lt;code>FlatMap&lt;/code>.
They are passed as additional positional arguments or keyword arguments to the function.&lt;/p>
&lt;p>In this example, &lt;code>split_words&lt;/code> takes &lt;code>text&lt;/code> and &lt;code>delimiter&lt;/code> as arguments.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">split_words&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">delimiter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">None&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">delimiter&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="s1">&amp;#39;🍓Strawberry,🥕Carrot,🍆Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;🍅Tomato,🥔Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Split words&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">split_words&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">delimiter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;,&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>🍓Strawberry
🥕Carrot
🍆Eggplant
🍅Tomato
🥔Potato&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/flatmap-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/flatmap.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-7-flatmap-with-side-inputs-as-singletons">Example 7: FlatMap with side inputs as singletons&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has a single value, such as the average from another computation,
passing the &lt;code>PCollection&lt;/code> as a &lt;em>singleton&lt;/em> accesses that value.&lt;/p>
&lt;p>In this example, we pass a &lt;code>PCollection&lt;/code> the value &lt;code>','&lt;/code> as a singleton.
We then use that value as the delimiter for the &lt;code>str.split&lt;/code> method.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">delimiter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create delimiter&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="s1">&amp;#39;,&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="n">plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="s1">&amp;#39;🍓Strawberry,🥕Carrot,🍆Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;🍅Tomato,🥔Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Split words&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="k">lambda&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">delimiter&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">delimiter&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">delimiter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsSingleton&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">delimiter&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>🍓Strawberry
🥕Carrot
🍆Eggplant
🍅Tomato
🥔Potato&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/flatmap-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/flatmap.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h3 id="example-8-flatmap-with-side-inputs-as-iterators">Example 8: FlatMap with side inputs as iterators&lt;/h3>
&lt;p>If the &lt;code>PCollection&lt;/code> has multiple values, pass the &lt;code>PCollection&lt;/code> as an &lt;em>iterator&lt;/em>.
This accesses elements lazily as they are needed,
so it is possible to iterate over large &lt;code>PCollection&lt;/code>s that won&amp;rsquo;t fit into memory.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">normalize_and_validate_durations&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">plant&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">valid_durations&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">valid_durations&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">plant&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">valid_durations&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Valid durations&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="n">valid_plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;BIENNIAL&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;unknown&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Normalize and validate durations&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">normalize_and_validate_durations&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">valid_durations&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsIter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">valid_durations&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;icon&amp;#39;: &amp;#39;🍓&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Strawberry&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🥕&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Carrot&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;biennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍆&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Eggplant&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍅&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Tomato&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;annual&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/flatmap-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/flatmap.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: You can pass the &lt;code>PCollection&lt;/code> as a &lt;em>list&lt;/em> with &lt;code>beam.pvalue.AsList(pcollection)&lt;/code>,
but this requires that all the elements fit into memory.&lt;/p>
&lt;/blockquote>
&lt;h3 id="example-9-flatmap-with-side-inputs-as-dictionaries">Example 9: FlatMap with side inputs as dictionaries&lt;/h3>
&lt;p>If a &lt;code>PCollection&lt;/code> is small enough to fit into memory, then that &lt;code>PCollection&lt;/code> can be passed as a &lt;em>dictionary&lt;/em>.
Each element must be a &lt;code>(key, value)&lt;/code> pair.
Note that all the elements of the &lt;code>PCollection&lt;/code> must fit into memory for this.
If the &lt;code>PCollection&lt;/code> won&amp;rsquo;t fit into memory, use &lt;code>beam.pvalue.AsIter(pcollection)&lt;/code> instead.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">replace_duration_if_valid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">plant&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">durations&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">durations&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">durations&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">plant&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;span class="k">yield&lt;/span> &lt;span class="n">plant&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">durations&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">pipeline&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Durations dict&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;annual&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;biennial&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;perennial&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="n">valid_plants&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Gardening plants&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Carrot&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Eggplant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Tomato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;icon&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;🥔&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Potato&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;duration&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Replace duration if valid&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FlatMap&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">replace_duration_if_valid&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">durations&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pvalue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AsDict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">durations&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>{&amp;#39;icon&amp;#39;: &amp;#39;🍓&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Strawberry&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🥕&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Carrot&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;biennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍆&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Eggplant&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;perennial&amp;#39;}
{&amp;#39;icon&amp;#39;: &amp;#39;🍅&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;Tomato&amp;#39;, &amp;#39;duration&amp;#39;: &amp;#39;annual&amp;#39;}&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py .notebook-skip" >
&lt;td>
&lt;a class="button" target="_blank" href="https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/documentation/transforms/python/elementwise/flatmap-py.ipynb">&lt;img src="https://github.com/googlecolab/open_in_colab/raw/master/images/icon32.png" width="32px" height="32px" alt="Run code now" /> Run code now&lt;/a>
&lt;/td>
&lt;/table>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/flatmap.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/elementwise/filter">Filter&lt;/a> is useful if the function is just
deciding whether to output an element or not.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/elementwise/pardo">ParDo&lt;/a> is the most general elementwise mapping
operation, and includes other abilities such as multiple output collections and side-inputs.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/elementwise/map">Map&lt;/a> behaves the same, but produces exactly one output for each input.&lt;/li>
&lt;/ul>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.FlatMap"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: FlatMapElements</title><link>/documentation/transforms/java/elementwise/flatmapelements/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/elementwise/flatmapelements/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="flatmapelements">FlatMapElements&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/FlatMapElements.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Applies a simple 1-to-many mapping function over each element in the
collection. The many elements are flattened into the resulting collection.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7702">BEAM-7702&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/elementwise/filter">Filter&lt;/a> is useful if the function is just
deciding whether to output an element or not.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/elementwise/pardo">ParDo&lt;/a> is the most general element-wise mapping
operation, and includes other abilities such as multiple output collections and side-inputs.&lt;/li>
&lt;/ul></description></item><item><title>Documentation: Flatten</title><link>/documentation/transforms/java/other/flatten/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/other/flatten/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="flatten">Flatten&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/Flatten.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Merges multiple &lt;code>PCollection&lt;/code> objects into a single logical &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>By default, the coder for the output &lt;code>PCollection&lt;/code> is the same as the coder
for the first &lt;code>PCollection&lt;/code> in the input &lt;code>PCollectionList&lt;/code>. However, the
input &lt;code>PCollection&lt;/code> objects can each use different coders, as long as
they all contain the same data type in your chosen language.&lt;/p>
&lt;p>When using &lt;code>Flatten&lt;/code> to merge &lt;code>PCollection&lt;/code> objects that have a windowing
strategy applied, all of the &lt;code>PCollection&lt;/code> objects you want to merge must
use a compatible windowing strategy and window sizing. For example, all
the collections you&amp;rsquo;re merging must all use (hypothetically) identical
5-minute fixed windows or 4-minute sliding windows starting every 30 seconds.&lt;/p>
&lt;p>If your pipeline attempts to use &lt;code>Flatten&lt;/code> to merge &lt;code>PCollection&lt;/code> objects
with incompatible windows, Beam generates an &lt;code>IllegalStateException&lt;/code> error
when your pipeline is constructed&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#flatten">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>&lt;strong>Example&lt;/strong>: Apply a &lt;code>Flatten&lt;/code> transform to merge multiple &lt;code>PCollection&lt;/code> objects&lt;/p>
&lt;p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// Flatten takes a PCollectionList of PCollection objects of a given type.
&lt;/span>&lt;span class="c1">// Returns a single PCollection that contains all of the elements in the PCollection objects in that list.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Hello&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;World&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;Beam&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">pc3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Create&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Is&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;Fun&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">PCollectionList&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">collections&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PCollectionList&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">pc1&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">pc2&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">pc3&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">merged&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">collections&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Flatten&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">pCollections&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
The resulting collection now has all the elements: &amp;ldquo;Hello&amp;rdquo;, &amp;ldquo;World&amp;rdquo;,
&amp;ldquo;Beam&amp;rdquo;, &amp;ldquo;Is&amp;rdquo;, and &amp;ldquo;Fun&amp;rdquo;.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/elementwise/pardo">ParDo&lt;/a>&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/elementwise/partition">Partition&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Documentation: Flatten</title><link>/documentation/transforms/python/other/flatten/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/other/flatten/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="flatten">Flatten&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html?highlight=flatten#apache_beam.transforms.core.Flatten">
&lt;img src="https://beam.apache.org/images/logos/sdks/python.png" width="20px" height="20px"
alt="Pydoc" />
Pydoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Merges multiple &lt;code>PCollection&lt;/code> objects into a single logical
&lt;code>PCollection&lt;/code>. A transform for &lt;code>PCollection&lt;/code> objects
that store the same data type.&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#flatten">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7391">BEAM-7391&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/elementwise/flatmap">FlatMap&lt;/a> applies a simple 1-to-many mapping
function over each element in the collection. This transform might produce zero
or more outputs.&lt;/li>
&lt;/ul></description></item><item><title>Documentation: Google BigQuery I/O connector</title><link>/documentation/io/built-in/google-bigquery/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/io/built-in/google-bigquery/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>&lt;a href="/documentation/io/built-in/">Built-in I/O Transforms&lt;/a>&lt;/p>
&lt;h1 id="google-bigquery-io-connector">Google BigQuery I/O connector&lt;/h1>
&lt;nav class="language-switcher">
&lt;strong>Adapt for:&lt;/strong>
&lt;ul>
&lt;li data-type="language-java" class="active">Java SDK&lt;/li>
&lt;li data-type="language-py">Python SDK&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;p>The Beam SDKs include built-in transforms that can read data from and write data
to &lt;a href="https://cloud.google.com/bigquery">Google BigQuery&lt;/a> tables.&lt;/p>
&lt;h2 id="before-you-start">Before you start&lt;/h2>
&lt;!-- Java specific -->
&lt;p class="language-java">To use BigQueryIO, add the Maven artifact dependency to your &lt;code>pom.xml&lt;/code> file.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">beam&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">sdks&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">java&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">google&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">cloud&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">platform&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">24&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">0&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">Additional resources:&lt;/p>
&lt;span class="language-java">&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/tree/master/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery">BigQueryIO source code&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.html">BigQueryIO Javadoc&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/bigquery/docs">Google BigQuery documentation&lt;/a>&lt;/li>
&lt;/ul>&lt;/span>
&lt;!-- Python specific -->
&lt;p class="language-py">To use BigQueryIO, you must install the Google Cloud Platform dependencies by
running &lt;code>pip install apache-beam[gcp]&lt;/code>.&lt;/p>
&lt;p class="language-py">Additional resources:&lt;/p>
&lt;span class="language-py">&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/gcp/bigquery.py">BigQueryIO source code&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://beam.apache.org/releases/pydoc/2.24.0/apache_beam.io.gcp.bigquery.html">BigQueryIO Pydoc&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/bigquery/docs">Google BigQuery documentation&lt;/a>&lt;/li>
&lt;/ul>&lt;/span>
&lt;h2 id="bigquery-basics">BigQuery basics&lt;/h2>
&lt;h3 id="table-names">Table names&lt;/h3>
&lt;p>To read or write from a BigQuery table, you must provide a fully-qualified
BigQuery table name (for example, &lt;code>bigquery-public-data:github_repos.sample_contents&lt;/code>).
A fully-qualified BigQuery table name consists of three parts:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Project ID&lt;/strong>: The ID for your Google Cloud Project. The default value comes
from your pipeline options object.&lt;/li>
&lt;li>&lt;strong>Dataset ID&lt;/strong>: The BigQuery dataset ID, which is unique within a given Cloud
Project.&lt;/li>
&lt;li>&lt;strong>Table ID&lt;/strong>: A BigQuery table ID, which is unique within a given dataset.&lt;/li>
&lt;/ul>
&lt;p>A table name can also include a &lt;a href="https://cloud.google.com/bigquery/table-decorators">table decorator&lt;/a>
if you are using &lt;a href="#using-time-partitioning">time-partitioned tables&lt;/a>.&lt;/p>
&lt;p>To specify a BigQuery table, you can use either the table&amp;rsquo;s fully-qualified name as
a string, or use a
&lt;span class="language-java">
&lt;a href="https://developers.google.com/resources/api-libraries/documentation/bigquery/v2/java/latest/index.html?com/google/api/services/bigquery/model/TableReference.html">TableReference&lt;/a>
&lt;/span>
&lt;span class="language-py">
&lt;a href="https://github.com/googleapis/google-cloud-python/blob/master/bigquery/google/cloud/bigquery/table.py#L153">TableReference&lt;/a>
&lt;/span>
object.&lt;/p>
&lt;h4 id="using-a-string">Using a string&lt;/h4>
&lt;p>To specify a table with a string, use the format
&lt;code>[project_id]:[dataset_id].[table_id]&lt;/code> to specify the fully-qualified BigQuery
table name.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">String&lt;/span> &lt;span class="n">tableSpec&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;clouddataflow-readonly:samples.weather_stations&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># project-id:dataset_id.table_id&lt;/span>
&lt;span class="n">table_spec&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;clouddataflow-readonly:samples.weather_stations&amp;#39;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>You can also omit &lt;code>project_id&lt;/code> and use the &lt;code>[dataset_id].[table_id]&lt;/code> format. If
you omit the project ID, Beam uses the default project ID from your
&lt;span class="language-java">
&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/org/apache/beam/sdk/extensions/gcp/options/GcpOptions.html">pipeline options&lt;/a>.
&lt;/span>
&lt;span class="language-py">
&lt;a href="https://beam.apache.org/releases/pydoc/2.24.0/apache_beam.options.pipeline_options.html#apache_beam.options.pipeline_options.GoogleCloudOptions">pipeline options&lt;/a>.
&lt;/span>&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">String&lt;/span> &lt;span class="n">tableSpec&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;samples.weather_stations&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># dataset_id.table_id&lt;/span>
&lt;span class="n">table_spec&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;samples.weather_stations&amp;#39;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="using-a-tablereference">Using a TableReference&lt;/h4>
&lt;p>To specify a table with a &lt;code>TableReference&lt;/code>, create a new &lt;code>TableReference&lt;/code> using
the three parts of the BigQuery table name.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">TableReference&lt;/span> &lt;span class="n">tableSpec&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableReference&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setProjectId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;clouddataflow-readonly&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setDatasetId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;samples&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setTableId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;weather_stations&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">from&lt;/span> &lt;span class="nn">apache_beam.io.gcp.internal.clients&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">bigquery&lt;/span>
&lt;span class="n">table_spec&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">bigquery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TableReference&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">projectId&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;clouddataflow-readonly&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">datasetId&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;samples&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">tableId&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;weather_stations&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;!-- Java specific -->
&lt;p class="language-java">The Beam SDK for Java also provides the &lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryHelpers.html">&lt;code>parseTableSpec&lt;/code>&lt;/a>
helper method, which constructs a &lt;code>TableReference&lt;/code> object from a String that
contains the fully-qualified BigQuery table name. However, the static factory
methods for BigQueryIO transforms accept the table name as a String and
construct a &lt;code>TableReference&lt;/code> object for you.&lt;/p>
&lt;h3 id="table-rows">Table rows&lt;/h3>
&lt;p>BigQueryIO read and write transforms produce and consume data as a &lt;code>PCollection&lt;/code>
of dictionaries, where each element in the &lt;code>PCollection&lt;/code> represents a single row
in the table.&lt;/p>
&lt;h3 id="schemas">Schemas&lt;/h3>
&lt;p>When writing to BigQuery, you must supply a table schema for the destination
table that you want to write to, unless you specify a &lt;a href="#create-disposition">create
disposition&lt;/a> of &lt;code>CREATE_NEVER&lt;/code>. &lt;a href="#creating-a-table-schema">Creating a table
schema&lt;/a> covers schemas in more detail.&lt;/p>
&lt;h3 id="data-types">Data types&lt;/h3>
&lt;p>BigQuery supports the following data types: STRING, BYTES, INTEGER, FLOAT,
NUMERIC, BOOLEAN, TIMESTAMP, DATE, TIME, DATETIME and GEOGRAPHY.
All possible values are described at &lt;a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types">https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types&lt;/a>.
BigQueryIO allows you to use all of these data types. The following example
shows the correct format for data types used when reading from and writing to
BigQuery:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kn">import&lt;/span> &lt;span class="nn">com.google.api.services.bigquery.model.TableRow&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.math.BigDecimal&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.nio.charset.StandardCharsets&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.time.Instant&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.time.LocalDate&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.time.LocalDateTime&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.time.LocalTime&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.AbstractMap.SimpleEntry&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.Arrays&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.Base64&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.stream.Collectors&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.stream.Stream&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">class&lt;/span> &lt;span class="nc">BigQueryTableRowCreate&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">TableRow&lt;/span> &lt;span class="nf">createTableRow&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">TableRow&lt;/span> &lt;span class="n">row&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableRow&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="c1">// To learn more about BigQuery data types:
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;string_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;UTF-8 strings are supported! 🌱🌳🌍&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;int64_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">432&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;float64_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">3&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">141592653589793&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;numeric_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">BigDecimal&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;1234.56&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;bool_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;bytes_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">Base64&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getEncoder&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">encodeToString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;UTF-8 byte string 🌱🌳🌍&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">StandardCharsets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">UTF_8&lt;/span>&lt;span class="o">)))&lt;/span>
&lt;span class="c1">// To learn more about date formatting:
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/time/format/DateTimeFormatter.html
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;date_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LocalDate&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">parse&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;2020-03-19&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="c1">// ISO_LOCAL_DATE
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;datetime_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">LocalDateTime&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">parse&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;2020-03-19T20:41:25.123&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="c1">// ISO_LOCAL_DATE_TIME
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;time_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">LocalTime&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">parse&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;20:41:25.123&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="c1">// ISO_LOCAL_TIME
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;timestamp_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">Instant&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">parse&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;2020-03-20T03:41:42.123Z&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="c1">// ISO_INSTANT
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// To learn more about the geography Well-Known Text (WKT) format:
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;geography_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;POINT(30 10)&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="c1">// An array has its mode set to REPEATED.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;array_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">2&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">3&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">4&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="c1">// Any class can be written as a STRUCT as long as all the fields in the
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// schema are present and they are encoded correctly as BigQuery types.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;struct_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">Stream&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">SimpleEntry&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="s">&amp;#34;string_value&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;Text 🌱🌳🌍&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">SimpleEntry&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="s">&amp;#34;int64_value&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;42&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">collect&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Collectors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toMap&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">SimpleEntry&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">getKey&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">SimpleEntry&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">getValue&lt;/span>&lt;span class="o">)));&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">row&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">bigquery_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[{&lt;/span>
&lt;span class="s1">&amp;#39;string&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;abc&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;bytes&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">base64&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">b64encode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">b&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="se">\xab\xac&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="s1">&amp;#39;integer&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;float&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mf">0.5&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;numeric&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Decimal&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;5&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="s1">&amp;#39;boolean&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="bp">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;timestamp&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;2018-12-31 12:44:31.744957 UTC&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;date&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;2018-12-31&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;time&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;12:44:31&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;datetime&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;2018-12-31T12:44:31&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s1">&amp;#39;geography&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;POINT(30 10)&amp;#39;&lt;/span>
&lt;span class="p">}]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;!-- Java specific -->
&lt;p class="language-java">As of Beam 2.7.0, the NUMERIC data type is supported. This data type supports
high-precision decimal numbers (precision of 38 digits, scale of 9 digits).
The GEOGRAPHY data type works with Well-Known Text (See &lt;a href="https://en.wikipedia.org/wiki/Well-known_text">https://en.wikipedia.org/wiki/Well-known_text&lt;/a>
format for reading and writing to BigQuery.
BigQuery IO requires values of BYTES datatype to be encoded using base64
encoding when writing to BigQuery. When bytes are read from BigQuery they are
returned as base64-encoded strings.&lt;/p>
&lt;!-- Python specific -->
&lt;p class="language-py">As of Beam 2.7.0, the NUMERIC data type is supported. This data type supports
high-precision decimal numbers (precision of 38 digits, scale of 9 digits).
The GEOGRAPHY data type works with Well-Known Text (See &lt;a href="https://en.wikipedia.org/wiki/Well-known_text">https://en.wikipedia.org/wiki/Well-known_text&lt;/a>
format for reading and writing to BigQuery.
BigQuery IO requires values of BYTES datatype to be encoded using base64
encoding when writing to BigQuery. When bytes are read from BigQuery they are
returned as base64-encoded bytes.&lt;/p>
&lt;h2 id="reading-from-bigquery">Reading from BigQuery&lt;/h2>
&lt;p>BigQueryIO allows you to read from a BigQuery table, or to execute a SQL query
and read the results. By default, Beam invokes a &lt;a href="https://cloud.google.com/bigquery/docs/exporting-data">BigQuery export
request&lt;/a> when you apply a
BigQueryIO read transform. However, the Beam SDK for Java also supports using
the &lt;a href="https://cloud.google.com/bigquery/docs/reference/storage">BigQuery Storage
API&lt;/a> to read directly
from BigQuery storage. See &lt;a href="#storage-api">Using the BigQuery Storage API&lt;/a> for
more information.&lt;/p>
&lt;blockquote>
&lt;p>Beam’s use of BigQuery APIs is subject to BigQuery&amp;rsquo;s
&lt;a href="https://cloud.google.com/bigquery/quota-policy">Quota&lt;/a>
and &lt;a href="https://cloud.google.com/bigquery/pricing">Pricing&lt;/a> policies.&lt;/p>
&lt;/blockquote>
&lt;!-- Java specific -->
&lt;p class="language-java">The Beam SDK for Java has two BigQueryIO read methods. Both of these methods
allow you to read from a table, or read fields using a query string.&lt;/p>
&lt;span class="language-java">&lt;ol>
&lt;li>
&lt;p>&lt;code>read(SerializableFunction)&lt;/code> reads Avro-formatted records and uses a
specified parsing function to parse them into a &lt;code>PCollection&lt;/code> of custom typed
objects. Each element in the &lt;code>PCollection&lt;/code> represents a single row in the
table. The &lt;a href="#reading-with-a-query-string">example code&lt;/a> for reading with a
query string shows how to use &lt;code>read(SerializableFunction)&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>readTableRows&lt;/code> returns a &lt;code>PCollection&lt;/code> of BigQuery &lt;code>TableRow&lt;/code>
objects. Each element in the &lt;code>PCollection&lt;/code> represents a single row in the
table. Integer values in the &lt;code>TableRow&lt;/code> objects are encoded as strings to
match BigQuery&amp;rsquo;s exported JSON format. This method is convenient, but can be
2-3 times slower in performance compared to &lt;code>read(SerializableFunction)&lt;/code>. The
&lt;a href="#reading-from-a-table">example code&lt;/a> for reading from a table shows how to
use &lt;code>readTableRows&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/span>
&lt;p class="language-java">&lt;em>&lt;strong>Note:&lt;/strong>&lt;/em> &lt;code>BigQueryIO.read()&lt;/code> is deprecated as of Beam SDK 2.2.0. Instead, use
&lt;code>read(SerializableFunction&amp;lt;SchemaAndRecord, T&amp;gt;)&lt;/code> to parse BigQuery rows from
Avro &lt;code>GenericRecord&lt;/code> into your custom type, or use &lt;code>readTableRows()&lt;/code> to parse
them into JSON &lt;code>TableRow&lt;/code> objects.&lt;/p>
&lt;!-- Python specific -->
&lt;p class="language-py">To read from a BigQuery table using the Beam SDK for Python, apply a &lt;code>Read&lt;/code>
transform on a &lt;code>BigQuerySource&lt;/code>. Read returns a &lt;code>PCollection&lt;/code> of dictionaries,
where each element in the &lt;code>PCollection&lt;/code> represents a single row in the table.
Integer values in the &lt;code>TableRow&lt;/code> objects are encoded as strings to match
BigQuery&amp;rsquo;s exported JSON format.&lt;/p>
&lt;h3 id="reading-from-a-table">Reading from a table&lt;/h3>
&lt;p class="language-java">To read an entire BigQuery table, use the &lt;code>from&lt;/code> method with a BigQuery table
name. This example uses &lt;code>readTableRows&lt;/code>.&lt;/p>
&lt;p class="language-py">To read an entire BigQuery table, use the &lt;code>table&lt;/code> parameter with the BigQuery
table name.&lt;/p>
&lt;p>The following code reads an entire table that contains weather station data and
then extracts the &lt;code>max_temperature&lt;/code> column.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.examples.snippets.transforms.io.gcp.bigquery.BigQueryMyData.MyData&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.Pipeline&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.transforms.MapElements&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.values.PCollection&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.values.TypeDescriptor&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">class&lt;/span> &lt;span class="nc">BigQueryReadFromTable&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">readFromTable&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">project&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">dataset&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">table&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Pipeline&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// String project = &amp;#34;my-project-id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// String dataset = &amp;#34;my_bigquery_dataset_id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// String table = &amp;#34;my_bigquery_table_id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// Pipeline pipeline = Pipeline.create();
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">rows&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;Read from BigQuery query&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">readTableRows&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">from&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">format&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;%s:%s.%s&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">project&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">dataset&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">table&lt;/span>&lt;span class="o">)))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;TableRows to MyData&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">fromTableRow&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">max_temperatures&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;ReadTable&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Read&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BigQuerySource&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">table_spec&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="c1"># Each row is a dictionary where the keys are the BigQuery columns&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;max_temperature&amp;#39;&lt;/span>&lt;span class="p">]))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="reading-with-a-query-string">Reading with a query string&lt;/h3>
&lt;p class="language-java">If you don&amp;rsquo;t want to read an entire table, you can supply a query string with
the &lt;code>fromQuery&lt;/code> method.&lt;/p>
&lt;p class="language-py">If you don&amp;rsquo;t want to read an entire table, you can supply a query string to
&lt;code>BigQuerySource&lt;/code> by specifying the &lt;code>query&lt;/code> parameter.&lt;/p>
&lt;p class="language-py">The following code uses a SQL query to only read the &lt;code>max_temperature&lt;/code> column.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.examples.snippets.transforms.io.gcp.bigquery.BigQueryMyData.MyData&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.Pipeline&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.transforms.MapElements&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.values.PCollection&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.values.TypeDescriptor&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">class&lt;/span> &lt;span class="nc">BigQueryReadFromQuery&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">readFromQuery&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">project&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">dataset&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">table&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Pipeline&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// String project = &amp;#34;my-project-id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// String dataset = &amp;#34;my_bigquery_dataset_id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// String table = &amp;#34;my_bigquery_table_id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// Pipeline pipeline = Pipeline.create();
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">rows&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;Read from BigQuery query&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">readTableRows&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">fromQuery&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">format&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;SELECT * FROM `%s.%s.%s`&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">project&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">dataset&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">table&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">usingStandardSql&lt;/span>&lt;span class="o">())&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;TableRows to MyData&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">fromTableRow&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">max_temperatures&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;QueryTable&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Read&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BigQuerySource&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">query&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;SELECT max_temperature FROM &amp;#39;&lt;/span>\
&lt;span class="s1">&amp;#39;[clouddataflow-readonly:samples.weather_stations]&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="c1"># Each row is a dictionary where the keys are the BigQuery columns&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;max_temperature&amp;#39;&lt;/span>&lt;span class="p">]))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>You can also use BigQuery&amp;rsquo;s standard SQL dialect with a query string, as shown
in the following example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Double&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">maxTemperatures&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">SchemaAndRecord&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Double&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getRecord&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;max_temperature&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">fromQuery&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;SELECT max_temperature FROM `clouddataflow-readonly.samples.weather_stations`&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">usingStandardSql&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withCoder&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">DoubleCoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">()));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">max_temperatures&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;QueryTableStdSQL&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Read&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BigQuerySource&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">query&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;SELECT max_temperature FROM &amp;#39;&lt;/span>\
&lt;span class="s1">&amp;#39;`clouddataflow-readonly.samples.weather_stations`&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">use_standard_sql&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">True&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="c1"># Each row is a dictionary where the keys are the BigQuery columns&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;max_temperature&amp;#39;&lt;/span>&lt;span class="p">]))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="storage-api">Using the BigQuery Storage API&lt;/h3>
&lt;p>The &lt;a href="https://cloud.google.com/bigquery/docs/reference/storage/">BigQuery Storage API&lt;/a>
allows you to directly access tables in BigQuery storage, and supports features
such as column selection and predicate filter push-down which can allow more
efficient pipeline execution.&lt;/p>
&lt;p>The Beam SDK for Java supports using the BigQuery Storage API when reading from
BigQuery. SDK versions before 2.24.0 support the BigQuery Storage API as an
&lt;a href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/annotations/Experimental.html">experimental feature&lt;/a>
and use the pre-GA BigQuery Storage API surface. Callers should migrate
pipelines which use the BigQuery Storage API to use SDK version 2.24.0 or later.&lt;/p>
&lt;p>The Beam SDK for Python does not support the BigQuery Storage API. See
&lt;a href="https://issues.apache.org/jira/browse/BEAM-10917">BEAM-10917&lt;/a>).&lt;/p>
&lt;h4 id="updating-your-code">Updating your code&lt;/h4>
&lt;p>Use the following methods when you read from a table:&lt;/p>
&lt;ul>
&lt;li>Required: Specify &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.TypedRead.html#withMethod-org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.TypedRead.Method-">withMethod(Method.DIRECT_READ)&lt;/a> to use the BigQuery Storage API for the read operation.&lt;/li>
&lt;li>Optional: To use features such as &lt;a href="https://cloud.google.com/bigquery/docs/reference/storage/">column projection and column filtering&lt;/a>, you must specify &lt;a href="https://beam.apache.org/releases/javadoc/2.17.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.TypedRead.html#withSelectedFields-java.util.List-">withSelectedFields&lt;/a> and &lt;a href="https://beam.apache.org/releases/javadoc/2.17.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.TypedRead.html#withRowRestriction-java.lang.String-">withRowRestriction&lt;/a> respectively.&lt;/li>
&lt;/ul>
&lt;p>The following code snippet reads from a table. This example is from the &lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/BigQueryTornadoes.java">BigQueryTornadoes
example&lt;/a>.
When the example&amp;rsquo;s read method option is set to &lt;code>DIRECT_READ&lt;/code>, the pipeline uses
the BigQuery Storage API and column projection to read public samples of weather
data from a BigQuery table. You can view the &lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/BigQueryTornadoes.java">full source code on
GitHub&lt;/a>.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.Arrays&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.examples.snippets.transforms.io.gcp.bigquery.BigQueryMyData.MyData&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.Pipeline&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.TypedRead.Method&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.transforms.MapElements&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.values.PCollection&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.values.TypeDescriptor&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">class&lt;/span> &lt;span class="nc">BigQueryReadFromTableWithBigQueryStorageAPI&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">readFromTableWithBigQueryStorageAPI&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">project&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">dataset&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">table&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Pipeline&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// String project = &amp;#34;my-project-id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// String dataset = &amp;#34;my_bigquery_dataset_id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// String table = &amp;#34;my_bigquery_table_id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// Pipeline pipeline = Pipeline.create();
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">rows&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;Read from BigQuery table&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">readTableRows&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">from&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">format&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;%s:%s.%s&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">project&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">dataset&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">table&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withMethod&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Method&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DIRECT_READ&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withSelectedFields&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;string_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;int64_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;float64_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;numeric_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;bool_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;bytes_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;date_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;datetime_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;time_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;timestamp_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;geography_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;array_field&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;struct_field&amp;#34;&lt;/span>&lt;span class="o">)))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;TableRows to MyData&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">MapElements&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">into&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TypeDescriptor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="na">via&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MyData&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">fromTableRow&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># The SDK for Python does not support the BigQuery Storage API.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The following code snippet reads with a query string.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">//&lt;/span> &lt;span class="n">Snippet&lt;/span> &lt;span class="n">not&lt;/span> &lt;span class="n">yet&lt;/span> &lt;span class="nf">available&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">BEAM&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">7034&lt;/span>&lt;span class="o">).&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># The SDK for Python does not support the BigQuery Storage API.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="writing-to-bigquery">Writing to BigQuery&lt;/h2>
&lt;p>BigQueryIO allows you to write to BigQuery tables. If you are using the Beam SDK
for Java, you can also write different rows to different tables.&lt;/p>
&lt;blockquote>
&lt;p>BigQueryIO write transforms use APIs that are subject to BigQuery&amp;rsquo;s
&lt;a href="https://cloud.google.com/bigquery/quota-policy">Quota&lt;/a> and
&lt;a href="https://cloud.google.com/bigquery/pricing">Pricing&lt;/a> policies.&lt;/p>
&lt;/blockquote>
&lt;p>When you apply a write transform, you must provide the following information
for the destination table(s):&lt;/p>
&lt;ul>
&lt;li>The table name.&lt;/li>
&lt;li>The destination table&amp;rsquo;s create disposition. The create disposition specifies
whether the destination table must exist or can be created by the write
operation.&lt;/li>
&lt;li>The destination table&amp;rsquo;s write disposition. The write disposition specifies
whether the data you write will replace an existing table, append rows to an
existing table, or write only to an empty table.&lt;/li>
&lt;/ul>
&lt;p>In addition, if your write operation creates a new BigQuery table, you must also
supply a table schema for the destination table.&lt;/p>
&lt;h3 id="create-disposition">Create disposition&lt;/h3>
&lt;p>The create disposition controls whether or not your BigQuery write operation
should create a table if the destination table does not exist.&lt;/p>
&lt;!-- Java specific -->
&lt;p class="language-java">Use &lt;code>.withCreateDisposition&lt;/code> to specify the create disposition. Valid enum
values are:&lt;/p>
&lt;span class="language-java">&lt;ul>
&lt;li>
&lt;p>&lt;code>Write.CreateDisposition.CREATE_IF_NEEDED&lt;/code>: Specifies that the
write operation should create a new table if one does not exist. If you use
this value, you must provide a table schema with the &lt;code>withSchema&lt;/code> method.
&lt;code>CREATE_IF_NEEDED&lt;/code> is the default behavior.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>Write.CreateDisposition.CREATE_NEVER&lt;/code>: Specifies that a table
should never be created. If the destination table does not exist, the write
operation fails.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/span>
&lt;!-- Python specific -->
&lt;p class="language-py">Use the &lt;code>create_disposition&lt;/code> parameter to specify the create disposition. Valid
enum values are:&lt;/p>
&lt;span class="language-py">&lt;ul>
&lt;li>
&lt;p>&lt;code>BigQueryDisposition.CREATE_IF_NEEDED&lt;/code>: Specifies that the write operation
should create a new table if one does not exist. If you use this value, you
must provide a table schema. &lt;code>CREATE_IF_NEEDED&lt;/code> is the default behavior.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>BigQueryDisposition.CREATE_NEVER&lt;/code>: Specifies that a table should never be
created. If the destination table does not exist, the write operation fails.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/span>
&lt;p>If you specify &lt;code>CREATE_IF_NEEDED&lt;/code> as the create disposition and you don&amp;rsquo;t supply
a table schema, the transform might fail at runtime if the destination table does
not exist.&lt;/p>
&lt;h3 id="write-disposition">Write disposition&lt;/h3>
&lt;p>The write disposition controls how your BigQuery write operation applies to an
existing table.&lt;/p>
&lt;!-- Java specific -->
&lt;p class="language-java">Use &lt;code>.withWriteDisposition&lt;/code> to specify the write disposition. Valid enum values
are:&lt;/p>
&lt;span class="language-java">&lt;ul>
&lt;li>
&lt;p>&lt;code>Write.WriteDisposition.WRITE_EMPTY&lt;/code>: Specifies that the write
operation should fail at runtime if the destination table is not empty.
&lt;code>WRITE_EMPTY&lt;/code> is the default behavior.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>Write.WriteDisposition.WRITE_TRUNCATE&lt;/code>: Specifies that the write
operation should replace an existing table. Any existing rows in the
destination table are removed, and the new rows are added to the table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>Write.WriteDisposition.WRITE_APPEND&lt;/code>: Specifies that the write
operation should append the rows to the end of the existing table.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/span>
&lt;!-- Python specific -->
&lt;p class="language-py">Use the &lt;code>write_disposition&lt;/code> parameter to specify the write disposition. Valid
enum values are:&lt;/p>
&lt;span class="language-py">&lt;ul>
&lt;li>
&lt;p>&lt;code>BigQueryDisposition.WRITE_EMPTY&lt;/code>: Specifies that the write operation should
fail at runtime if the destination table is not empty. &lt;code>WRITE_EMPTY&lt;/code> is the
default behavior.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>BigQueryDisposition.WRITE_TRUNCATE&lt;/code>: Specifies that the write operation
should replace an existing table. Any existing rows in the destination table
are removed, and the new rows are added to the table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>BigQueryDisposition.WRITE_APPEND&lt;/code>: Specifies that the write operation should
append the rows to the end of the existing table.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/span>
&lt;p>When you use &lt;code>WRITE_EMPTY&lt;/code>, the check for whether or not the destination table
is empty can occur before the actual write operation. This check doesn&amp;rsquo;t
guarantee that your pipeline will have exclusive access to the table. Two
concurrent pipelines that write to the same output table with a write
disposition of &lt;code>WRITE_EMPTY&lt;/code> might start successfully, but both pipelines can
fail later when the write attempts happen.&lt;/p>
&lt;h3 id="creating-a-table-schema">Creating a table schema&lt;/h3>
&lt;p>If your BigQuery write operation creates a new table, you must provide schema
information. The schema contains information about each field in the table.&lt;/p>
&lt;p class="language-java">To create a table schema in Java, you can either use a &lt;code>TableSchema&lt;/code> object, or
use a string that contains a JSON-serialized &lt;code>TableSchema&lt;/code> object.&lt;/p>
&lt;p class="language-py">To create a table schema in Python, you can either use a &lt;code>TableSchema&lt;/code> object,
or use a string that defines a list of fields. Single string based schemas do
not support nested fields, repeated fields, or specifying a BigQuery mode for
fields (the mode will always be set to &lt;code>NULLABLE&lt;/code>).&lt;/p>
&lt;h4 id="using-a-tableschema">Using a TableSchema&lt;/h4>
&lt;p>To create and use a table schema as a &lt;code>TableSchema&lt;/code> object, follow these steps.&lt;/p>
&lt;!-- Java specific - TableSchema -->
&lt;span class="language-java">&lt;ol>
&lt;li>
&lt;p>Create a list of &lt;code>TableFieldSchema&lt;/code> objects. Each &lt;code>TableFieldSchema&lt;/code> object
represents a field in the table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create a &lt;code>TableSchema&lt;/code> object and use the &lt;code>setFields&lt;/code> method to specify your
list of fields.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Use the &lt;code>withSchema&lt;/code> method to provide your table schema when you apply a
write transform.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/span>
&lt;!-- Python specific - TableSchema -->
&lt;span class="language-py">&lt;ol>
&lt;li>
&lt;p>Create a &lt;code>TableSchema&lt;/code> object.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create and append a &lt;code>TableFieldSchema&lt;/code> object for each field in your table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Next, use the &lt;code>schema&lt;/code> parameter to provide your table schema when you apply
a write transform. Set the parameter’s value to the &lt;code>TableSchema&lt;/code> object.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/span>
&lt;!-- Common -->
&lt;p>The following example code shows how to create a &lt;code>TableSchema&lt;/code> for a table with
two fields (source and quote) of type string.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kn">import&lt;/span> &lt;span class="nn">com.google.api.services.bigquery.model.TableFieldSchema&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">com.google.api.services.bigquery.model.TableSchema&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.Arrays&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">class&lt;/span> &lt;span class="nc">BigQuerySchemaCreate&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">TableSchema&lt;/span> &lt;span class="nf">createSchema&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// To learn more about BigQuery schemas:
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// https://cloud.google.com/bigquery/docs/schemas
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">TableSchema&lt;/span> &lt;span class="n">schema&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setFields&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;string_field&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STRING&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setMode&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;REQUIRED&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;int64_field&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;INT64&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setMode&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;NULLABLE&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;float64_field&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;FLOAT64&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="c1">// default mode is &amp;#34;NULLABLE&amp;#34;
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;numeric_field&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;NUMERIC&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;bool_field&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;BOOL&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;bytes_field&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;BYTES&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;date_field&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;DATE&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;datetime_field&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;DATETIME&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;time_field&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;TIME&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;timestamp_field&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;TIMESTAMP&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;geography_field&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;GEOGRAPHY&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;array_field&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;INT64&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setMode&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;REPEATED&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setDescription&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Setting the mode to REPEATED makes this an ARRAY&amp;lt;INT64&amp;gt;.&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;struct_field&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STRUCT&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setDescription&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;A STRUCT accepts a custom data class, the fields must match the custom class fields.&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setFields&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;string_value&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;STRING&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;int64_value&amp;#34;&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;INT64&amp;#34;&lt;/span>&lt;span class="o">)))));&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">schema&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">table_schema&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;fields&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[{&lt;/span>
&lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;source&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;type&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;STRING&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;mode&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;NULLABLE&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;name&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;quote&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;type&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;STRING&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;mode&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;REQUIRED&amp;#39;&lt;/span>
&lt;span class="p">}]&lt;/span>
&lt;span class="p">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="using-a-string-1">Using a string&lt;/h4>
&lt;!-- Java specific - string -->
&lt;p class="language-java">To create and use a table schema as a string that contains JSON-serialized
&lt;code>TableSchema&lt;/code> object, follow these steps.&lt;/p>
&lt;span class="language-java">&lt;ol>
&lt;li>
&lt;p>Create a string that contains a JSON-serialized &lt;code>TableSchema&lt;/code> object.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Use the &lt;code>withJsonSchema&lt;/code> method to provide your table schema when you apply a
write transform.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/span>
&lt;!-- Python specific - string -->
&lt;p class="language-py">To create and use a table schema as a string, follow these steps.&lt;/p>
&lt;span class="language-py">&lt;ol>
&lt;li>
&lt;p>Create a single comma separated string of the form
&amp;ldquo;field1:type1,field2:type2,field3:type3&amp;rdquo; that defines a list of fields. The
type should specify the field’s BigQuery type.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Use the &lt;code>schema&lt;/code> parameter to provide your table schema when you apply a
write transform. Set the parameter’s value to the string.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/span>
&lt;!-- Common -->
&lt;p>The following example shows how to use a string to specify the same table schema
as the previous example.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">String&lt;/span> &lt;span class="n">tableSchemaJson&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="s">&amp;#34;&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;{&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; \&amp;#34;fields\&amp;#34;: [&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; {&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; \&amp;#34;name\&amp;#34;: \&amp;#34;source\&amp;#34;,&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; \&amp;#34;type\&amp;#34;: \&amp;#34;STRING\&amp;#34;,&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; \&amp;#34;mode\&amp;#34;: \&amp;#34;NULLABLE\&amp;#34;&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; },&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; {&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; \&amp;#34;name\&amp;#34;: \&amp;#34;quote\&amp;#34;,&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; \&amp;#34;type\&amp;#34;: \&amp;#34;STRING\&amp;#34;,&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; \&amp;#34;mode\&amp;#34;: \&amp;#34;REQUIRED\&amp;#34;&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; }&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; ]&amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;}&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># column_name:BIGQUERY_TYPE, ...&lt;/span>
&lt;span class="n">table_schema&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;source:STRING, quote:STRING&amp;#39;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="setting-the-insertion-method">Setting the insertion method&lt;/h3>
&lt;p class="language-py">&lt;blockquote>
&lt;p>The Beam SDK for Python does not currently support specifying the insertion
method.&lt;/p>
&lt;/blockquote>&lt;/p>
&lt;p>BigQueryIO supports two methods of inserting data into BigQuery: load jobs and
streaming inserts. Each insertion method provides different tradeoffs of cost,
quota, and data consistency. See the BigQuery documentation for
&lt;a href="https://cloud.google.com/bigquery/loading-data">load jobs&lt;/a> and
&lt;a href="https://cloud.google.com/bigquery/streaming-data-into-bigquery">streaming inserts&lt;/a>
for more information about these tradeoffs.&lt;/p>
&lt;p>BigQueryIO chooses a default insertion method based on the input &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p class="language-py">BigQueryIO uses load jobs when you apply a BigQueryIO write transform to a
bounded &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p class="language-java">BigQueryIO uses load jobs in the following situations:&lt;/p>
&lt;span class="language-java">&lt;ul>
&lt;li>When you apply a BigQueryIO write transform to a bounded &lt;code>PCollection&lt;/code>.&lt;/li>
&lt;li>When you apply a BigQueryIO write transform to an unbounded &lt;code>PCollection&lt;/code> and
use &lt;code>BigQueryIO.write().withTriggeringFrequency()&lt;/code> to set the triggering
frequency.&lt;/li>
&lt;li>When you specify load jobs as the insertion method using
&lt;code>BigQueryIO.write().withMethod(FILE_LOADS)&lt;/code>.&lt;/li>
&lt;/ul>&lt;/span>
&lt;p class="language-py">BigQueryIO uses streaming inserts when you apply a BigQueryIO write transform to
an unbounded &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p class="language-java">BigQueryIO uses streaming inserts in the following situations:&lt;/p>
&lt;span class="language-java">&lt;ul>
&lt;li>When you apply a BigQueryIO write transform to an unbounded &lt;code>PCollection&lt;/code> and
do not set the triggering frequency.&lt;/li>
&lt;li>When you specify streaming inserts as the insertion method using
&lt;code>BigQueryIO.write().withMethod(STREAMING_INSERTS)&lt;/code>.&lt;/li>
&lt;/ul>&lt;/span>
&lt;!-- Java specific -->
&lt;p class="language-java">You can use &lt;code>withMethod&lt;/code> to specify the desired insertion method. See
&lt;a href="https://beam.apache.org/releases/javadoc/2.24.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.Write.Method.html">Write.Method&lt;/a>
for the list of the available methods and their restrictions.&lt;/p>
&lt;p class="language-java">&lt;em>&lt;strong>Note:&lt;/strong>&lt;/em> If you use batch loads in a streaming pipeline, you must use
&lt;code>withTriggeringFrequency&lt;/code> to specify a triggering frequency and &lt;code>withNumFileShards&lt;/code> to specify number of file shards written.&lt;/p>
&lt;h3 id="writing-to-a-table">Writing to a table&lt;/h3>
&lt;p class="language-java">To write to a BigQuery table, apply either a &lt;code>writeTableRows&lt;/code> or &lt;code>write&lt;/code>
transform.&lt;/p>
&lt;p class="language-py">To write to a BigQuery table, apply the &lt;code>WriteToBigQuery&lt;/code> transform.
&lt;code>WriteToBigQuery&lt;/code> supports both batch mode and streaming mode. You must apply
the transform to a &lt;code>PCollection&lt;/code> of dictionaries. In general, you&amp;rsquo;ll need to use
another transform, such as &lt;code>ParDo&lt;/code>, to format your output data into a
collection.&lt;/p>
&lt;p class="language-py">The following examples use this &lt;code>PCollection&lt;/code> that contains quotes.&lt;/p>
&lt;p class="language-java">The &lt;code>writeTableRows&lt;/code> method writes a &lt;code>PCollection&lt;/code> of BigQuery &lt;code>TableRow&lt;/code>
objects to a BigQuery table. Each element in the &lt;code>PCollection&lt;/code> represents a
single row in the table. This example uses &lt;code>writeTableRows&lt;/code> to write elements to a
&lt;code>PCollection&amp;lt;TableRow&amp;gt;&lt;/code>. The write operation creates a table if needed; if the
table already exists, it will be replaced.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kn">import&lt;/span> &lt;span class="nn">com.google.api.services.bigquery.model.TableRow&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">com.google.api.services.bigquery.model.TableSchema&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.Write.CreateDisposition&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.Write.WriteDisposition&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.beam.sdk.values.PCollection&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">class&lt;/span> &lt;span class="nc">BigQueryWriteToTable&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">writeToTable&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">project&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">dataset&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">String&lt;/span> &lt;span class="n">table&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">TableSchema&lt;/span> &lt;span class="n">schema&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">TableRow&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">rows&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// String project = &amp;#34;my-project-id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// String dataset = &amp;#34;my_bigquery_dataset_id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// String table = &amp;#34;my_bigquery_table_id&amp;#34;;
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// TableSchema schema = new TableSchema().setFields(Arrays.asList(...));
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// Pipeline pipeline = Pipeline.create();
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// PCollection&amp;lt;TableRow&amp;gt; rows = ...
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="n">rows&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;Write to BigQuery&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">writeTableRows&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">format&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;%s:%s.%s&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">project&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">dataset&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">table&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">schema&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="c1">// For CreateDisposition:
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// - CREATE_IF_NEEDED (default): creates the table if it doesn&amp;#39;t exist, a schema is
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// required
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// - CREATE_NEVER: raises an error if the table doesn&amp;#39;t exist, a schema is not needed
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withCreateDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CreateDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CREATE_IF_NEEDED&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="c1">// For WriteDisposition:
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// - WRITE_EMPTY (default): raises an error if the table is not empty
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// - WRITE_APPEND: appends new rows to existing rows
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// - WRITE_TRUNCATE: deletes the existing rows before writing
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withWriteDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">WriteDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">WRITE_TRUNCATE&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="c1">// pipeline.run().waitUntilFinish();
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">quotes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;source&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Mahatma Gandhi&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;quote&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;My life is my message.&amp;#39;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="s1">&amp;#39;source&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;Yoda&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;quote&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;Do, or do not. There is no &amp;#39;try&amp;#39;.&amp;#34;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">])&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;!-- WriteToBigQuery (python-only) -->
&lt;p class="language-py">The following example code shows how to apply a &lt;code>WriteToBigQuery&lt;/code> transform to
write a &lt;code>PCollection&lt;/code> of dictionaries to a BigQuery table. The write operation
creates a table if needed; if the table already exists, it will be replaced.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">quotes&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WriteToBigQuery&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">table_spec&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">schema&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">table_schema&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">write_disposition&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BigQueryDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">WRITE_TRUNCATE&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">create_disposition&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BigQueryDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CREATE_IF_NEEDED&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;!-- write (java-only) -->
&lt;p class="language-java">The &lt;code>write&lt;/code> transform writes a &lt;code>PCollection&lt;/code> of custom typed objects to a BigQuery
table. Use &lt;code>.withFormatFunction(SerializableFunction)&lt;/code> to provide a formatting
function that converts each input element in the &lt;code>PCollection&lt;/code> into a
&lt;code>TableRow&lt;/code>. This example uses &lt;code>write&lt;/code> to write a &lt;code>PCollection&amp;lt;String&amp;gt;&lt;/code>. The
write operation creates a table if needed; if the table already exists, it will
be replaced.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">quotes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">Quote&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableSpec&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableSchema&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withFormatFunction&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">Quote&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableRow&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;source&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">source&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;quote&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">quote&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withCreateDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CreateDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CREATE_IF_NEEDED&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withWriteDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">WriteDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">WRITE_TRUNCATE&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="language-java">When you use streaming inserts, you can decide what to do with failed records.
You can either keep retrying, or return the failed records in a separate
&lt;code>PCollection&lt;/code> using the &lt;code>WriteResult.getFailedInserts()&lt;/code> method.&lt;/p>
&lt;h3 id="using-dynamic-destinations">Using dynamic destinations&lt;/h3>
&lt;p class="language-py">&lt;blockquote>
&lt;p>The Beam SDK for Python does not currently support dynamic destinations.&lt;/p>
&lt;/blockquote>&lt;/p>
&lt;p>You can use the dynamic destinations feature to write elements in a
&lt;code>PCollection&lt;/code> to different BigQuery tables, possibly with different schemas.&lt;/p>
&lt;p>The dynamic destinations feature groups your user type by a user-defined
destination key, uses the key to compute a destination table and/or schema, and
writes each group&amp;rsquo;s elements to the computed destination.&lt;/p>
&lt;p>In addition, you can also write your own types that have a mapping function to
&lt;code>TableRow&lt;/code>, and you can use side inputs in all &lt;code>DynamicDestinations&lt;/code> methods.&lt;/p>
&lt;!-- Java specific -->
&lt;p class="language-java">To use dynamic destinations, you must create a &lt;code>DynamicDestinations&lt;/code> object and
implement the following methods:&lt;/p>
&lt;span class="language-java">&lt;ul>
&lt;li>
&lt;p>&lt;code>getDestination&lt;/code>: Returns an object that &lt;code>getTable&lt;/code> and &lt;code>getSchema&lt;/code> can use as
the destination key to compute the destination table and/or schema.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>getTable&lt;/code>: Returns the table (as a &lt;code>TableDestination&lt;/code> object) for the
destination key. This method must return a unique table for each unique
destination.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>getSchema&lt;/code>: Returns the table schema (as a &lt;code>TableSchema&lt;/code> object) for the
destination key.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/span>
&lt;p class="language-java">Then, use &lt;code>write().to&lt;/code> with your &lt;code>DynamicDestinations&lt;/code> object. This example
uses a &lt;code>PCollection&lt;/code> that contains weather data and writes the data into a
different table for each year.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="cm">/*
&lt;/span>&lt;span class="cm">@DefaultCoder(AvroCoder.class)
&lt;/span>&lt;span class="cm">static class WeatherData {
&lt;/span>&lt;span class="cm"> final long year;
&lt;/span>&lt;span class="cm"> final long month;
&lt;/span>&lt;span class="cm"> final long day;
&lt;/span>&lt;span class="cm"> final double maxTemp;
&lt;/span>&lt;span class="cm">
&lt;/span>&lt;span class="cm"> public WeatherData() {
&lt;/span>&lt;span class="cm"> this.year = 0;
&lt;/span>&lt;span class="cm"> this.month = 0;
&lt;/span>&lt;span class="cm"> this.day = 0;
&lt;/span>&lt;span class="cm"> this.maxTemp = 0.0f;
&lt;/span>&lt;span class="cm"> }
&lt;/span>&lt;span class="cm"> public WeatherData(long year, long month, long day, double maxTemp) {
&lt;/span>&lt;span class="cm"> this.year = year;
&lt;/span>&lt;span class="cm"> this.month = month;
&lt;/span>&lt;span class="cm"> this.day = day;
&lt;/span>&lt;span class="cm"> this.maxTemp = maxTemp;
&lt;/span>&lt;span class="cm"> }
&lt;/span>&lt;span class="cm">}
&lt;/span>&lt;span class="cm">*/&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">WeatherData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">weatherData&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">p&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">read&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">SchemaAndRecord&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">GenericRecord&lt;/span> &lt;span class="n">record&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getRecord&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">WeatherData&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">record&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;year&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">record&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;month&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">record&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;day&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">Double&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">record&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;max_temperature&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="o">})&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">fromQuery&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="s">&amp;#34;SELECT year, month, day, max_temperature &amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;FROM [clouddataflow-readonly:samples.weather_stations] &amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;WHERE year BETWEEN 2007 AND 2009&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withCoder&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">AvroCoder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">WeatherData&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)));&lt;/span>
&lt;span class="c1">// We will send the weather data into different tables for every year.
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">weatherData&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">WeatherData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">DynamicDestinations&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">WeatherData&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Long&lt;/span> &lt;span class="nf">getDestination&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ValueInSingleWindow&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">WeatherData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getValue&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">year&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">TableDestination&lt;/span> &lt;span class="nf">getTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Long&lt;/span> &lt;span class="n">destination&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TableDestination&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableReference&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setProjectId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">writeProject&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setDatasetId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">writeDataset&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setTableId&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">writeTable&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;_&amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">destination&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="s">&amp;#34;Table for year &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">destination&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">TableSchema&lt;/span> &lt;span class="nf">getSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Long&lt;/span> &lt;span class="n">destination&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TableSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setFields&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">ImmutableList&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;year&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;INTEGER&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setMode&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;REQUIRED&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;month&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;INTEGER&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setMode&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;REQUIRED&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;day&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;INTEGER&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setMode&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;REQUIRED&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableFieldSchema&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTemp&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;FLOAT&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setMode&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;NULLABLE&amp;#34;&lt;/span>&lt;span class="o">)));&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">})&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withFormatFunction&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">WeatherData&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableRow&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;year&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">year&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;month&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">month&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;day&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">day&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTemp&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">maxTemp&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withCreateDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CreateDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CREATE_IF_NEEDED&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withWriteDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">WriteDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">WRITE_TRUNCATE&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># The Beam SDK for Python does not currently support dynamic destinations.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="using-time-partitioning">Using time partitioning&lt;/h3>
&lt;p class="language-py">&lt;blockquote>
&lt;p>The Beam SDK for Python does not currently support time partitioning.&lt;/p>
&lt;/blockquote>&lt;/p>
&lt;p>BigQuery time partitioning divides your table into smaller partitions, which is
called a &lt;a href="https://cloud.google.com/bigquery/docs/partitioned-tables">partitioned table&lt;/a>.
Partitioned tables make it easier for you to manage and query your data.&lt;/p>
&lt;!-- Java specific -->
&lt;p class="language-java">To use BigQuery time partitioning, use one of these two methods:&lt;/p>
&lt;span class="language-java">&lt;ul>
&lt;li>
&lt;p>&lt;code>withTimePartitioning&lt;/code>: This method takes a &lt;code>TimePartitioning&lt;/code> class, and is
only usable if you are writing to a single table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>withJsonTimePartitioning&lt;/code>: This method is the same as
&lt;code>withTimePartitioning&lt;/code>, but takes a JSON-serialized String object.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/span>
&lt;p class="language-java">This example generates one partition per day.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">weatherData&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">BigQueryIO&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">WeatherData&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">to&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableSpec&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;_partitioning&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withSchema&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableSchema&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withFormatFunction&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="o">(&lt;/span>&lt;span class="n">WeatherData&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span>
&lt;span class="k">new&lt;/span> &lt;span class="n">TableRow&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;year&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">year&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;month&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">month&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;day&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">day&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;maxTemp&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">elem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">maxTemp&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="c1">// NOTE: an existing table without time partitioning set up will not work
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">.&lt;/span>&lt;span class="na">withTimePartitioning&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">TimePartitioning&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;DAY&amp;#34;&lt;/span>&lt;span class="o">))&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withCreateDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CreateDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CREATE_IF_NEEDED&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">withWriteDisposition&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">WriteDisposition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">WRITE_TRUNCATE&lt;/span>&lt;span class="o">));&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="c1"># The Beam SDK for Python does not currently support time partitioning.&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h2 id="limitations">Limitations&lt;/h2>
&lt;p>BigQueryIO currently has the following limitations.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>You can’t sequence the completion of a BigQuery write with other steps of
your pipeline.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you are using the Beam SDK for Python, you might have import size quota
issues if you write a very large dataset. As a workaround, you can partition
the dataset (for example, using Beam&amp;rsquo;s &lt;code>Partition&lt;/code> transform) and write to
multiple BigQuery tables. The Beam SDK for Java does not have this limitation
as it partitions your dataset for you.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="additional-examples">Additional examples&lt;/h2>
&lt;p>You can find additional examples that use BigQuery in Beam&amp;rsquo;s examples
directories.&lt;/p>
&lt;h3 id="java-cookbook-examples">Java cookbook examples&lt;/h3>
&lt;p>These examples are from the Java &lt;a href="https://github.com/apache/beam/tree/master/examples/java/src/main/java/org/apache/beam/examples/cookbook">cookbook examples&lt;/a>
directory.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/BigQueryTornadoes.java">BigQueryTornadoes&lt;/a>
reads the public samples of weather data from BigQuery, counts the number of
tornadoes that occur in each month, and writes the results to a BigQuery
table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/CombinePerKeyExamples.java">CombinePerKeyExamples&lt;/a>
reads the public Shakespeare data from BigQuery, and for each word in the
dataset that exceeds a given length, generates a string containing the list of
play names in which that word appears. The pipeline then writes the results to
a BigQuery table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/FilterExamples.java">FilterExamples&lt;/a>
reads public samples of weather data from BigQuery, performs a projection
on the data, finds the global mean of the temperature readings, filters on
readings for a single given month, and outputs only data (for that month)
that has a mean temp smaller than the derived global mean.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/JoinExamples.java">JoinExamples&lt;/a>
reads a sample of the &lt;a href="https://goo.gl/OB6oin">GDELT &amp;ldquo;world event&amp;rdquo;&lt;/a> from
BigQuery and joins the event &lt;code>action&lt;/code> country code against a table that maps
country codes to country names.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/MaxPerKeyExamples.java">MaxPerKeyExamples&lt;/a>
reads the public samples of weather data from BigQuery, finds the maximum
temperature for each month, and writes the results to a BigQuery table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/TriggerExample.java">TriggerExample&lt;/a>
performs a streaming analysis of traffic data from San Diego freeways. The
pipeline looks at the data coming in from a text file and writes the results
to a BigQuery table.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="java-complete-examples">Java complete examples&lt;/h3>
&lt;p>These examples are from the Java &lt;a href="https://github.com/apache/beam/tree/master/examples/java/src/main/java/org/apache/beam/examples/complete">complete examples&lt;/a>
directory.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/complete/AutoComplete.java">AutoComplete&lt;/a>
computes the most popular hash tags for every prefix, which can be used for
auto-completion. The pipeline can optionally write the results to a BigQuery
table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/complete/StreamingWordExtract.java">StreamingWordExtract&lt;/a>
reads lines of text, splits each line into individual words, capitalizes those
words, and writes the output to a BigQuery table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/complete/TrafficMaxLaneFlow.java">TrafficMaxLaneFlow&lt;/a>
reads traffic sensor data, finds the lane that had the highest recorded flow,
and writes the results to a BigQuery table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/complete/TrafficRoutes.java">TrafficRoutes&lt;/a>
reads traffic sensor data, calculates the average speed for each window and
looks for slowdowns in routes, and writes the results to a BigQuery table.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="python-cookbook-examples">Python cookbook examples&lt;/h3>
&lt;p>These examples are from the Python &lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/examples/cookbook">cookbook examples&lt;/a>
directory.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/cookbook/bigquery_schema.py">BigQuery schema&lt;/a>
creates a &lt;code>TableSchema&lt;/code> with nested and repeated fields, generates data with
nested and repeated fields, and writes the data to a BigQuery table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/cookbook/bigquery_side_input.py">BigQuery side inputs&lt;/a>
uses BigQuery sources as a side inputs. It illustrates how to insert
side-inputs into transforms in three different forms: as a singleton, as a
iterator, and as a list.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/cookbook/bigquery_tornadoes.py">BigQuery tornadoes&lt;/a>
reads from a BigQuery table that has the &amp;lsquo;month&amp;rsquo; and &amp;lsquo;tornado&amp;rsquo; fields as part
of the table schema, computes the number of tornadoes in each month, and
outputs the results to a BigQuery table.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/cookbook/filters.py">BigQuery filters&lt;/a>
reads weather station data from a BigQuery table, manipulates BigQuery rows in
memory, and writes the results to a BigQuery table.&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Documentation: GroupBy</title><link>/documentation/transforms/python/aggregation/groupby/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/groupby/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="groupby">GroupBy&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.GroupBy"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Takes a collection of elements and produces a collection grouped,
by properties of those elements.&lt;/p>
&lt;p>Unlike &lt;code>GroupByKey&lt;/code>, the key is dynamically created from the elements themselves.&lt;/p>
&lt;h2 id="grouping-examples">Grouping Examples&lt;/h2>
&lt;p>In the following example, we create a pipeline with a &lt;code>PCollection&lt;/code> of fruits.&lt;/p>
&lt;p>We use &lt;code>GroupBy&lt;/code> to group all fruits by the first letter of their name.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">grouped&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="s1">&amp;#39;strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;raspberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;blueberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;blackberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;banana&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GroupBy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;s&amp;#39;, [&amp;#39;strawberry&amp;#39;]),
(&amp;#39;r&amp;#39;, [&amp;#39;raspberry&amp;#39;]),
(&amp;#39;b&amp;#39;, [&amp;#39;banana&amp;#39;, &amp;#39;blackberry&amp;#39;, &amp;#39;blueberry&amp;#39;]),&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/groupby_test.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>We can group by a composite key consisting of multiple properties if desired.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">grouped&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="s1">&amp;#39;strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;raspberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;blueberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;blackberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;banana&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GroupBy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">letter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">is_berry&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;berry&amp;#39;&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>The resulting key is a named tuple with the two requested attributes, and the
values are grouped accordingly.&lt;/p>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(NamedTuple(letter=&amp;#39;s&amp;#39;, is_berry=True), [&amp;#39;strawberry&amp;#39;]),
(NamedTuple(letter=&amp;#39;r&amp;#39;, is_berry=True), [&amp;#39;raspberry&amp;#39;]),
(NamedTuple(letter=&amp;#39;b&amp;#39;, is_berry=True), [&amp;#39;blackberry&amp;#39;, &amp;#39;blueberry&amp;#39;]),
(NamedTuple(letter=&amp;#39;b&amp;#39;, is_berry=False), [&amp;#39;banana&amp;#39;]),&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/groupby_test.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>In the case that the property one wishes to group by is an attribute, a string
may be passed to &lt;code>GroupBy&lt;/code> in the place of a callable expression. For example,
suppose I have the following data&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="n">GROCERY_LIST&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">recipe&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;pie&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fruit&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;strawberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">quantity&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">unit_price&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">1.50&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">recipe&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;pie&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fruit&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;raspberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">quantity&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">unit_price&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">3.50&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">recipe&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;pie&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fruit&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;blackberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">quantity&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">unit_price&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">4.00&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">recipe&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;pie&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fruit&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;blueberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">quantity&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">unit_price&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">2.00&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">recipe&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;muffin&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fruit&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;blueberry&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">quantity&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">unit_price&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">2.00&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Row&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">recipe&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;muffin&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fruit&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;banana&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">quantity&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">unit_price&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">1.00&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>We can then do&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">grouped&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">GROCERY_LIST&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GroupBy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;recipe&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;pie&amp;#39;,
[
beam.Row(recipe=&amp;#39;pie&amp;#39;, fruit=&amp;#39;strawberry&amp;#39;, quantity=3, unit_price=1.50),
beam.Row(recipe=&amp;#39;pie&amp;#39;, fruit=&amp;#39;raspberry&amp;#39;, quantity=1, unit_price=3.50),
beam.Row(recipe=&amp;#39;pie&amp;#39;, fruit=&amp;#39;blackberry&amp;#39;, quantity=1, unit_price=4.00),
beam.Row(recipe=&amp;#39;pie&amp;#39;, fruit=&amp;#39;blueberry&amp;#39;, quantity=1, unit_price=2.00),
]),
(&amp;#39;muffin&amp;#39;,
[
beam.Row(recipe=&amp;#39;muffin&amp;#39;, fruit=&amp;#39;blueberry&amp;#39;, quantity=2, unit_price=2.00),
beam.Row(recipe=&amp;#39;muffin&amp;#39;, fruit=&amp;#39;banana&amp;#39;, quantity=3, unit_price=1.00),
]),&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/groupby_test.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>It is possible to mix and match attributes and expressions, for example&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">grouped&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">GROCERY_LIST&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GroupBy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;recipe&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">is_berry&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;berry&amp;#39;&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fruit&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(NamedTuple(recipe=&amp;#39;pie&amp;#39;, is_berry=True),
[
beam.Row(recipe=&amp;#39;pie&amp;#39;, fruit=&amp;#39;strawberry&amp;#39;, quantity=3, unit_price=1.50),
beam.Row(recipe=&amp;#39;pie&amp;#39;, fruit=&amp;#39;raspberry&amp;#39;, quantity=1, unit_price=3.50),
beam.Row(recipe=&amp;#39;pie&amp;#39;, fruit=&amp;#39;blackberry&amp;#39;, quantity=1, unit_price=4.00),
beam.Row(recipe=&amp;#39;pie&amp;#39;, fruit=&amp;#39;blueberry&amp;#39;, quantity=1, unit_price=2.00),
]),
(NamedTuple(recipe=&amp;#39;muffin&amp;#39;, is_berry=True),
[
beam.Row(recipe=&amp;#39;muffin&amp;#39;, fruit=&amp;#39;blueberry&amp;#39;, quantity=2, unit_price=2.00),
]),
(NamedTuple(recipe=&amp;#39;muffin&amp;#39;, is_berry=False),
[
beam.Row(recipe=&amp;#39;muffin&amp;#39;, fruit=&amp;#39;banana&amp;#39;, quantity=3, unit_price=1.00),
]),&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/groupby_test.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
.&lt;/p>
&lt;h2 id="aggregation">Aggregation&lt;/h2>
&lt;p>Grouping is often used in conjunction with aggregation, and the
&lt;code>aggregate_field&lt;/code> method of the &lt;code>GroupBy&lt;/code> transform can be used to accomplish
this easily.
This method takes three parameters: the field (or expression) which to
aggregate, the &lt;code>CombineFn&lt;/code> (or associative &lt;code>callable&lt;/code>) with which to aggregate
by, and finally a field name in which to store the result.
For example, suppose one wanted to compute the amount of each fruit to buy.
One could write&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">grouped&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">GROCERY_LIST&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GroupBy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;fruit&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="n">aggregate_field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;quantity&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;total_quantity&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>NamedTuple(fruit=&amp;#39;strawberry&amp;#39;, total_quantity=3),
NamedTuple(fruit=&amp;#39;raspberry&amp;#39;, total_quantity=1),
NamedTuple(fruit=&amp;#39;blackberry&amp;#39;, total_quantity=1),
NamedTuple(fruit=&amp;#39;blueberry&amp;#39;, total_quantity=3),
NamedTuple(fruit=&amp;#39;banana&amp;#39;, total_quantity=3),&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/groupby_test.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
.&lt;/p>
&lt;p>Similar to the parameters in &lt;code>GroupBy&lt;/code>, one can also aggregate multiple fields
and by expressions.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">grouped&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">GROCERY_LIST&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GroupBy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;recipe&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="n">aggregate_field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;quantity&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;total_quantity&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="n">aggregate_field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">quantity&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unit_price&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;price&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>NamedTuple(recipe=&amp;#39;pie&amp;#39;, total_quantity=6, price=14.00),
NamedTuple(recipe=&amp;#39;muffin&amp;#39;, total_quantity=5, price=7.00),&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/groupby_test.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
.&lt;/p>
&lt;p>One can, of course, aggregate the same field multiple times as well.
This example also illustrates a global grouping, as the grouping key is empty.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">grouped&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">p&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">GROCERY_LIST&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GroupBy&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="n">aggregate_field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;unit_price&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;min_price&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="n">aggregate_field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;unit_price&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">MeanCombineFn&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="s1">&amp;#39;mean_price&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="n">aggregate_field&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;unit_price&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">max&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;max_price&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>NamedTuple(min_price=1.00, mean_price=7 / 3, max_price=4.00),&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/groupby_test.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/combineperkey">CombinePerKey&lt;/a> for combining with a single CombineFn.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/groupbykey">GroupByKey&lt;/a> for grouping with a known key.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/cogroupbykey">CoGroupByKey&lt;/a> for multiple input collections.&lt;/li>
&lt;/ul>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.GroupByKey"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: GroupByKey</title><link>/documentation/transforms/java/aggregation/groupbykey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/groupbykey/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="groupbykey">GroupByKey&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/GroupByKey.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Takes a keyed collection of elements and produces a collection where
each element consists of a key and an &lt;code>Iterable&lt;/code> of all values
associated with that key.&lt;/p>
&lt;p>The results can be combined with windowing to subdivide each key
based on time or triggering to produce partial aggregations. Either
windowing or triggering is necessary when processing unbounded collections.&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#groupbykey">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>&lt;strong>Example 1&lt;/strong>: (a, 1), (b, 2), (a, 3) will result into (a, [1, 3]), (b, [2]).&lt;/p>
&lt;p>&lt;strong>Example 2&lt;/strong>: Given a collection of customer orders keyed by postal code,
you could use &lt;code>GroupByKey&lt;/code> to get the collection of all orders in each postal code.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/cogroupbykey">CoGroupByKey&lt;/a>
for multiple input collections&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/combine">Combine&lt;/a>
for combining all values associated with a key to a single result&lt;/li>
&lt;/ul></description></item><item><title>Documentation: GroupByKey</title><link>/documentation/transforms/python/aggregation/groupbykey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/groupbykey/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="groupbykey">GroupByKey&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.GroupByKey"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Takes a keyed collection of elements and produces a collection
where each element consists of a key and all values associated with that key.&lt;/p>
&lt;p>See more information in the &lt;a href="/documentation/programming-guide/#groupbykey">Beam Programming Guide&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following example, we create a pipeline with a &lt;code>PCollection&lt;/code> of produce keyed by season.&lt;/p>
&lt;p>We use &lt;code>GroupByKey&lt;/code> to group all the produce for each season.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">produce_counts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce counts&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;fall&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;fall&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;winter&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Group counts per produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GroupByKey&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;spring&amp;#39;, [&amp;#39;🍓&amp;#39;, &amp;#39;🥕&amp;#39;, &amp;#39;🍆&amp;#39;, &amp;#39;🍅&amp;#39;])
(&amp;#39;summer&amp;#39;, [&amp;#39;🥕&amp;#39;, &amp;#39;🍅&amp;#39;, &amp;#39;🌽&amp;#39;])
(&amp;#39;fall&amp;#39;, [&amp;#39;🥕&amp;#39;, &amp;#39;🍅&amp;#39;])
(&amp;#39;winter&amp;#39;, [&amp;#39;🍆&amp;#39;])&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/groupbykey.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/groupby">GroupBy&lt;/a> for grouping by arbitrary properties of the elements.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/combineperkey">CombinePerKey&lt;/a> for combining all values associated with a key to a single result.&lt;/li>
&lt;li>&lt;a href="/documentation/transforms/python/aggregation/cogroupbykey">CoGroupByKey&lt;/a> for multiple input collections.&lt;/li>
&lt;/ul>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.core.html#apache_beam.transforms.core.GroupByKey"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: GroupIntoBatches</title><link>/documentation/transforms/java/aggregation/groupintobatches/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/groupintobatches/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="groupintobatches">GroupIntoBatches&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/transforms/GroupIntoBatches.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Batches inputs to a desired batch size.&lt;/p>
&lt;p>Batches contain only elements of a single key. Elements are buffered until
&lt;code>batchSize&lt;/code> number of elements buffered. Then, these elements are output
to the output collection.&lt;/p>
&lt;p>Batches contain elements from the same window, so windows are preserved. Batches might contain elements from more than one bundle.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>See &lt;a href="https://issues.apache.org/jira/browse/BEAM-7703">BEAM-7703&lt;/a> for updates.&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/groupbykey">GroupByKey&lt;/a> takes one input collection.&lt;/li>
&lt;/ul></description></item><item><title>Documentation: GroupIntoBatches</title><link>/documentation/transforms/python/aggregation/groupintobatches/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/python/aggregation/groupintobatches/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="groupintobatches">GroupIntoBatches&lt;/h1>
&lt;script type="text/javascript">
localStorage.setItem("language", "language-py")
&lt;/script>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html#apache_beam.transforms.util.GroupIntoBatches"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;p>Batches the input into desired batch size.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>In the following example, we create a pipeline with a &lt;code>PCollection&lt;/code> of produce by season.&lt;/p>
&lt;p>We use &lt;code>GroupIntoBatches&lt;/code> to get fixed-sized batches for every key, which outputs a list of elements for every key.&lt;/p>
&lt;div class=language-py>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="kn">import&lt;/span> &lt;span class="nn">apache_beam&lt;/span> &lt;span class="kn">as&lt;/span> &lt;span class="nn">beam&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pipeline&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">pipeline&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">batches_with_keys&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="n">pipeline&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Create produce&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Create&lt;/span>&lt;span class="p">([&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍓&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;spring&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;summer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🌽&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;fall&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🥕&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;fall&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍅&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;winter&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;🍆&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">])&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="s1">&amp;#39;Group into batches&amp;#39;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GroupIntoBatches&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">|&lt;/span> &lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">print&lt;/span>&lt;span class="p">))&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p class="notebook-skip">Output:&lt;/p>
&lt;div class=notebook-skip>
&lt;pre>&lt;code>(&amp;#39;spring&amp;#39;, [&amp;#39;🍓&amp;#39;, &amp;#39;🥕&amp;#39;, &amp;#39;🍆&amp;#39;])
(&amp;#39;summer&amp;#39;, [&amp;#39;🥕&amp;#39;, &amp;#39;🍅&amp;#39;, &amp;#39;🌽&amp;#39;])
(&amp;#39;spring&amp;#39;, [&amp;#39;🍅&amp;#39;])
(&amp;#39;fall&amp;#39;, [&amp;#39;🥕&amp;#39;, &amp;#39;🍅&amp;#39;])
(&amp;#39;winter&amp;#39;, [&amp;#39;🍆&amp;#39;])&lt;/code>&lt;/pre>
&lt;/div>
&lt;table align="left" style="margin-right:1em" class=".language-py" >
&lt;td>
&lt;a class="button" target="_blank" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/aggregation/groupintobatches.py">&lt;img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" width="32px" height="32px" alt="View source code" /> View source code&lt;/a>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;!-- TODO(BEAM-10889): Create a page for BatchElements and link to it here. //-->
&lt;p>For unkeyed data and dynamic batch sizes, one may want to use
&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html#apache_beam.transforms.util.BatchElements">BatchElements&lt;/a>.&lt;/p>
&lt;table align="left" style="margin-right:1em">
&lt;td>
&lt;a
class="button"
target="_blank"
href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html#apache_beam.transforms.util.GroupIntoBatches"
>&lt;img
src="https://beam.apache.org/images/logos/sdks/python.png"
width="32px"
height="32px"
alt="Pydoc"
/>
Pydoc&lt;/a
>
&lt;/td>
&lt;/table>
&lt;p>&lt;br>&lt;br>&lt;br>&lt;/p></description></item><item><title>Documentation: HllCount</title><link>/documentation/transforms/java/aggregation/hllcount/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/aggregation/hllcount/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="latest">Latest&lt;/h1>
&lt;table align="left">
&lt;a target="_blank" class="button"
href="https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/extensions/zetasketch/HllCount.html">
&lt;img src="https://beam.apache.org/images/logos/sdks/java.png" width="20px" height="20px"
alt="Javadoc" />
Javadoc
&lt;/a>
&lt;/table>
&lt;br>&lt;br>
&lt;p>Estimates the number of distinct elements in a data stream using the
&lt;a href="https://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/40671.pdf">HyperLogLog++ algorithm&lt;/a>.
The respective transforms to create and merge sketches, and to extract from them, are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>HllCount.Init&lt;/code> aggregates inputs into HLL++ sketches.&lt;/li>
&lt;li>&lt;code>HllCount.MergePartial&lt;/code> merges HLL++ sketches into a new sketch.&lt;/li>
&lt;li>&lt;code>HllCount.Extract&lt;/code> extracts the estimated count of distinct elements from HLL++ sketches.&lt;/li>
&lt;/ul>
&lt;p>You can read more about what a sketch is at &lt;a href="https://github.com/google/zetasketch">https://github.com/google/zetasketch&lt;/a>.&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>&lt;strong>Example 1&lt;/strong>: creates a long-type sketch for a &lt;code>PCollection&amp;lt;Long&amp;gt;&lt;/code> with a custom precision:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&lt;/span> &lt;span class="n">sketch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HllCount&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Init&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">forLongs&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">withPrecision&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">globally&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;p>&lt;strong>Example 2&lt;/strong>: creates a bytes-type sketch for a &lt;code>PCollection&amp;lt;KV&amp;lt;String, byte[]&amp;gt;&amp;gt;&lt;/code>:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">KV&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">sketch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HllCount&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Init&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">forBytes&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">perKey&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;p>&lt;strong>Example 3&lt;/strong>: merges existing sketches in a &lt;code>PCollection&amp;lt;byte[]&amp;gt;&lt;/code> into a new sketch,
which summarizes the union of the inputs that were aggregated in the merged sketches:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&lt;/span> &lt;span class="n">sketches&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&lt;/span> &lt;span class="n">mergedSketch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sketches&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HllCount&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">MergePartial&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">globally&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;p>&lt;strong>Example 4&lt;/strong>: estimates the count of distinct elements in a &lt;code>PCollection&amp;lt;String&amp;gt;&lt;/code>:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">countDistinct&lt;/span> &lt;span class="o">=&lt;/span>
&lt;span class="n">input&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HllCount&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Init&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">forStrings&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">globally&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HllCount&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Extract&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">globally&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;p>&lt;strong>Example 5&lt;/strong>: extracts the count distinct estimate from an existing sketch:
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&lt;/span> &lt;span class="n">sketch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">countDistinct&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sketch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HllCount&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Extract&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">globally&lt;/span>&lt;span class="o">());&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/p>
&lt;h2 id="related-transforms">Related transforms&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="/documentation/transforms/java/aggregation/approximateunique">ApproximateUnique&lt;/a>
estimates the number of distinct elements or values in key-value pairs (but does not expose sketches; also less accurate than &lt;code>HllCount&lt;/code>).&lt;/li>
&lt;/ul></description></item><item><title>Documentation: Java transform catalog overview</title><link>/documentation/transforms/java/overview/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/transforms/java/overview/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="java-transform-catalog-overview">Java transform catalog overview&lt;/h1>
&lt;h2 id="element-wise">Element-wise&lt;/h2>
&lt;table class="table-bordered table-striped">
&lt;tr>&lt;th>Transform&lt;/th>&lt;th>Description&lt;/th>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/filter">Filter&lt;/a>&lt;/td>&lt;td>Given a predicate, filter out all elements that don't satisfy the predicate.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/flatmapelements">FlatMapElements&lt;/a>&lt;/td>&lt;td>Applies a function that returns a collection to every element in the input and
outputs all resulting elements.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/keys">Keys&lt;/a>&lt;/td>&lt;td>Extracts the key from each element in a collection of key-value pairs.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/kvswap">KvSwap&lt;/a>&lt;/td>&lt;td>Swaps the key and value of each element in a collection of key-value pairs.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/mapelements">MapElements&lt;/a>&lt;/td>&lt;td>Applies a function to every element in the input and outputs the result.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/pardo">ParDo&lt;/a>&lt;/td>&lt;td>The most-general mechanism for applying a user-defined &lt;code>DoFn&lt;/code> to every element
in the input collection.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/partition">Partition&lt;/a>&lt;/td>&lt;td>Routes each input element to a specific output collection based on some partition
function.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/regex">Regex&lt;/a>&lt;/td>&lt;td>Filters input string elements based on a regex. May also transform them based on the matching groups.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/reify">Reify&lt;/a>&lt;/td>&lt;td>Transforms for converting between explicit and implicit form of various Beam values.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/tostring">ToString&lt;/a>&lt;/td>&lt;td>Transforms every element in an input collection to a string.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/withkeys">WithKeys&lt;/a>&lt;/td>&lt;td>Produces a collection containing each element from the input collection converted to a key-value pair, with a key selected by applying a function to the input element.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/withtimestamps">WithTimestamps&lt;/a>&lt;/td>&lt;td>Applies a function to determine a timestamp to each element in the output collection,
and updates the implicit timestamp associated with each input. Note that it is only safe to adjust timestamps forwards.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/elementwise/values">Values&lt;/a>&lt;/td>&lt;td>Extracts the value from each element in a collection of key-value pairs.&lt;/td>&lt;/tr>
&lt;/table>
&lt;h2 id="aggregation">Aggregation&lt;/h2>
&lt;table class="table-bordered table-striped">
&lt;tr>&lt;th>Transform&lt;/th>&lt;th>Description&lt;/th>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/approximatequantiles">ApproximateQuantiles&lt;/a>&lt;/td>&lt;td>Uses an approximation algorithm to estimate the data distribution within each aggregation using a specified number of quantiles.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/approximateunique">ApproximateUnique&lt;/a>&lt;/td>&lt;td>Uses an approximation algorithm to estimate the number of unique elements within each aggregation.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/cogroupbykey/">CoGroupByKey&lt;/a>&lt;/td>&lt;td>Similar to &lt;code>GroupByKey&lt;/code>, but groups values associated with each key into a batch of a given size&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/combine">Combine&lt;/a>&lt;/td>&lt;td>Transforms to combine elements according to a provided &lt;code>CombineFn&lt;/code>.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/combinewithcontext">CombineWithContext&lt;/a>&lt;/td>&lt;td>An extended version of Combine which allows accessing side-inputs and other context.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/count">Count&lt;/a>&lt;/td>&lt;td>Counts the number of elements within each aggregation.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/distinct">Distinct&lt;/a>&lt;/td>&lt;td>Produces a collection containing distinct elements from the input collection.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/groupbykey">GroupByKey&lt;/a>&lt;/td>&lt;td>Takes a keyed collection of elements and produces a collection where each element
consists of a key and all values associated with that key.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/groupintobatches">GroupIntoBatches&lt;/a>&lt;/td>&lt;td>Batches values associated with keys into &lt;code>Iterable&lt;/code> batches of some size. Each batch contains elements associated with a specific key.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/hllcount">HllCount&lt;/a>&lt;/td>&lt;td>Estimates the number of distinct elements and creates re-aggregatable sketches using the HyperLogLog++ algorithm.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/latest">Latest&lt;/a>&lt;/td>&lt;td>Selects the latest element within each aggregation according to the implicit timestamp.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/max">Max&lt;/a>&lt;/td>&lt;td>Outputs the maximum element within each aggregation.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/mean">Mean&lt;/a>&lt;/td>&lt;td>Computes the average within each aggregation.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/min">Min&lt;/a>&lt;/td>&lt;td>Outputs the minimum element within each aggregation.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/sample">Sample&lt;/a>&lt;/td>&lt;td>Randomly select some number of elements from each aggregation.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/sum">Sum&lt;/a>&lt;/td>&lt;td>Compute the sum of elements in each aggregation.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/aggregation/top">Top&lt;/a>&lt;/td>&lt;td>Compute the largest element(s) in each aggregation.&lt;/td>&lt;/tr>
&lt;/table>
&lt;h2 id="other">Other&lt;/h2>
&lt;table class="table-bordered table-striped">
&lt;tr>&lt;th>Transform&lt;/th>&lt;th>Description&lt;/th>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/other/create">Create&lt;/a>&lt;/td>&lt;td>Creates a collection from an in-memory list.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/other/flatten">Flatten&lt;/a>&lt;/td>&lt;td>Given multiple input collections, produces a single output collection containing
all elements from all of the input collections.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/other/passert">PAssert&lt;/a>&lt;/td>&lt;td>A transform to assert the contents of a &lt;code>PCollection&lt;/code> used as part of testing a pipeline either locally or with a runner.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/other/view">View&lt;/a>&lt;/td>&lt;td>Operations for turning a collection into view that may be used as a side-input to a &lt;code>ParDo&lt;/code>.&lt;/td>&lt;/tr>
&lt;tr>&lt;td>&lt;a href="/documentation/transforms/java/other/window">Window&lt;/a>&lt;/td>&lt;td>Logically divides up or groups the elements of a collection into finite
windows according to a provided &lt;code>WindowFn&lt;/code>.&lt;/td>&lt;/tr>
&lt;/table></description></item><item><title>Documentation: JStorm Runner</title><link>/documentation/runners/jstorm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/documentation/runners/jstorm/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="using-the-jstorm-runner">Using the JStorm Runner&lt;/h1>
&lt;p>The JStorm Runner can be used to execute Beam pipelines using &lt;a href="http://jstorm.io/">JStorm&lt;/a>, while providing:&lt;/p>
&lt;ul>
&lt;li>High throughput and low latency.&lt;/li>
&lt;li>At-least-once and exactly-once fault tolerance.&lt;/li>
&lt;/ul>
&lt;p>Like a native JStorm topology, users can execute Beam topology with local mode, standalone cluster or jstorm-on-yarn cluster.&lt;/p>
&lt;p>The &lt;a href="/documentation/runners/capability-matrix/">Beam Capability Matrix&lt;/a> documents the currently supported capabilities of the JStorm Runner.&lt;/p>
&lt;h2 id="jstorm-runner-prerequisites-and-setup">JStorm Runner prerequisites and setup&lt;/h2>
&lt;p>The JStorm runner currently supports JStorm version 2.5.0-SNAPSHOT.&lt;/p>
&lt;p>You can add a dependency on the latest version of the JStorm runner by adding the following to your pom.xml:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">beam&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">runners&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">jstorm&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">24&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">0&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="deploying-jstorm-with-your-application">Deploying JStorm with your application&lt;/h3>
&lt;p>To run against a Standalone cluster, you can package your program with all Beam dependencies into a fat jar, and then submit the topology with the following command.&lt;/p>
&lt;pre>&lt;code>jstorm jar WordCount.jar org.apache.beam.examples.WordCount --runner=org.apache.beam.runners.jstorm.JStormRunner
&lt;/code>&lt;/pre>&lt;p>If you don&amp;rsquo;t want to package a fat jar, you can upload the Beam dependencies onto all cluster nodes(&lt;code>$JSTORM_HOME/lib/ext/beam&lt;/code>) first.
When you submit a topology with argument &lt;code>&amp;quot;--external-libs beam&amp;quot;&lt;/code>, JStorm will load the Beam dependencies automatically.&lt;/p>
&lt;pre>&lt;code>jstorm jar WordCount.jar org.apache.beam.examples.WordCount --external-libs beam --runner=org.apache.beam.runners.jstorm.JStormRunner
&lt;/code>&lt;/pre>&lt;p>To learn about deploying a JStorm cluster, please refer to &lt;a href="http://jstorm.io/QuickStart/Deploy/index.html">JStorm cluster deploy&lt;/a>&lt;/p>
&lt;h2 id="pipeline-options-for-the-jstorm-runner">Pipeline options for the JStorm Runner&lt;/h2>
&lt;p>When executing your pipeline with the JStorm Runner, you should consider the following pipeline options.&lt;/p>
&lt;table class="table table-bordered">
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>Default Value&lt;/th>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>runner&lt;/code>&lt;/td>
&lt;td>The pipeline runner to use. This option allows you to determine the pipeline runner at runtime.&lt;/td>
&lt;td>Set to &lt;code>JStormRunner&lt;/code> to run using JStorm.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>topologyConfig&lt;/code>&lt;/td>
&lt;td>System topology config of JStorm&lt;/td>
&lt;td>DefaultMapValueFactory.class&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>workerNumber&lt;/code>&lt;/td>
&lt;td>Worker number of topology&lt;/td>
&lt;td>1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>parallelism&lt;/code>&lt;/td>
&lt;td>Global parallelism number of a component&lt;/td>
&lt;td>1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>parallelismMap&lt;/code>&lt;/td>
&lt;td>Parallelism number of a specified composite PTransform&lt;/td>
&lt;td>DefaultMapValueFactory.class&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>exactlyOnceTopology&lt;/code>&lt;/td>
&lt;td>Indicate if it is an exactly once topology&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>localMode&lt;/code>&lt;/td>
&lt;td>Indicate if the topology is running on local machine or distributed cluster&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>localModeExecuteTimeSec&lt;/code>&lt;/td>
&lt;td>Executing time(sec) of topology on local mode.&lt;/td>
&lt;td>60&lt;/td>
&lt;/tr>
&lt;/table>
&lt;h2 id="additional-notes">Additional notes&lt;/h2>
&lt;h3 id="monitoring-your-job">Monitoring your job&lt;/h3>
&lt;p>You can monitor your job with the JStorm UI, which displays all JStorm system metrics and Beam metrics.
For testing on local mode, you can retreive the Beam metrics with the metrics method of PipelineResult.&lt;/p></description></item></channel></rss>