<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Apache Beam</title><description>Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes.</description><link>/</link><generator>Hugo -- gohugo.io</generator><item><title>How to validate a Beam Release</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>Performing new releases is a core responsibility of any software project.
It is even more important in the culture of Apache projects. Releases are
the main flow of new code / features among the community of a project.&lt;/p>
&lt;p>Beam is no exception: We aspire to keep a release cadence of about 6 weeks,
and try to work with the community to release useful new features, and to
keep Beam useful.&lt;/p>
&lt;h3 id="configure-a-java-build-to-validate-a-beam-release-candidate">Configure a Java build to validate a Beam release candidate&lt;/h3>
&lt;p>First of all, it would be useful to have a single property in your &lt;code>pom.xml&lt;/code>
where you keep the global Beam version that you&amp;rsquo;re using. Something like this
in your &lt;code>pom.xml&lt;/code>:&lt;/p>
&lt;div class='language-java snippet'>
&lt;div class="notebook-skip code-snippet">
&lt;a class="copy" type="button" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Copy to clipboard">
&lt;img src="/images/copy-icon.svg"/>
&lt;/a>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">properties&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">26&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">0&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">properties&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">dependencies&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">beam&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">groupId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">sdks&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">java&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">core&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">artifactId&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">$&lt;/span>&lt;span class="o">{&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">version&lt;/span>&lt;span class="o">}&amp;lt;/&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">dependency&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">dependencies&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Second, you can add a new profile to your &lt;code>pom.xml&lt;/code> file. In this new profile,
add a new repository with the staging repository for the new Beam release. For
Beam 2.27.0, this was &lt;code>https://repository.apache.org/content/repositories/orgapachebeam-1149/&lt;/code>.&lt;/p>
&lt;div class='language-java snippet'>
&lt;div class="notebook-skip code-snippet">
&lt;a class="copy" type="button" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Copy to clipboard">
&lt;img src="/images/copy-icon.svg"/>
&lt;/a>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">profile&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">validaterelease&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">repositories&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">repository&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">newrelease&lt;/span>&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">$&lt;/span>&lt;span class="o">{&lt;/span>&lt;span class="n">beam&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">release&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">repo&lt;/span>&lt;span class="o">}&amp;lt;/&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">repository&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">repositories&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;lt;/&lt;/span>&lt;span class="n">profile&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Once you have a &lt;code>beam.version&lt;/code> property in your &lt;code>pom.xml&lt;/code>, and a new profile
with the new release, you can run your &lt;code>mvn&lt;/code> command activating the new profile,
and the new Beam version:&lt;/p>
&lt;pre>&lt;code>mvn test -Pvalidaterelease \
-Dbeam.version=2.27.0 \
-Dbeam.release.repo=https://repository.apache.org/content/repositories/orgapachebeam-XXXX/
&lt;/code>&lt;/pre>&lt;p>This should build your project against the new release, and run basic tests.
It will allow you to run basic validations against the new Beam release.
If you find any issues, then you can share them &lt;em>before&lt;/em> the release is
finalized, so your concerns can be addressed by the community.&lt;/p>
&lt;h3 id="configuring-a-python-build-to-validate-a-beam-release-candidate">Configuring a Python build to validate a Beam release candidate&lt;/h3>
&lt;p>For Python SDK releases, you can install SDK from Pypi, by enabling the
installation of pre-release artifacts.&lt;/p>
&lt;p>First, make sure that your &lt;code>requirements.txt&lt;/code> or &lt;code>setup.py&lt;/code> files allow
for Beam versions above the current one. Something like this should install
the latest available version:&lt;/p>
&lt;pre>&lt;code>apache-beam&amp;lt;=3.0.0
&lt;/code>&lt;/pre>&lt;p>With that, you can ask &lt;code>pip&lt;/code> to install pre-release versions of Beam in your
environment:&lt;/p>
&lt;pre>&lt;code>pip install --pre apache-beam
&lt;/code>&lt;/pre>&lt;p>With that, the Beam version in your environment will be the latest release
candidate, and you can go ahead and run your tests to verify that everything
works well.&lt;/p></description><link>/blog/validate-beam-release/</link><pubDate>Tue, 08 Jun 2021 00:00:01 -0800</pubDate><guid>/blog/validate-beam-release/</guid><category>blog</category></item><item><title>Apache Beam 2.29.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.29.0 release of Beam.
This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2290-2021-04-15">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.29.0, check out the &lt;a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12349629">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Spark Classic and Portable runners officially support Spark 3 (&lt;a href="https://issues.apache.org/jira/browse/BEAM-7093">BEAM-7093&lt;/a>).&lt;/li>
&lt;li>Official Java 11 support for most runners (Dataflow, Flink, Spark) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-2530">BEAM-2530&lt;/a>).&lt;/li>
&lt;li>DataFrame API now supports GroupBy.apply (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11628">BEAM-11628&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="ios">I/Os&lt;/h3>
&lt;ul>
&lt;li>Added support for S3 filesystem on AWS SDK V2 (Java) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-7637">BEAM-7637&lt;/a>)&lt;/li>
&lt;li>GCP BigQuery sink (file loads) uses runner determined sharding for unbounded data (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11772">BEAM-11772&lt;/a>)&lt;/li>
&lt;li>KafkaIO now recognizes the &lt;code>partition&lt;/code> property in writing records (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11806">BEAM-11806&lt;/a>)&lt;/li>
&lt;li>Support for Hadoop configuration on ParquetIO (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11913">BEAM-11913&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h3 id="new-features--improvements">New Features / Improvements&lt;/h3>
&lt;ul>
&lt;li>DataFrame API now supports pandas 1.2.x (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11531">BEAM-11531&lt;/a>).&lt;/li>
&lt;li>Multiple DataFrame API bugfixes (&lt;a href="https://issues.apache/jira/browse/BEAM-12071">BEAM-12071&lt;/a>, &lt;a href="https://issues.apache/jira/browse/BEAM-11929">BEAM-11929&lt;/a>)&lt;/li>
&lt;li>DDL supported in SQL transforms (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11850">BEAM-11850&lt;/a>)&lt;/li>
&lt;li>Upgrade Flink runner to Flink version 1.12.2 (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11941">BEAM-11941&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h3 id="breaking-changes">Breaking Changes&lt;/h3>
&lt;ul>
&lt;li>Deterministic coding enforced for GroupByKey and Stateful DoFns. Previously non-deterministic coding was allowed, resulting in keys not properly being grouped in some cases. (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11719">BEAM-11719&lt;/a>)
To restore the old behavior, one can register &lt;code>FakeDeterministicFastPrimitivesCoder&lt;/code> with
&lt;code>beam.coders.registry.register_fallback_coder(beam.coders.coders.FakeDeterministicFastPrimitivesCoder())&lt;/code>
or use the &lt;code>allow_non_deterministic_key_coders&lt;/code> pipeline option.&lt;/li>
&lt;/ul>
&lt;h3 id="deprecations">Deprecations&lt;/h3>
&lt;ul>
&lt;li>Support for Flink 1.8 and 1.9 will be removed in the next release (2.30.0) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11948">BEAM-11948&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="known-issues">Known Issues&lt;/h3>
&lt;ul>
&lt;li>See a full list of open &lt;a href="https://issues.apache.org/jira/issues/?jql=project%20%3D%20BEAM%20AND%20affectedVersion%20%3D%202.29.0%20ORDER%20BY%20priority%20DESC%2C%20updated%20DESC">issues that affect&lt;/a> this version.&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to &lt;code>git shortlog&lt;/code>, the following people contributed to the 2.29.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Ahmet Altay, Alan Myrvold, Alex Amato, Alexander Chermenin, Alexey Romanenko,
Allen Pradeep Xavier, Amy Wu, Anant Damle, Andreas Bergmeier, Andrei Balici,
Andrew Pilloud, Andy Xu, Ankur Goenka, Bashir Sadjad, Benjamin Gonzalez, Boyuan
Zhang, Brian Hulette, Chamikara Jayalath, Chinmoy Mandayam, Chuck Yang,
dandy10, Daniel Collins, Daniel Oliveira, David Cavazos, David Huntsperger,
David Moravek, Dmytro Kozhevin, Emily Ye, Esun Kim, Evgeniy Belousov, Filip
Popić, Fokko Driesprong, Gris Cuevas, Heejong Lee, Ihor Indyk, Ismaël Mejía,
Jakub-Sadowski, Jan Lukavský, John Edmonds, Juan Sandoval, 谷口恵輔, Kenneth
Jung, Kenneth Knowles, KevinGG, Kiley Sok, Kyle Weaver, MabelYC, Mackenzie
Clark, Masato Nakamura, Milena Bukal, Miltos, Minbo Bae, Miraç Vuslat Başaran,
mynameborat, Nahian-Al Hasan, Nam Bui, Niel Markwick, Niels Basjes, Ning Kang,
Nir Gazit, Pablo Estrada, Ramazan Yapparov, Raphael Sanamyan, Reuven Lax, Rion
Williams, Robert Bradshaw, Robert Burke, Rui Wang, Sam Rohde, Sam Whittle,
Shehzaad Nakhoda, Shehzaad Nakhoda, Siyuan Chen, Sonam Ramchand, Steve Niemitz,
sychen, Sylvain Veyrié, Tim Robertson, Tobias Kaymak, Tomasz Szerszeń, Tomasz
Szerszeń, Tomo Suzuki, Tyson Hamilton, Udi Meiri, Valentyn Tymofieiev, Yichi
Zhang, Yifan Mai, Yixing Zhang, Yoshiki Obata&lt;/p></description><link>/blog/beam-2.29.0/</link><pubDate>Thu, 29 Apr 2021 09:00:00 -0700</pubDate><guid>/blog/beam-2.29.0/</guid><category>blog</category></item><item><title>Apache Beam 2.28.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.28.0 release of Apache Beam. This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2280-2021-02-13">download page&lt;/a> for this release.
For more information on changes in 2.28.0, check out the
&lt;a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12349499">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Many improvements related to Parquet support (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11460">BEAM-11460&lt;/a>, &lt;a href="https://issues.apache.org/jira/browse/BEAM-8202">BEAM-8202&lt;/a>, and &lt;a href="https://issues.apache.org/jira/browse/BEAM-11526">BEAM-11526&lt;/a>)&lt;/li>
&lt;li>Hash Functions in BeamSQL (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10074">BEAM-10074&lt;/a>)&lt;/li>
&lt;li>Hash functions in ZetaSQL (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11624">BEAM-11624&lt;/a>)&lt;/li>
&lt;li>Create ApproximateDistinct using HLL Impl (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10324">BEAM-10324&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="ios">I/Os&lt;/h2>
&lt;ul>
&lt;li>SpannerIO supports using BigDecimal for Numeric fields (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11643">BEAM-11643&lt;/a>)&lt;/li>
&lt;li>Add Beam schema support to ParquetIO (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11526">BEAM-11526&lt;/a>)&lt;/li>
&lt;li>Support ParquetTable Writer (&lt;a href="https://issues.apache.org/jira/browse/BEAM-8202">BEAM-8202&lt;/a>)&lt;/li>
&lt;li>GCP BigQuery sink (streaming inserts) uses runner determined sharding (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11408">BEAM-11408&lt;/a>)&lt;/li>
&lt;li>PubSub support types: TIMESTAMP, DATE, TIME, DATETIME (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11533">BEAM-11533&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="new-features--improvements">New Features / Improvements&lt;/h2>
&lt;ul>
&lt;li>ParquetIO add methods &lt;em>readGenericRecords&lt;/em> and &lt;em>readFilesGenericRecords&lt;/em> can read files with an unknown schema. See &lt;a href="https://github.com/apache/beam/pull/13554">PR-13554&lt;/a> and (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11460">BEAM-11460&lt;/a>)&lt;/li>
&lt;li>Added support for thrift in KafkaTableProvider (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11482">BEAM-11482&lt;/a>)&lt;/li>
&lt;li>Added support for HadoopFormatIO to skip key/value clone (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11457">BEAM-11457&lt;/a>)&lt;/li>
&lt;li>Support Conversion to GenericRecords in Convert.to transform (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11571">BEAM-11571&lt;/a>).&lt;/li>
&lt;li>Support writes for Parquet Tables in Beam SQL (&lt;a href="https://issues.apache.org/jira/browse/BEAM-8202">BEAM-8202&lt;/a>).&lt;/li>
&lt;li>Support reading Parquet files with unknown schema (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11460">BEAM-11460&lt;/a>)&lt;/li>
&lt;li>Support user configurable Hadoop Configuration flags for ParquetIO (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11527">BEAM-11527&lt;/a>)&lt;/li>
&lt;li>Expose commit_offset_in_finalize and timestamp_policy to ReadFromKafka (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11677">BEAM-11677&lt;/a>)&lt;/li>
&lt;li>S3 options does not provided to boto3 client while using FlinkRunner and Beam worker pool container (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11799">BEAM-11799&lt;/a>)&lt;/li>
&lt;li>HDFS not deduplicating identical configuration paths (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11329">BEAM-11329&lt;/a>)&lt;/li>
&lt;li>Hash Functions in BeamSQL (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10074">BEAM-10074&lt;/a>)&lt;/li>
&lt;li>Create ApproximateDistinct using HLL Impl (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10324">BEAM-10324&lt;/a>)&lt;/li>
&lt;li>Add Beam schema support to ParquetIO (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11526">BEAM-11526&lt;/a>)&lt;/li>
&lt;li>Add a Deque Encoder (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11538">BEAM-11538&lt;/a>)&lt;/li>
&lt;li>Hash functions in ZetaSQL (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11624">BEAM-11624&lt;/a>)&lt;/li>
&lt;li>Refactor ParquetTableProvider (&lt;a href="https://issues.apache.org/jira/browse/">&lt;/a>)&lt;/li>
&lt;li>Add JVM properties to JavaJobServer (&lt;a href="https://issues.apache.org/jira/browse/BEAM-8344">BEAM-8344&lt;/a>)&lt;/li>
&lt;li>Single source of truth for supported Flink versions (&lt;a href="https://issues.apache.org/jira/browse/">&lt;/a>)&lt;/li>
&lt;li>Use metric for Python BigQuery streaming insert API latency logging (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11018">BEAM-11018&lt;/a>)&lt;/li>
&lt;li>Use metric for Java BigQuery streaming insert API latency logging (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11032">BEAM-11032&lt;/a>)&lt;/li>
&lt;li>Upgrade Flink runner to Flink versions 1.12.1 and 1.11.3 (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11697">BEAM-11697&lt;/a>)&lt;/li>
&lt;li>Upgrade Beam base image to use Tensorflow 2.4.1 (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11762">BEAM-11762&lt;/a>)&lt;/li>
&lt;li>Create Beam GCP BOM (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11665">BEAM-11665&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="breaking-changes">Breaking Changes&lt;/h2>
&lt;ul>
&lt;li>The Java artifacts &amp;ldquo;beam-sdks-java-io-kinesis&amp;rdquo;, &amp;ldquo;beam-sdks-java-io-google-cloud-platform&amp;rdquo;, and
&amp;ldquo;beam-sdks-java-extensions-sql-zetasql&amp;rdquo; declare Guava 30.1-jre dependency (It was 25.1-jre in Beam 2.27.0).
This new Guava version may introduce dependency conflicts if your project or dependencies rely
on removed APIs. If affected, ensure to use an appropriate Guava version via &lt;code>dependencyManagement&lt;/code> in Maven and
&lt;code>force&lt;/code> in Gradle.&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.28.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Ahmet Altay, Alex Amato, Alexey Romanenko, Allen Pradeep Xavier, Anant Damle, Artur Khanin,
Boyuan Zhang, Brian Hulette, Chamikara Jayalath, Chris Roth, Costi Ciudatu, Damon Douglas,
Daniel Collins, Daniel Oliveira, David Cavazos, David Huntsperger, Elliotte Rusty Harold,
Emily Ye, Etienne Chauchot, Etta Rapp, Evan Palmer, Eyal, Filip Krakowski, Fokko Driesprong,
Heejong Lee, Ismaël Mejía, janeliulwq, Jan Lukavský, John Edmonds, Jozef Vilcek, Kenneth Knowles
Ke Wu, kileys, Kyle Weaver, MabelYC, masahitojp, Masato Nakamura, Milena Bukal, Miraç Vuslat Başaran,
Nelson Osacky, Niel Markwick, Ning Kang, omarismail94, Pablo Estrada, Piotr Szuberski,
ramazan-yapparov, Reuven Lax, Reza Rokni, rHermes, Robert Bradshaw, Robert Burke, Robert Gruener,
Romster, Rui Wang, Sam Whittle, shehzaadn-vd, Siyuan Chen, Sonam Ramchand, Tobiasz Kędzierski,
Tomo Suzuki, tszerszen, tvalentyn, Tyson Hamilton, Udi Meiri, Xinbin Huang, Yichi Zhang,
Yifan Mai, yoshiki.obata, Yueyang Qiu, Yusaku Matsuki&lt;/p></description><link>/blog/beam-2.28.0/</link><pubDate>Mon, 22 Feb 2021 12:00:00 -0800</pubDate><guid>/blog/beam-2.28.0/</guid><category>blog</category></item><item><title>Example to ingest data from Apache Kafka to Google Cloud Pub/Sub</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>In this blog post we present an example that creates a pipeline to read data from a single topic or
multiple topics from &lt;a href="https://kafka.apache.org/">Apache Kafka&lt;/a> and write data into a topic
in &lt;a href="https://cloud.google.com/pubsub">Google Pub/Sub&lt;/a>. The example provides code samples to implement
simple yet powerful pipelines and also provides an out-of-the-box solution that you can just &lt;em>&amp;rdquo;
plug&amp;rsquo;n&amp;rsquo;play&amp;rdquo;&lt;/em>.&lt;/p>
&lt;p>This end-to-end example is included
in &lt;a href="https://beam.apache.org/blog/beam-2.27.0/">Apache Beam release 2.27&lt;/a>
and can be downloaded &lt;a href="https://beam.apache.org/get-started/downloads/#2270-2020-12-22">here&lt;/a>.&lt;/p>
&lt;p>We hope you will find this example useful for setting up data pipelines between Kafka and Pub/Sub.&lt;/p>
&lt;h1 id="example-specs">Example specs&lt;/h1>
&lt;p>Supported data formats:&lt;/p>
&lt;ul>
&lt;li>Serializable plain text formats, such as JSON&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage">PubSubMessage&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Supported input source configurations:&lt;/p>
&lt;ul>
&lt;li>Single or multiple Apache Kafka bootstrap servers&lt;/li>
&lt;li>Apache Kafka SASL/SCRAM authentication over plaintext or SSL connection&lt;/li>
&lt;li>Secrets vault service &lt;a href="https://www.vaultproject.io/">HashiCorp Vault&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Supported destination configuration:&lt;/p>
&lt;ul>
&lt;li>Single Google Pub/Sub topic&lt;/li>
&lt;/ul>
&lt;p>In a simple scenario, the example will create an Apache Beam pipeline that will read messages from a
source Kafka server with a source topic, and stream the text messages into specified Pub/Sub
destination topic. Other scenarios may need Kafka SASL/SCRAM authentication, that can be performed
over plaintext or SSL encrypted connection. The example supports using a single Kafka user account
to authenticate in the provided source Kafka servers and topics. To support SASL authentication over
SSL the example will need an SSL certificate location and access to a secrets vault service with
Kafka username and password, currently supporting HashiCorp Vault.&lt;/p>
&lt;h1 id="where-can-i-run-this-example">Where can I run this example?&lt;/h1>
&lt;p>There are two ways to execute the pipeline.&lt;/p>
&lt;ol>
&lt;li>Locally. This way has many options - run directly from your IntelliJ, or create &lt;code>.jar&lt;/code> file and
run it in the terminal, or use your favourite method of running Beam pipelines.&lt;/li>
&lt;li>In &lt;a href="https://cloud.google.com/">Google Cloud&lt;/a> using Google
Cloud &lt;a href="https://cloud.google.com/dataflow">Dataflow&lt;/a>:
&lt;ul>
&lt;li>With &lt;code>gcloud&lt;/code> command-line tool you can create
a &lt;a href="https://cloud.google.com/dataflow/docs/concepts/dataflow-templates">Flex Template&lt;/a>
out of this Beam example and execute it in Google Cloud Platform. &lt;em>This requires corresponding
modifications of the example to turn it into a template.&lt;/em>&lt;/li>
&lt;li>This example exists as
a &lt;a href="https://github.com/GoogleCloudPlatform/DataflowTemplates/tree/master/v2/kafka-to-pubsub">Flex Template version&lt;/a>
within &lt;a href="https://github.com/GoogleCloudPlatform/DataflowTemplates">Google Cloud Dataflow Template Pipelines&lt;/a>
repository and can be run with no additional code modifications.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h1 id="next-steps">Next Steps&lt;/h1>
&lt;p>Give this &lt;strong>Beam end-to-end example&lt;/strong> a try. If you are new to Beam, we hope this example will give
you more understanding on how pipelines work and look like. If you are already using Beam, we hope
some code samples in it will be useful for your use cases.&lt;/p>
&lt;p>Please
&lt;a href="https://beam.apache.org/community/contact-us/">let us know&lt;/a> if you encounter any issues.&lt;/p></description><link>/blog/kafka-to-pubsub-example/</link><pubDate>Fri, 15 Jan 2021 00:00:01 -0800</pubDate><guid>/blog/kafka-to-pubsub-example/</guid><category>blog</category><category>java</category></item><item><title>Apache Beam 2.27.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.27.0 release of Apache Beam. This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2270-2020-12-22">download page&lt;/a> for this release.
For more information on changes in 2.27.0, check out the
&lt;a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12349380">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Java 11 Containers are now published with all Beam releases.&lt;/li>
&lt;li>There is a new transform &lt;code>ReadAllFromBigQuery&lt;/code> that can receive multiple requests to read data from BigQuery at pipeline runtime. See &lt;a href="https://github.com/apache/beam/pull/13170">PR 13170&lt;/a>, and &lt;a href="https://issues.apache.org/jira/browse/BEAM-9650">BEAM-9650&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h2 id="ios">I/Os&lt;/h2>
&lt;ul>
&lt;li>ReadFromMongoDB can now be used with MongoDB Atlas (Python) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11266">BEAM-11266&lt;/a>.)&lt;/li>
&lt;li>ReadFromMongoDB/WriteToMongoDB will mask password in display_data (Python) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11444">BEAM-11444&lt;/a>.)&lt;/li>
&lt;li>There is a new transform &lt;code>ReadAllFromBigQuery&lt;/code> that can receive multiple requests to read data from BigQuery at pipeline runtime. See &lt;a href="https://github.com/apache/beam/pull/13170">PR 13170&lt;/a>, and &lt;a href="https://issues.apache.org/jira/browse/BEAM-9650">BEAM-9650&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h2 id="new-features--improvements">New Features / Improvements&lt;/h2>
&lt;ul>
&lt;li>Beam modules that depend on Hadoop are now tested for compatibility with Hadoop 3 (&lt;a href="https://issues.apache.org/jira/browse/BEAM-8569">BEAM-8569&lt;/a>). (Hive/HCatalog pending)&lt;/li>
&lt;li>Publishing Java 11 SDK container images now supported as part of Apache Beam release process. (&lt;a href="https://issues.apache.org/jira/browse/BEAM-8106">BEAM-8106&lt;/a>)&lt;/li>
&lt;li>Added Cloud Bigtable Provider extension to Beam SQL (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11173">BEAM-11173&lt;/a>, &lt;a href="https://issues.apache.org/jira/browse/BEAM-11373">BEAM-11373&lt;/a>)&lt;/li>
&lt;li>Added a schema provider for thrift data (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11338">BEAM-11338&lt;/a>)&lt;/li>
&lt;li>Added combiner packing pipeline optimization to Dataflow runner. (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10641">BEAM-10641&lt;/a>)&lt;/li>
&lt;li>Added an example to ingest data from Apache Kafka to Google Pub/Sub. (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11065">BEAM-11065&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="breaking-changes">Breaking Changes&lt;/h2>
&lt;ul>
&lt;li>HBaseIO hbase-shaded-client dependency should be now provided by the users (&lt;a href="https://issues.apache.org/jira/browse/BEAM-9278">BEAM-9278&lt;/a>).&lt;/li>
&lt;li>&lt;code>--region&lt;/code> flag in amazon-web-services2 was replaced by &lt;code>--awsRegion&lt;/code> (&lt;a href="https://issues.apache.org/jira/projects/BEAM/issues/BEAM-11331">BEAM-11331&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.27.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Ahmet Altay, Alan Myrvold, Alex Amato, Alexey Romanenko, Aliraza Nagamia, Allen Pradeep Xavier,
Andrew Pilloud, andreyKaparulin, Ashwin Ramaswami, Boyuan Zhang, Brent Worden, Brian Hulette,
Carlos Marin, Chamikara Jayalath, Costi Ciudatu, Damon Douglas, Daniel Collins,
Daniel Oliveira, David Huntsperger, David Lu, David Moravek, David Wrede,
dennis, Dennis Yung, dpcollins-google, Emily Ye, emkornfield,
Esun Kim, Etienne Chauchot, Eugene Nikolaiev, Frank Zhao, Haizhou Zhao,
Hector Acosta, Heejong Lee, Ilya, Iñigo San Jose Visiers, InigoSJ,
Ismaël Mejía, janeliulwq, Jan Lukavský, Kamil Wasilewski, Kenneth Jung,
Kenneth Knowles, Ke Wu, kileys, Kyle Weaver, lostluck,
Matt Casters, Maximilian Michels, Michal Walenia, Mike Dewar, nehsyc,
Nelson Osacky, Niels Basjes, Ning Kang, Pablo Estrada, palmere-google,
Pawel Pasterz, Piotr Szuberski, purbanow, Reuven Lax, rHermes,
Robert Bradshaw, Robert Burke, Rui Wang, Sam Rohde, Sam Whittle,
Siyuan Chen, Tim Robertson, Tobiasz Kędzierski, tszerszen,
Valentyn Tymofieiev, Tyson Hamilton, Udi Meiri, vachan-shetty, Xinyu Liu,
Yichi Zhang, Yifan Mai, yoshiki.obata, Yueyang Qiu&lt;/p></description><link>/blog/beam-2.27.0/</link><pubDate>Thu, 07 Jan 2021 12:00:00 -0800</pubDate><guid>/blog/beam-2.27.0/</guid><category>blog</category></item><item><title>DataFrame API Preview now Available!</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We&amp;rsquo;re excited to announce that a preview of the Beam Python SDK&amp;rsquo;s new DataFrame
API is now available in &lt;a href="https://beam.apache.org/blog/beam-2.26.0/">Beam
2.26.0&lt;/a>. Much like &lt;code>SqlTransform&lt;/code>
(&lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/extensions/sql/SqlTransform.html">Java&lt;/a>,
&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.sql.html#apache_beam.transforms.sql.SqlTransform">Python&lt;/a>),
the DataFrame API gives Beam users a way to express complex
relational logic much more concisely than previously possible.&lt;/p>
&lt;h2 id="a-more-expressive-api">A more expressive API&lt;/h2>
&lt;p>Beam&amp;rsquo;s new DataFrame API aims to be compatible with the well known
&lt;a href="https://pandas.pydata.org/pandas-docs/stable/index.html">Pandas&lt;/a>
DataFrame API, with a few caveats detailed below. With this new API a simple
pipeline that reads NYC taxiride data from a CSV, performs a grouped
aggregation, and writes the output to CSV, can be expressed very concisely:&lt;/p>
&lt;pre>&lt;code>from apache_beam.dataframe.io import read_csv
with beam.Pipeline() as p:
df = p | read_csv(&amp;quot;gs://apache-beam-samples/nyc_taxi/2019/*.csv&amp;quot;,
use_ncols=['passenger_count' , 'DOLocationID'])
# Count the number of passengers dropped off per LocationID
agg = df.groupby('DOLocationID').sum()
agg.to_csv(output)
&lt;/code>&lt;/pre>&lt;p>Compare this to the same logic implemented as a conventional Beam python
pipeline with a &lt;code>CombinePerKey&lt;/code>:&lt;/p>
&lt;pre>&lt;code>with beam.Pipeline() as p:
(p | beam.io.ReadFromText(&amp;quot;gs://apache-beam-samples/nyc_taxi/2019/*.csv&amp;quot;,
skip_header_lines=1)
| beam.Map(lambda line: line.split(','))
# Parse CSV, create key - value pairs
| beam.Map(lambda splits: (int(splits[8] or 0), # DOLocationID
int(splits[3] or 0))) # passenger_count
# Sum values per key
| beam.CombinePerKey(sum)
| beam.MapTuple(lambda loc_id, pc: f'{loc_id},{pc}')
| beam.io.WriteToText(known_args.output))
&lt;/code>&lt;/pre>&lt;p>The DataFrame example is much easier to quickly inspect and understand, as it
allows you to concisely express grouped aggregations without using the low-level
&lt;code>CombinePerKey&lt;/code>.&lt;/p>
&lt;p>In addition to being more expressive, a pipeline written with the DataFrame API
can often be more efficient than a conventional Beam pipeline. This is because
the DataFrame API defers to the very efficient, columnar Pandas implementation
as much as possible.&lt;/p>
&lt;h2 id="dataframes-as-a-dsl">DataFrames as a DSL&lt;/h2>
&lt;p>You may already be aware of &lt;a href="https://beam.apache.org/documentation/dsls/sql/overview/">Beam
SQL&lt;/a>, which is
a Domain-Specific Language (DSL) built with Beam&amp;rsquo;s Java SDK. SQL is
considered a DSL because it&amp;rsquo;s possible to express a full pipeline, including IOs
and complex operations, entirely with SQL. &lt;/p>
&lt;p>Similarly, the DataFrame API is a DSL built with the Python SDK. You can see
that the above example is written without traditional Beam constructs like IOs,
ParDo, or CombinePerKey. In fact the only traditional Beam type is the Pipeline
instance! Otherwise this pipeline is written completely using the DataFrame API.
This is possible because the DataFrame API doesn&amp;rsquo;t just implement Pandas&amp;rsquo;
computation operations, it also includes IOs based on the Pandas native
implementations (&lt;code>pd.read_{csv,parquet,...}&lt;/code> and &lt;code>pd.DataFrame.to_{csv,parquet,...}&lt;/code>).&lt;/p>
&lt;p>Like SQL, it&amp;rsquo;s also possible to embed the DataFrame API into a larger pipeline
by using
&lt;a href="https://beam.apache.org/documentation/programming-guide/#what-is-a-schema">schemas&lt;/a>.
A schema-aware PCollection can be converted to a DataFrame, processed, and the
result converted back to another schema-aware PCollection. For example, if you
wanted to use traditional Beam IOs rather than one of the DataFrame IOs you
could rewrite the above pipeline like this:&lt;/p>
&lt;pre>&lt;code>from apache_beam.dataframe.convert import to_dataframe
from apache_beam.dataframe.convert import to_pcollection
with beam.Pipeline() as p:
...
schema_pc = (p | beam.ReadFromText(..)
# Use beam.Select to assign a schema
| beam.Select(DOLocationID=lambda line: int(...),
passenger_count=lambda line: int(...)))
df = to_dataframe(schema_pc)
agg = df.groupby('DOLocationID').sum()
agg_pc = to_pcollection(pc)
# agg_pc has a schema based on the structure of agg
(agg_pc | beam.Map(lambda row: f'{row.DOLocationID},{row.passenger_count}')
| beam.WriteToText(..))
&lt;/code>&lt;/pre>&lt;p>It&amp;rsquo;s also possible to use the DataFrame API by passing a function to
&lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.dataframe.transforms.html#apache_beam.dataframe.transforms.DataframeTransform">&lt;code>DataframeTransform&lt;/code>&lt;/a>:&lt;/p>
&lt;pre>&lt;code>from apache_beam.dataframe.transforms import DataframeTransform
with beam.Pipeline() as p:
...
| beam.Select(DOLocationID=lambda line: int(..),
passenger_count=lambda line: int(..))
| DataframeTransform(lambda df: df.groupby('DOLocationID').sum())
| beam.Map(lambda row: f'{row.DOLocationID},{row.passenger_count}')
...
&lt;/code>&lt;/pre>&lt;h2 id="caveats">Caveats&lt;/h2>
&lt;p>As hinted above, there are some differences between Beam&amp;rsquo;s DataFrame API and the
Pandas API. The most significant difference is that the Beam DataFrame API is
&lt;em>deferred&lt;/em>, just like the rest of the Beam API. This means that you can&amp;rsquo;t
&lt;code>print()&lt;/code> a DataFrame instance in order to inspect the data, because we haven&amp;rsquo;t
computed the data yet! The computation doesn&amp;rsquo;t take place until the pipeline is
&lt;code>run()&lt;/code>. Before that, we only know about the shape/schema of the result (i.e.
the names and types of the columns), and not the result itself.&lt;/p>
&lt;p>There are a few common exceptions you will likely see when attempting to use
certain Pandas operations:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>NotImplementedError:&lt;/strong> Indicates this is an operation or argument that we
haven&amp;rsquo;t had time to look at yet. We&amp;rsquo;ve tried to make as many Pandas operations
as possible available in the Preview offering of this new API, but there&amp;rsquo;s
still a long tail of operations to go.&lt;/li>
&lt;li>&lt;strong>WontImplementError:&lt;/strong> Indicates this is an operation or argument we do not
intend to support in the near-term because it&amp;rsquo;s incompatible with the Beam
model. The largest class of operations that raise this error are those that
are order sensitive (e.g. shift, cummax, cummin, head, tail, etc..). These
cannot be trivially mapped to Beam because PCollections, representing
distributed datasets, are unordered. Note that even some of these operations
&lt;em>may&lt;/em> get implemented in the future - we actually have some ideas for how we
might support order sensitive operations - but it&amp;rsquo;s a ways off.&lt;/li>
&lt;/ul>
&lt;p>Finally, it&amp;rsquo;s important to note that this is a preview of a new feature that
will get hardened over the next few Beam releases. We would love for you to try
it out now and give us some feedback, but we do not yet recommend it for use in
production workloads.&lt;/p>
&lt;h2 id="how-to-get-involved">How to get involved&lt;/h2>
&lt;p>The easiest way to get involved with this effort is to try out DataFrames and
let us know what you think! You can send questions to &lt;a href="mailto:user@beam.apache.org">user@beam.apache.org&lt;/a>, or
file bug reports and feature requests in &lt;a href="https://issues.apache.org/jira">jira&lt;/a>.
In particular, it would be really helpful to know if there&amp;rsquo;s an operation we
haven&amp;rsquo;t implemented yet that you&amp;rsquo;d find useful, so that we can prioritize it.&lt;/p>
&lt;p>If you&amp;rsquo;d like to learn more about how the DataFrame API works under the hood and
get involved with the development we recommend you take a look at the
&lt;a href="http://s.apache.org/beam-dataframes">design doc&lt;/a>
and our &lt;a href="https://2020.beamsummit.org/sessions/simpler-python-pipelines/">Beam summit
presentation&lt;/a>.
From there the best way to help is to knock out some of those not implemented
operations. We&amp;rsquo;re coordinating that work in
&lt;a href="https://issues.apache.org/jira/browse/BEAM-9547">BEAM-9547&lt;/a>.&lt;/p></description><link>/blog/dataframe-api-preview-available/</link><pubDate>Wed, 16 Dec 2020 09:09:41 -0800</pubDate><guid>/blog/dataframe-api-preview-available/</guid><category>blog</category></item><item><title>Splittable DoFn in Apache Beam is Ready to Use</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are pleased to announce that Splittable DoFn (SDF) is ready for use in the Beam Python, Java,
and Go SDKs for versions 2.25.0 and later.&lt;/p>
&lt;p>In 2017, &lt;a href="https://beam.apache.org/blog/splittable-do-fn/">Splittable DoFn Blog Post&lt;/a> proposed
to build &lt;a href="https://s.apache.org/splittable-do-fn">Splittable DoFn&lt;/a> APIs as the new recommended way of
building I/O connectors. Splittable DoFn is a generalization of &lt;code>DoFn&lt;/code> that gives it the core
capabilities of &lt;code>Source&lt;/code> while retaining &lt;code>DoFn&lt;/code>'s syntax, flexibility, modularity, and ease of
coding. Thus, it becomes much easier to develop complex I/O connectors with simpler and reusable
code.&lt;/p>
&lt;p>SDF has three advantages over the existing &lt;code>UnboundedSource&lt;/code> and &lt;code>BoundedSource&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>SDF provides a unified set of APIs to handle both unbounded and bounded cases.&lt;/li>
&lt;li>SDF enables reading from source descriptors dynamically.
&lt;ul>
&lt;li>Taking KafkaIO as an example, within &lt;code>UnboundedSource&lt;/code>/&lt;code>BoundedSource&lt;/code> API, you must specify
the topic and partition you want to read from during pipeline construction time. There is no way
for &lt;code>UnboundedSource&lt;/code>/&lt;code>BoundedSource&lt;/code> to accept topics and partitions as inputs during execution
time. But it&amp;rsquo;s built-in to SDF.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>SDF fits in as any node on a pipeline freely with the ability of splitting.
&lt;ul>
&lt;li>&lt;code>UnboundedSource&lt;/code>/&lt;code>BoundedSource&lt;/code> has to be the root node of the pipeline to gain performance
benefits from splitting strategies, which limits many real-world usages. This is no longer a limit
for an SDF.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>As SDF is now ready to use with all the mentioned improvements, it is the recommended
way to build the new I/O connectors. Try out building your own Splittable DoFn by following the
&lt;a href="https://beam.apache.org/documentation/programming-guide/#splittable-dofns">programming guide&lt;/a>. We
have provided tonnes of common utility classes such as common types of &lt;code>RestrictionTracker&lt;/code> and
&lt;code>WatermarkEstimator&lt;/code> in Beam SDK, which will help you onboard easily. As for the existing I/O
connectors, we have wrapped &lt;code>UnboundedSource&lt;/code> and &lt;code>BoundedSource&lt;/code> implementations into Splittable
DoFns, yet we still encourage developers to convert &lt;code>UnboundedSource&lt;/code>/&lt;code>BoundedSource&lt;/code> into actual
Splittable DoFn implementation to gain more performance benefits.&lt;/p>
&lt;p>Many thanks to every contributor who brought this highly anticipated design into the data processing
world. We are really excited to see that users benefit from SDF.&lt;/p>
&lt;p>Below are some real-world SDF examples for you to explore.&lt;/p>
&lt;h2 id="real-world-splittable-dofn-examples">Real world Splittable DoFn examples&lt;/h2>
&lt;p>&lt;strong>Java Examples&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/571338b0cc96e2e80f23620fe86de5c92dffaccc/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ReadFromKafkaDoFn.java#L118">Kafka&lt;/a>:
An I/O connector for &lt;a href="https://kafka.apache.org/">Apache Kafka&lt;/a>
(an open-source distributed event streaming platform).&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/571338b0cc96e2e80f23620fe86de5c92dffaccc/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Watch.java#L787">Watch&lt;/a>:
Uses a polling function producing a growing set of outputs for each input until a per-input
termination condition is met.&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/571338b0cc96e2e80f23620fe86de5c92dffaccc/sdks/java/io/parquet/src/main/java/org/apache/beam/sdk/io/parquet/ParquetIO.java#L365">Parquet&lt;/a>:
An I/O connector for &lt;a href="https://parquet.apache.org/">Apache Parquet&lt;/a>
(an open-source columnar storage format).&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/6fdde4f4eab72b49b10a8bb1cb3be263c5c416b5/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java#L493">HL7v2&lt;/a>:
An I/O connector for HL7v2 messages (a clinical messaging format that provides data about events
that occur inside an organization) part of
&lt;a href="https://cloud.google.com/healthcare">Google’s Cloud Healthcare API&lt;/a>.&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/571338b0cc96e2e80f23620fe86de5c92dffaccc/sdks/java/core/src/main/java/org/apache/beam/sdk/io/Read.java#L248">BoundedSource wrapper&lt;/a>:
A wrapper which converts an existing &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/BoundedSource.html">BoundedSource&lt;/a>
implementation to a splittable DoFn.&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/571338b0cc96e2e80f23620fe86de5c92dffaccc/sdks/java/core/src/main/java/org/apache/beam/sdk/io/Read.java#L432">UnboundedSource wrapper&lt;/a>:
A wrapper which converts an existing &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/UnboundedSource.html">UnboundedSource&lt;/a>
implementation to a splittable DoFn.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Python Examples&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/571338b0cc96e2e80f23620fe86de5c92dffaccc/sdks/python/apache_beam/io/iobase.py#L1375">BoundedSourceWrapper&lt;/a>:
A wrapper which converts an existing &lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.io.iobase.html#apache_beam.io.iobase.BoundedSource">BoundedSource&lt;/a>
implementation to a splittable DoFn.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Go Examples&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/ce190e11332469ea59b6c9acf16ee7c673ccefdd/sdks/go/pkg/beam/io/textio/sdf.go#L40">textio.ReadSdf&lt;/a> implements reading from text files using a splittable DoFn.&lt;/li>
&lt;/ul></description><link>/blog/splittable-do-fn-is-available/</link><pubDate>Mon, 14 Dec 2020 00:00:01 -0800</pubDate><guid>/blog/splittable-do-fn-is-available/</guid><category>blog</category></item><item><title>Apache Beam 2.26.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.26.0 release of Apache Beam. This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2260-2020-12-11">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.26.0, check out the
&lt;a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12348833">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Splittable DoFn is now the default for executing the Read transform for Java based runners (Spark with bounded pipelines) in addition to existing runners from the 2.25.0 release (Direct, Flink, Jet, Samza, Twister2). The expected output of the Read transform is unchanged. Users can opt-out using &lt;code>--experiments=use_deprecated_read&lt;/code>. The Apache Beam community is looking for feedback for this change as the community is planning to make this change permanent with no opt-out. If you run into an issue requiring the opt-out, please send an e-mail to &lt;a href="mailto:user@beam.apache.org">user@beam.apache.org&lt;/a> specifically referencing BEAM-10670 in the subject line and why you needed to opt-out. (Java) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10670">BEAM-10670&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="ios">I/Os&lt;/h2>
&lt;ul>
&lt;li>Java BigQuery streaming inserts now have timeouts enabled by default. Pass &lt;code>--HTTPWriteTimeout=0&lt;/code> to revert to the old behavior. (&lt;a href="https://issues.apache.org/jira/browse/BEAM-6103">BEAM-6103&lt;/a>)&lt;/li>
&lt;li>Added support for Contextual Text IO (Java), a version of text IO that provides metadata about the records (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10124">BEAM-10124&lt;/a>). Support for this IO is currently experimental. Specifically, &lt;strong>there are no update-compatibility guarantees&lt;/strong> for streaming jobs with this IO between current future verisons of Apache Beam SDK.&lt;/li>
&lt;/ul>
&lt;h2 id="new-features--improvements">New Features / Improvements&lt;/h2>
&lt;ul>
&lt;li>Added support for avro payload format in Beam SQL Kafka Table (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10885">BEAM-10885&lt;/a>)&lt;/li>
&lt;li>Added support for json payload format in Beam SQL Kafka Table (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10893">BEAM-10893&lt;/a>)&lt;/li>
&lt;li>Added support for protobuf payload format in Beam SQL Kafka Table (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10892">BEAM-10892&lt;/a>)&lt;/li>
&lt;li>Added support for avro payload format in Beam SQL Pubsub Table (&lt;a href="https://issues.apache.org/jira/browse/BEAM-5504">BEAM-5504&lt;/a>)&lt;/li>
&lt;li>Added option to disable unnecessary copying between operators in Flink Runner (Java) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-11146">BEAM-11146&lt;/a>)&lt;/li>
&lt;li>Added CombineFn.setup and CombineFn.teardown to Python SDK. These methods let you initialize the CombineFn&amp;rsquo;s state before any of the other methods of the CombineFn is executed and clean that state up later on. If you are using Dataflow, you need to enable Dataflow Runner V2 by passing &lt;code>--experiments=use_runner_v2&lt;/code> before using this feature. (&lt;a href="https://issues.apache.org/jira/browse/BEAM-3736">BEAM-3736&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="breaking-changes">Breaking Changes&lt;/h2>
&lt;ul>
&lt;li>BigQuery&amp;rsquo;s DATETIME type now maps to Beam logical type org.apache.beam.sdk.schemas.logicaltypes.SqlTypes.DATETIME&lt;/li>
&lt;li>Pandas 1.x is now required for dataframe operations.&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.26.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Abhishek Yadav, AbhiY98, Ahmet Altay, Alan Myrvold, Alex Amato, Alexey Romanenko,
Andrew Pilloud, Ankur Goenka, Boyuan Zhang, Brian Hulette, Chad Dombrova,
Chamikara Jayalath, Curtis &amp;ldquo;Fjord&amp;rdquo; Hawthorne, Damon Douglas, dandy10, Daniel Oliveira,
David Cavazos, dennis, Derrick Qin, dpcollins-google, Dylan Hercher, emily, Esun Kim,
Gleb Kanterov, Heejong Lee, Ismaël Mejía, Jan Lukavský, Jean-Baptiste Onofré, Jing,
Jozef Vilcek, Justin White, Kamil Wasilewski, Kenneth Knowles, kileys, Kyle Weaver,
lostluck, Luke Cwik, Mark, Maximilian Michels, Milan Cermak, Mohammad Hossein Sekhavat,
Nelson Osacky, Neville Li, Ning Kang, pabloem, Pablo Estrada, pawelpasterz,
Pawel Pasterz, Piotr Szuberski, PoojaChandak, purbanow, rarokni, Ravi Magham,
Reuben van Ammers, Reuven Lax, Reza Rokni, Robert Bradshaw, Robert Burke,
Romain Manni-Bucau, Rui Wang, rworley-monster, Sam Rohde, Sam Whittle, shollyman,
Simone Primarosa, Siyuan Chen, Steve Niemitz, Steven van Rossum, sychen, Teodor Spæren,
Tim Clemons, Tim Robertson, Tobiasz Kędzierski, tszerszen, Tudor Marian, tvalentyn,
Tyson Hamilton, Udi Meiri, Vasu Gupta, xasm83, Yichi Zhang, yichuan66, Yifan Mai,
yoshiki.obata, Yueyang Qiu, yukihira1992&lt;/p></description><link>/blog/beam-2.26.0/</link><pubDate>Fri, 11 Dec 2020 12:00:00 -0800</pubDate><guid>/blog/beam-2.26.0/</guid><category>blog</category></item><item><title>Apache Beam 2.25.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.25.0 release of Apache Beam. This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2250-2020-10-23">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.25.0, check out the
&lt;a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12347147">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Splittable DoFn is now the default for executing the Read transform for Java based runners (Direct, Flink, Jet, Samza, Twister2). The expected output of the Read transform is unchanged. Users can opt-out using &lt;code>--experiments=use_deprecated_read&lt;/code>. The Apache Beam community is looking for feedback for this change as the community is planning to make this change permanent with no opt-out. If you run into an issue requiring the opt-out, please send an e-mail to &lt;a href="mailto:user@beam.apache.org">user@beam.apache.org&lt;/a> specifically referencing BEAM-10670 in the subject line and why you needed to opt-out. (Java) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10670">BEAM-10670&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="ios">I/Os&lt;/h2>
&lt;ul>
&lt;li>Added cross-language support to Java&amp;rsquo;s KinesisIO, now available in the Python module &lt;code>apache_beam.io.kinesis&lt;/code> (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10138">BEAM-10138&lt;/a>, &lt;a href="https://issues.apache.org/jira/browse/BEAM-10137">BEAM-10137&lt;/a>).&lt;/li>
&lt;li>Update Snowflake JDBC dependency for SnowflakeIO (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10864">BEAM-10864&lt;/a>)&lt;/li>
&lt;li>Added cross-language support to Java&amp;rsquo;s SnowflakeIO.Write, now available in the Python module &lt;code>apache_beam.io.snowflake&lt;/code> (&lt;a href="https://issues.apache.org/jira/browse/BEAM-9898">BEAM-9898&lt;/a>).&lt;/li>
&lt;li>Added delete function to Java&amp;rsquo;s &lt;code>ElasticsearchIO#Write&lt;/code>. Now, Java&amp;rsquo;s ElasticsearchIO can be used to selectively delete documents using &lt;code>withIsDeleteFn&lt;/code> function (&lt;a href="https://issues.apache.org/jira/browse/BEAM-5757">BEAM-5757&lt;/a>).&lt;/li>
&lt;li>Java SDK: Added new IO connector for InfluxDB - InfluxDbIO (&lt;a href="https://issues.apache.org/jira/browse/BEAM-2546">BEAM-2546&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h2 id="new-features--improvements">New Features / Improvements&lt;/h2>
&lt;ul>
&lt;li>Support for repeatable fields in JSON decoder for &lt;code>ReadFromBigQuery&lt;/code> added. (Python) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10524">BEAM-10524&lt;/a>)&lt;/li>
&lt;li>Added an opt-in, performance-driven runtime type checking system for the Python SDK (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10549">BEAM-10549&lt;/a>).
More details will be in an upcoming &lt;a href="https://beam.apache.org/blog/python-performance-runtime-type-checking/index.html">blog post&lt;/a>.&lt;/li>
&lt;li>Added support for Python 3 type annotations on PTransforms using typed PCollections (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10258">BEAM-10258&lt;/a>).
More details will be in an upcoming &lt;a href="https://beam.apache.org/blog/python-improved-annotations/index.html">blog post&lt;/a>.&lt;/li>
&lt;li>Improved the Interactive Beam API where recording streaming jobs now start a long running background recording job. Running ib.show() or ib.collect() samples from the recording (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10603">BEAM-10603&lt;/a>).&lt;/li>
&lt;li>In Interactive Beam, ib.show() and ib.collect() now have &amp;ldquo;n&amp;rdquo; and &amp;ldquo;duration&amp;rdquo; as parameters. These mean read only up to &amp;ldquo;n&amp;rdquo; elements and up to &amp;ldquo;duration&amp;rdquo; seconds of data read from the recording (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10603">BEAM-10603&lt;/a>).&lt;/li>
&lt;li>Initial preview of &lt;a href="https://s.apache.org/simpler-python-pipelines-2020#slide=id.g905ac9257b_1_21">Dataframes&lt;/a> support.
See also example at apache_beam/examples/wordcount_dataframe.py&lt;/li>
&lt;li>Fixed support for type hints on &lt;code>@ptransform_fn&lt;/code> decorators in the Python SDK.
(&lt;a href="https://issues.apache.org/jira/browse/BEAM-4091">BEAM-4091&lt;/a>)
This has not enabled by default to preserve backwards compatibility; use the
&lt;code>--type_check_additional=ptransform_fn&lt;/code> flag to enable. It may be enabled by
default in future versions of Beam.&lt;/li>
&lt;/ul>
&lt;h2 id="breaking-changes">Breaking Changes&lt;/h2>
&lt;ul>
&lt;li>Python 2 and Python 3.5 support dropped (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10644">BEAM-10644&lt;/a>, &lt;a href="https://issues.apache.org/jira/browse/BEAM-9372">BEAM-9372&lt;/a>).&lt;/li>
&lt;li>Pandas 1.x allowed. Older version of Pandas may still be used, but may not be as well tested.&lt;/li>
&lt;/ul>
&lt;h2 id="deprecations">Deprecations&lt;/h2>
&lt;ul>
&lt;li>Python transform ReadFromSnowflake has been moved from &lt;code>apache_beam.io.external.snowflake&lt;/code> to &lt;code>apache_beam.io.snowflake&lt;/code>. The previous path will be removed in the future versions.&lt;/li>
&lt;/ul>
&lt;h2 id="known-issues">Known Issues&lt;/h2>
&lt;ul>
&lt;li>Dataflow streaming timers once against not strictly time ordered when set earlier mid-bundle, as the fix for &lt;a href="https://issues.apache.org/jira/browse/BEAM-8543">BEAM-8543&lt;/a> introduced more severe bugs and has been rolled back.&lt;/li>
&lt;li>Default compressor change breaks dataflow python streaming job update compatibility. Please use python SDK version &amp;lt;= 2.23.0 or &amp;gt; 2.25.0 if job update is critical.(&lt;a href="https://issues.apache.org/jira/browse/BEAM-11113">BEAM-11113&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.25.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Ahmet Altay, Alan Myrvold, Aldair Coronel Ruiz, Alexey Romanenko, Andrew Pilloud, Ankur Goenka,
Ayoub ENNASSIRI, Bipin Upadhyaya, Boyuan Zhang, Brian Hulette, Brian Michalski, Chad Dombrova,
Chamikara Jayalath, Damon Douglas, Daniel Oliveira, David Cavazos, David Janicek, Doug Roeper, Eric
Roshan-Eisner, Etta Rapp, Eugene Kirpichov, Filipe Regadas, Heejong Lee, Ihor Indyk, Irvi Firqotul
Aini, Ismaël Mejía, Jan Lukavský, Jayendra, Jiadai Xia, Jithin Sukumar, Jozsef Bartok, Kamil
Gałuszka, Kamil Wasilewski, Kasia Kucharczyk, Kenneth Jung, Kenneth Knowles, Kevin Puthusseri, Kevin
Sijo Puthusseri, KevinGG, Kyle Weaver, Leiyi Zhang, Lourens Naudé, Luke Cwik, Matthew Ouyang,
Maximilian Michels, Michal Walenia, Milan Cermak, Monica Song, Nelson Osacky, Neville Li, Ning Kang,
Pablo Estrada, Piotr Szuberski, Qihang, Rehman, Reuven Lax, Robert Bradshaw, Robert Burke, Rui Wang,
Saavan Nanavati, Sam Bourne, Sam Rohde, Sam Whittle, Sergiy Kolesnikov, Sindy Li, Siyuan Chen, Steve
Niemitz, Terry Xian, Thomas Weise, Tobiasz Kędzierski, Truc Le, Tyson Hamilton, Udi Meiri, Valentyn
Tymofieiev, Yichi Zhang, Yifan Mai, Yueyang Qiu, annaqin418, danielxjd, dennis, dp, fuyuwei,
lostluck, nehsyc, odeshpande, odidev, pulasthi, purbanow, rworley-monster, sclukas77, terryxian78,
tvalentyn, yoshiki.obata&lt;/p></description><link>/blog/beam-2.25.0/</link><pubDate>Fri, 23 Oct 2020 14:00:00 -0800</pubDate><guid>/blog/beam-2.25.0/</guid><category>blog</category></item><item><title>Apache Beam 2.24.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.24.0 release of Apache Beam. This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2240-2020-09-18">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.24.0, check out the
&lt;a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12347146">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Apache Beam 2.24.0 is the last release with Python 2 and Python 3.5
support.&lt;/li>
&lt;/ul>
&lt;h2 id="ios">I/Os&lt;/h2>
&lt;ul>
&lt;li>New overloads for BigtableIO.Read.withKeyRange() and BigtableIO.Read.withRowFilter()
methods that take ValueProvider as a parameter (Java) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10283">BEAM-10283&lt;/a>).&lt;/li>
&lt;li>The WriteToBigQuery transform (Python) in Dataflow Batch no longer relies on BigQuerySink by default. It relies on
a new, fully-featured transform based on file loads into BigQuery. To revert the behavior to the old implementation,
you may use &lt;code>--experiments=use_legacy_bq_sink&lt;/code>.&lt;/li>
&lt;li>Add cross-language support to Java&amp;rsquo;s JdbcIO, now available in the Python module &lt;code>apache_beam.io.jdbc&lt;/code> (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10135">BEAM-10135&lt;/a>, &lt;a href="https://issues.apache.org/jira/browse/BEAM-10136">BEAM-10136&lt;/a>).&lt;/li>
&lt;li>Add support of AWS SDK v2 for KinesisIO.Read (Java) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-9702">BEAM-9702&lt;/a>).&lt;/li>
&lt;li>Add streaming support to SnowflakeIO in Java SDK (&lt;a href="https://issues.apache.org/jira/browse/BEAM-9896">BEAM-9896&lt;/a>)&lt;/li>
&lt;li>Support reading and writing to Google Healthcare DICOM APIs in Python SDK (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10601">BEAM-10601&lt;/a>)&lt;/li>
&lt;li>Add dispositions for SnowflakeIO.write (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10343">BEAM-10343&lt;/a>)&lt;/li>
&lt;li>Add cross-language support to SnowflakeIO.Read now available in the Python module &lt;code>apache_beam.io.external.snowflake&lt;/code> (&lt;a href="https://issues.apache.org/jira/browse/BEAM-9897">BEAM-9897&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h2 id="new-features--improvements">New Features / Improvements&lt;/h2>
&lt;ul>
&lt;li>Shared library for simplifying management of large shared objects added to Python SDK. Example use case is sharing a large TF model object across threads (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10417">BEAM-10417&lt;/a>).&lt;/li>
&lt;li>Dataflow streaming timers are not strictly time ordered when set earlier mid-bundle (&lt;a href="https://issues.apache.org/jira/browse/BEAM-8543">BEAM-8543&lt;/a>).&lt;/li>
&lt;li>OnTimerContext should not create a new one when processing each element/timer in FnApiDoFnRunner (&lt;a href="https://issues.apache.org/jira/browse/BEAM-9839">BEAM-9839&lt;/a>)&lt;/li>
&lt;li>Key should be available in @OnTimer methods (Spark Runner) (&lt;a href="https://issues.apache.org/jira/browse/BEAM-9850">BEAM-9850&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="breaking-changes">Breaking Changes&lt;/h2>
&lt;ul>
&lt;li>WriteToBigQuery transforms now require a GCS location to be provided through either
custom_gcs_temp_location in the constructor of WriteToBigQuery or the fallback option
&amp;ndash;temp_location, or pass method=&amp;quot;STREAMING_INSERTS&amp;rdquo; to WriteToBigQuery (&lt;a href="https://issues.apache.org/jira/browse/BEAM-6928">BEAM-6928&lt;/a>).&lt;/li>
&lt;li>Python SDK now understands &lt;code>typing.FrozenSet&lt;/code> type hints, which are not interchangeable with &lt;code>typing.Set&lt;/code>. You may need to update your pipelines if type checking fails. (&lt;a href="https://issues.apache.org/jira/browse/BEAM-10197">BEAM-10197&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="known-issues">Known Issues&lt;/h2>
&lt;ul>
&lt;li>Default compressor change breaks dataflow python streaming job update compatibility. Please use python SDK version &amp;lt;= 2.23.0 or &amp;gt; 2.25.0 if job update is critical.(&lt;a href="https://issues.apache.org/jira/browse/BEAM-11113">BEAM-11113&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.24.0 release. Thank you to all contributors!&lt;/p>
&lt;p>adesormi, Ahmet Altay, Alex Amato, Alexey Romanenko, Andrew Pilloud, Ashwin Ramaswami, Borzoo,
Boyuan Zhang, Brian Hulette, Brian M, Bu Sun Kim, Chamikara Jayalath, Colm O hEigeartaigh,
Corvin Deboeser, Damian Gadomski, Damon Douglas, Daniel Oliveira, Dariusz Aniszewski,
davidak09, David Cavazos, David Moravek, David Yan, dhodun, Doug Roeper, Emil Hessman, Emily Ye,
Etienne Chauchot, Etta Rapp, Eugene Kirpichov, fuyuwei, Gleb Kanterov,
Harrison Green, Heejong Lee, Henry Suryawirawan, InigoSJ, Ismaël Mejía, Israel Herraiz,
Jacob Ferriero, Jan Lukavský, Jayendra, jfarr, jhnmora000, Jiadai Xia, JIahao wu, Jie Fan,
Jiyong Jung, Julius Almeida, Kamil Gałuszka, Kamil Wasilewski, Kasia Kucharczyk, Kenneth Knowles,
Kevin Puthusseri, Kyle Weaver, Łukasz Gajowy, Luke Cwik, Mark-Zeng, Maximilian Michels,
Michal Walenia, Niel Markwick, Ning Kang, Pablo Estrada, pawel.urbanowicz, Piotr Szuberski,
Rafi Kamal, rarokni, Rehman Murad Ali, Reuben van Ammers, Reuven Lax, Ricardo Bordon,
Robert Bradshaw, Robert Burke, Robin Qiu, Rui Wang, Saavan Nanavati, sabhyankar, Sam Rohde,
Scott Lukas, Siddhartha Thota, Simone Primarosa, Sławomir Andrian,
Steve Niemitz, Tobiasz Kędzierski, Tomo Suzuki, Tyson Hamilton, Udi Meiri,
Valentyn Tymofieiev, viktorjonsson, Xinyu Liu, Yichi Zhang, Yixing Zhang, yoshiki.obata,
Yueyang Qiu, zijiesong&lt;/p></description><link>/blog/beam-2.24.0/</link><pubDate>Fri, 18 Sep 2020 00:00:01 -0800</pubDate><guid>/blog/beam-2.24.0/</guid><category>blog</category></item></channel></rss>